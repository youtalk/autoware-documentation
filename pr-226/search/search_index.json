{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Autoware Documentation # About Autoware # Autoware is the world\u2019s leading open-source software project for autonomous driving. Autoware is built on Robot Operating System ( ROS ) and enables commercial deployment of autonomous driving in a broad range of vehicles and applications. Please see here for more details. Getting started # Installation pages explain the installation steps of Autoware and related tools. Tutorials pages explain several tutorials that you should try after installation. How-to guides pages explain advanced topics that you should read after you get used to Autoware. Design pages explain the design concept of Autoware. Contributing pages explain how to contribute to Autoware. Datasets pages contain information about datasets that can be used with Autoware. Support pages explain several support resources.","title":"Introduction"},{"location":"#autoware-documentation","text":"","title":"Autoware Documentation"},{"location":"#about-autoware","text":"Autoware is the world\u2019s leading open-source software project for autonomous driving. Autoware is built on Robot Operating System ( ROS ) and enables commercial deployment of autonomous driving in a broad range of vehicles and applications. Please see here for more details.","title":"About Autoware"},{"location":"#getting-started","text":"Installation pages explain the installation steps of Autoware and related tools. Tutorials pages explain several tutorials that you should try after installation. How-to guides pages explain advanced topics that you should read after you get used to Autoware. Design pages explain the design concept of Autoware. Contributing pages explain how to contribute to Autoware. Datasets pages contain information about datasets that can be used with Autoware. Support pages explain several support resources.","title":"Getting started"},{"location":"contributing/","text":"Contributing # Thank you for your interest in contributing! Autoware is supported by people like you, and all types and sizes of contribution are welcome. As a contributor, here are the guidelines that we would like you to follow for Autoware and its associated repositories. Code of Conduct What should I know before I get started? Autoware concepts Contributing to open source projects How can I get help? How can I contribute? Participate in discussions Join a working group Report bugs Make a pull request Like Autoware itself, these guidelines are being actively developed and suggestions for improvement are always welcome! Guideline changes can be proposed by creating a discussion in the Ideas category . Code of Conduct # To ensure the Autoware community stays open and inclusive, please follow the Code of Conduct . If you believe that someone in the community has violated the Code of Conduct, please make a report by emailing conduct@autoware.org . What should I know before I get started? # Autoware concepts # To gain a high-level understanding of Autoware's architecture and design, the following pages provide a brief overview: Autoware architecture Autoware concepts For experienced developers, the Autoware interfaces and individual component pages should also be reviewed to understand the inputs and outputs for each component or module at a more detailed level. Contributing to open source projects # If you are new to open source projects, we recommend reading GitHub's How to Contribute to Open Source guide for an overview of why people contribute to open source projects, what it means to contribute and much more besides. How can I get help? # Do not open issues for general support questions as we want to keep GitHub issues for confirmed bug reports. Instead, open a discussion in the Q&A category. For more details on the support mechanisms for Autoware, refer to the Support guidelines . Note Issues created for questions or unconfirmed bugs will be moved to GitHub discussions by the maintainers. How can I contribute? # Discussions # You can contribute to Autoware by facilitating and participating in discussions, such as: Proposing a new feature to enhance Autoware Joining an existing discussion and expressing your opinion Organizing discussions for other contributors Answering questions and supporting other contributors Working groups # The various working groups within the Autoware Foundation are responsible for accomplishing goals set by the Technical Steering Committee. These working groups are open to everyone, and joining a particular working group will allow you to gain an understanding of current projects, see how those projects are managed within each group and to contribute to issues that will help progress a particular project. To see the schedule for upcoming working group meetings, refer to the Autoware Foundation events calendar . Bug reports # Before you report a bug, please search the issue tracker for the appropriate repository. It is possible that someone has already reported the same issue and that workarounds exist. If you can't determine the appropriate repository, ask the maintainers for help by creating a new discussion in the Q&A category . When reporting a bug, you should provide a minimal set of instructions to reproduce the issue. Doing so allows us to quickly confirm and focus on the right problem. If you want to fix the bug by yourself that will be appreciated, but you should discuss possible approaches with the maintainers in the issue before submitting a pull request. Creating an issue is straightforward , but if you happen to experience any problems then create a Q&A discussion to ask for help. Pull requests # You can submit pull requests for small changes such as: Minor documentation updates Fixing spelling mistakes Fixing CI failures Fixing warnings detected by compilers or analysis tools Making small changes to a single package If your pull request is a large change, the following process should be followed: Create a GitHub Discussion to propose the change. Doing so allows you to get feedback from other members and the Autoware maintainers and to ensure that the proposed change is in line with Autoware's design philosophy and current development plans. If you're not sure where to have that conversation, then create a new Q&A discussion . Create an issue following consensus in the discussions Create a pull request to implement the changes that references the Issue created in step 2 Create documentation for the new addition (if relevant) Examples of large changes include: Adding a new feature to Autoware Adding a new documentation page or section For more information on how to submit a good pull request, have a read of the pull request guidelines and don't forget to review the required license notations !","title":"Contributing"},{"location":"contributing/#contributing","text":"Thank you for your interest in contributing! Autoware is supported by people like you, and all types and sizes of contribution are welcome. As a contributor, here are the guidelines that we would like you to follow for Autoware and its associated repositories. Code of Conduct What should I know before I get started? Autoware concepts Contributing to open source projects How can I get help? How can I contribute? Participate in discussions Join a working group Report bugs Make a pull request Like Autoware itself, these guidelines are being actively developed and suggestions for improvement are always welcome! Guideline changes can be proposed by creating a discussion in the Ideas category .","title":"Contributing"},{"location":"contributing/#code-of-conduct","text":"To ensure the Autoware community stays open and inclusive, please follow the Code of Conduct . If you believe that someone in the community has violated the Code of Conduct, please make a report by emailing conduct@autoware.org .","title":"Code of Conduct"},{"location":"contributing/#what-should-i-know-before-i-get-started","text":"","title":"What should I know before I get started?"},{"location":"contributing/#autoware-concepts","text":"To gain a high-level understanding of Autoware's architecture and design, the following pages provide a brief overview: Autoware architecture Autoware concepts For experienced developers, the Autoware interfaces and individual component pages should also be reviewed to understand the inputs and outputs for each component or module at a more detailed level.","title":"Autoware concepts"},{"location":"contributing/#contributing-to-open-source-projects","text":"If you are new to open source projects, we recommend reading GitHub's How to Contribute to Open Source guide for an overview of why people contribute to open source projects, what it means to contribute and much more besides.","title":"Contributing to open source projects"},{"location":"contributing/#how-can-i-get-help","text":"Do not open issues for general support questions as we want to keep GitHub issues for confirmed bug reports. Instead, open a discussion in the Q&A category. For more details on the support mechanisms for Autoware, refer to the Support guidelines . Note Issues created for questions or unconfirmed bugs will be moved to GitHub discussions by the maintainers.","title":"How can I get help?"},{"location":"contributing/#how-can-i-contribute","text":"","title":"How can I contribute?"},{"location":"contributing/#discussions","text":"You can contribute to Autoware by facilitating and participating in discussions, such as: Proposing a new feature to enhance Autoware Joining an existing discussion and expressing your opinion Organizing discussions for other contributors Answering questions and supporting other contributors","title":"Discussions"},{"location":"contributing/#working-groups","text":"The various working groups within the Autoware Foundation are responsible for accomplishing goals set by the Technical Steering Committee. These working groups are open to everyone, and joining a particular working group will allow you to gain an understanding of current projects, see how those projects are managed within each group and to contribute to issues that will help progress a particular project. To see the schedule for upcoming working group meetings, refer to the Autoware Foundation events calendar .","title":"Working groups"},{"location":"contributing/#bug-reports","text":"Before you report a bug, please search the issue tracker for the appropriate repository. It is possible that someone has already reported the same issue and that workarounds exist. If you can't determine the appropriate repository, ask the maintainers for help by creating a new discussion in the Q&A category . When reporting a bug, you should provide a minimal set of instructions to reproduce the issue. Doing so allows us to quickly confirm and focus on the right problem. If you want to fix the bug by yourself that will be appreciated, but you should discuss possible approaches with the maintainers in the issue before submitting a pull request. Creating an issue is straightforward , but if you happen to experience any problems then create a Q&A discussion to ask for help.","title":"Bug reports"},{"location":"contributing/#pull-requests","text":"You can submit pull requests for small changes such as: Minor documentation updates Fixing spelling mistakes Fixing CI failures Fixing warnings detected by compilers or analysis tools Making small changes to a single package If your pull request is a large change, the following process should be followed: Create a GitHub Discussion to propose the change. Doing so allows you to get feedback from other members and the Autoware maintainers and to ensure that the proposed change is in line with Autoware's design philosophy and current development plans. If you're not sure where to have that conversation, then create a new Q&A discussion . Create an issue following consensus in the discussions Create a pull request to implement the changes that references the Issue created in step 2 Create documentation for the new addition (if relevant) Examples of large changes include: Adding a new feature to Autoware Adding a new documentation page or section For more information on how to submit a good pull request, have a read of the pull request guidelines and don't forget to review the required license notations !","title":"Pull requests"},{"location":"contributing/license/","text":"License # Autoware is licensed under Apache License 2.0. Thus all contributions will be licensed as such as per clause 5 of the Apache License 2.0: 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Here is an example copyright header to add to the top of a new file: Copyright [first year of contribution] The Autoware Contributors SPDX-License-Identifier: Apache-2.0 We don't write copyright notations of each contributor here. Instead, we place them in the NOTICE file like the following. This product includes code developed by [company name]. Copyright [first year of contribution] [company name] Let us know if your legal department has a special request for the copyright notation. Currently, the old formats explained here are also acceptable. Those old formats can be replaced by this new format if the original authors agree. Note that we won't write their copyrights to the NOTICE file unless they agree with the new format. References: https://opensource.google/docs/copyright/#the-year https://www.linuxfoundation.org/blog/copyright-notices-in-open-source-software-projects/ https://www.apache.org/licenses/LICENSE-2.0 https://www.apache.org/legal/src-headers.html https://www.apache.org/foundation/license-faq.html https://infra.apache.org/licensing-howto.html","title":"License"},{"location":"contributing/license/#license","text":"Autoware is licensed under Apache License 2.0. Thus all contributions will be licensed as such as per clause 5 of the Apache License 2.0: 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Here is an example copyright header to add to the top of a new file: Copyright [first year of contribution] The Autoware Contributors SPDX-License-Identifier: Apache-2.0 We don't write copyright notations of each contributor here. Instead, we place them in the NOTICE file like the following. This product includes code developed by [company name]. Copyright [first year of contribution] [company name] Let us know if your legal department has a special request for the copyright notation. Currently, the old formats explained here are also acceptable. Those old formats can be replaced by this new format if the original authors agree. Note that we won't write their copyrights to the NOTICE file unless they agree with the new format. References: https://opensource.google/docs/copyright/#the-year https://www.linuxfoundation.org/blog/copyright-notices-in-open-source-software-projects/ https://www.apache.org/licenses/LICENSE-2.0 https://www.apache.org/legal/src-headers.html https://www.apache.org/foundation/license-faq.html https://infra.apache.org/licensing-howto.html","title":"License"},{"location":"contributing/coding-guidelines/","text":"Coding guidelines # Warning Under Construction Common guidelines # Refer to the following links for now: https://docs.ros.org/en/humble/Contributing/Developer-Guide.html Also, keep in mind the following concepts. Keep things consistent. Automate where possible, using simple checks for formatting, syntax, etc. When it comes to code reviews, don't spend too much time on trivial disagreements. For details see: https://en.wikipedia.org/wiki/Law_of_triviality https://steemit.com/programming/@emrebeyler/code-reviews-and-parkinson-s-law-of-triviality","title":"Coding guidelines"},{"location":"contributing/coding-guidelines/#coding-guidelines","text":"Warning Under Construction","title":"Coding guidelines"},{"location":"contributing/coding-guidelines/#common-guidelines","text":"Refer to the following links for now: https://docs.ros.org/en/humble/Contributing/Developer-Guide.html Also, keep in mind the following concepts. Keep things consistent. Automate where possible, using simple checks for formatting, syntax, etc. When it comes to code reviews, don't spend too much time on trivial disagreements. For details see: https://en.wikipedia.org/wiki/Law_of_triviality https://steemit.com/programming/@emrebeyler/code-reviews-and-parkinson-s-law-of-triviality","title":"Common guidelines"},{"location":"contributing/coding-guidelines/languages/cmake/","text":"CMake # Warning Under Construction Refer to the following links for now: https://docs.ros.org/en/humble/Contributing/Code-Style-Language-Versions.html#cmake Use the autoware_package macro # To reduce duplications in CMakeLists.txt, there is the autoware_package() macro. See the README and use it in your package.","title":"CMake"},{"location":"contributing/coding-guidelines/languages/cmake/#cmake","text":"Warning Under Construction Refer to the following links for now: https://docs.ros.org/en/humble/Contributing/Code-Style-Language-Versions.html#cmake","title":"CMake"},{"location":"contributing/coding-guidelines/languages/cmake/#use-the-autoware_package-macro","text":"To reduce duplications in CMakeLists.txt, there is the autoware_package() macro. See the README and use it in your package.","title":"Use the autoware_package macro"},{"location":"contributing/coding-guidelines/languages/cpp/","text":"C++ # Warning Under Construction Refer to the following links for now: https://docs.ros.org/en/humble/Contributing/Code-Style-Language-Versions.html#id1 https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines https://www.autosar.org/fileadmin/user_upload/standards/adaptive/21-11/AUTOSAR_RS_CPP14Guidelines.pdf","title":"C++"},{"location":"contributing/coding-guidelines/languages/cpp/#c","text":"Warning Under Construction Refer to the following links for now: https://docs.ros.org/en/humble/Contributing/Code-Style-Language-Versions.html#id1 https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines https://www.autosar.org/fileadmin/user_upload/standards/adaptive/21-11/AUTOSAR_RS_CPP14Guidelines.pdf","title":"C++"},{"location":"contributing/coding-guidelines/languages/docker/","text":"Docker # Warning Under Construction Refer to the following links for now: https://github.com/hadolint/hadolint","title":"Docker"},{"location":"contributing/coding-guidelines/languages/docker/#docker","text":"Warning Under Construction Refer to the following links for now: https://github.com/hadolint/hadolint","title":"Docker"},{"location":"contributing/coding-guidelines/languages/github-actions/","text":"GitHub Actions # Warning Under Construction Refer to the following links for now: https://docs.github.com/en/actions/guides","title":"GitHub Actions"},{"location":"contributing/coding-guidelines/languages/github-actions/#github-actions","text":"Warning Under Construction Refer to the following links for now: https://docs.github.com/en/actions/guides","title":"GitHub Actions"},{"location":"contributing/coding-guidelines/languages/markdown/","text":"Markdown # Warning Under Construction Refer to the following links for now: https://docs.ros.org/en/foxy/Contributing/Code-Style-Language-Versions.html#markdown-restructured-text-docblocks https://github.com/DavidAnson/markdownlint","title":"Markdown"},{"location":"contributing/coding-guidelines/languages/markdown/#markdown","text":"Warning Under Construction Refer to the following links for now: https://docs.ros.org/en/foxy/Contributing/Code-Style-Language-Versions.html#markdown-restructured-text-docblocks https://github.com/DavidAnson/markdownlint","title":"Markdown"},{"location":"contributing/coding-guidelines/languages/package-xml/","text":"package.xml # Warning Under Construction Refer to the following links for now: https://ros.org/reps/rep-0149.html https://github.com/tier4/pre-commit-hooks-ros#prettier-package-xml","title":"package.xml"},{"location":"contributing/coding-guidelines/languages/package-xml/#packagexml","text":"Warning Under Construction Refer to the following links for now: https://ros.org/reps/rep-0149.html https://github.com/tier4/pre-commit-hooks-ros#prettier-package-xml","title":"package.xml"},{"location":"contributing/coding-guidelines/languages/python/","text":"Python # Warning Under Construction Refer to the following links for now: https://docs.ros.org/en/foxy/Contributing/Code-Style-Language-Versions.html#python https://github.com/psf/black https://github.com/PyCQA/isort","title":"Python"},{"location":"contributing/coding-guidelines/languages/python/#python","text":"Warning Under Construction Refer to the following links for now: https://docs.ros.org/en/foxy/Contributing/Code-Style-Language-Versions.html#python https://github.com/psf/black https://github.com/PyCQA/isort","title":"Python"},{"location":"contributing/coding-guidelines/languages/shell-scripts/","text":"Shell scripts # Warning Under Construction Refer to the following links for now: https://google.github.io/styleguide/shellguide.html https://github.com/koalaman/shellcheck https://github.com/mvdan/sh","title":"Shell scripts"},{"location":"contributing/coding-guidelines/languages/shell-scripts/#shell-scripts","text":"Warning Under Construction Refer to the following links for now: https://google.github.io/styleguide/shellguide.html https://github.com/koalaman/shellcheck https://github.com/mvdan/sh","title":"Shell scripts"},{"location":"contributing/coding-guidelines/ros-nodes/class-design/","text":"Class design # Warning Under Construction","title":"Class design"},{"location":"contributing/coding-guidelines/ros-nodes/class-design/#class-design","text":"Warning Under Construction","title":"Class design"},{"location":"contributing/coding-guidelines/ros-nodes/console-logging/","text":"Console logging # Warning Under Construction","title":"Console logging"},{"location":"contributing/coding-guidelines/ros-nodes/console-logging/#console-logging","text":"Warning Under Construction","title":"Console logging"},{"location":"contributing/coding-guidelines/ros-nodes/coordinate-system/","text":"Coordinate system # Warning Under Construction","title":"Coordinate system"},{"location":"contributing/coding-guidelines/ros-nodes/coordinate-system/#coordinate-system","text":"Warning Under Construction","title":"Coordinate system"},{"location":"contributing/coding-guidelines/ros-nodes/directory-structure/","text":"Directory structure # Warning Under Construction C++ package # <package_name> \u251c\u2500 config \u2502 \u251c\u2500 foo_ros.param.yaml \u2502 \u2514\u2500 foo_non_ros.yaml \u251c\u2500 include \u2502 \u2514\u2500 <package_name> \u2502 \u2514\u2500 foo_public.hpp \u251c\u2500 launch \u2502 \u251c\u2500 foo.launch.xml \u2502 \u2514\u2500 foo.launch.py \u251c\u2500 src \u2502 \u251c\u2500 foo_node.cpp \u2502 \u251c\u2500 foo_node.hpp \u2502 \u2514\u2500 foo_private.hpp \u251c\u2500 test \u2502 \u2514\u2500 test_foo.cpp \u251c\u2500 package.xml \u2514\u2500 CMakeLists.txt config directory # Place configuration files such as node parameters. For ROS parameters, use the extension .param.yaml . For non- ROS parameters, use the extension .yaml . Rationale: Since ROS parameters files are type-sensitive, they should not be the target of some code formatters and linters. In order to distinguish the file type, we use different file extensions. include directory # Place header files exposed to other packages. Do not place files directly under the include directory, but place files under the directory with the package name. This directory is used for mostly library headers. Note that many headers do not need to be placed here. It is enough to place the headers under the src directory. Reference: https://docs.ros.org/en/rolling/How-To-Guides/Ament-CMake-Documentation.html#adding-files-and-headers launch directory # Place launch files ( .launch.xml and .launch.py ). src directory # Place source files and private header files. test directory # Place source files for testing. Python package # T.B.D.","title":"Directory structure"},{"location":"contributing/coding-guidelines/ros-nodes/directory-structure/#directory-structure","text":"Warning Under Construction","title":"Directory structure"},{"location":"contributing/coding-guidelines/ros-nodes/directory-structure/#c-package","text":"<package_name> \u251c\u2500 config \u2502 \u251c\u2500 foo_ros.param.yaml \u2502 \u2514\u2500 foo_non_ros.yaml \u251c\u2500 include \u2502 \u2514\u2500 <package_name> \u2502 \u2514\u2500 foo_public.hpp \u251c\u2500 launch \u2502 \u251c\u2500 foo.launch.xml \u2502 \u2514\u2500 foo.launch.py \u251c\u2500 src \u2502 \u251c\u2500 foo_node.cpp \u2502 \u251c\u2500 foo_node.hpp \u2502 \u2514\u2500 foo_private.hpp \u251c\u2500 test \u2502 \u2514\u2500 test_foo.cpp \u251c\u2500 package.xml \u2514\u2500 CMakeLists.txt","title":"C++ package"},{"location":"contributing/coding-guidelines/ros-nodes/directory-structure/#config-directory","text":"Place configuration files such as node parameters. For ROS parameters, use the extension .param.yaml . For non- ROS parameters, use the extension .yaml . Rationale: Since ROS parameters files are type-sensitive, they should not be the target of some code formatters and linters. In order to distinguish the file type, we use different file extensions.","title":"config directory"},{"location":"contributing/coding-guidelines/ros-nodes/directory-structure/#include-directory","text":"Place header files exposed to other packages. Do not place files directly under the include directory, but place files under the directory with the package name. This directory is used for mostly library headers. Note that many headers do not need to be placed here. It is enough to place the headers under the src directory. Reference: https://docs.ros.org/en/rolling/How-To-Guides/Ament-CMake-Documentation.html#adding-files-and-headers","title":"include directory"},{"location":"contributing/coding-guidelines/ros-nodes/directory-structure/#launch-directory","text":"Place launch files ( .launch.xml and .launch.py ).","title":"launch directory"},{"location":"contributing/coding-guidelines/ros-nodes/directory-structure/#src-directory","text":"Place source files and private header files.","title":"src directory"},{"location":"contributing/coding-guidelines/ros-nodes/directory-structure/#test-directory","text":"Place source files for testing.","title":"test directory"},{"location":"contributing/coding-guidelines/ros-nodes/directory-structure/#python-package","text":"T.B.D.","title":"Python package"},{"location":"contributing/coding-guidelines/ros-nodes/launch-files/","text":"Launch files # Warning Under Construction","title":"Launch files"},{"location":"contributing/coding-guidelines/ros-nodes/launch-files/#launch-files","text":"Warning Under Construction","title":"Launch files"},{"location":"contributing/coding-guidelines/ros-nodes/message-guidelines/","text":"Message guidelines # Format # All messages should follow ROS message description specification . The accepted formats are: .msg .srv .action Default units # All the fields by default have the following units depending on their types: type default unit distance meter (m) angle radians (rad) time second (s) speed m/s velocity m/s acceleration m/s\u00b2 angular vel. rad/s angular accel. rad/s\u00b2 If a field in a message has any of these default units, don't add any suffix or prefix denoting the type. Non-default units # For non-default units, use following suffixes: type non-default unit suffix distance nanometer _nm distance micrometer _um distance millimeter _mm distance kilometer _km angle degree (deg) _deg time nanosecond _ns time microsecond _us time millisecond _ms time minute _min time hour (h) _hour velocity km/h _kmph If a unit that you'd like to use doesn't exist here, create an issue/PR to add it to this list. Message field types # For list of types supported by the ROS interfaces see here . Also copied here for convenience: Message Field Type C++ equivalent bool bool byte uint8_t char char float32 float float64 double int8 int8_t uint8 uint8_t int16 int16_t uint16 uint16_t int32 int32_t uint32 uint32_t int64 int64_t uint64 uint64_t string std::string wstring std::u16string Arrays # For arrays, use unbounded dynamic array type. Example: int32[] unbounded_integer_array Enumerations # ROS 2 interfaces don't support enumerations directly. It is possible to define integers constants and assign them to a non-constant integer parameter. Constants are written in CONSTANT_CASE . Assign a different value to each element of a constant. Example from shape_msgs/msg/SolidPrimitive.msg uint8 BOX=1 uint8 SPHERE=2 uint8 CYLINDER=3 uint8 CONE=4 uint8 PRISM=5 # The type of the shape uint8 type Comments # On top of the message, briefly explain what the message contains and/or what it is used for. For an example, see sensor_msgs/msg/Imu.msg . If necessary, add line comments before the fields that explain the context and/or meaning. For simple fields like x, y, z, w you might not need to add comments. Even though it is not strictly checked, try not to pass 100 characters in a line. Example: # Number of times the vehicle performed an emergency brake uint32 count_emergency_brake # Seconds passed since the last emergency brake uint64 duration Example usages # Don't use unit suffixes for default types: Bad: float32 path_length_m Good: float32 path_length Don't prefix the units: Bad: float32 kmph_velocity_vehicle Good: float32 velocity_vehicle_kmph Use recommended suffixes if they are available in the table : Bad: float32 velocity_vehicle_km_h Good: float32 velocity_vehicle_kmph","title":"Message guidelines"},{"location":"contributing/coding-guidelines/ros-nodes/message-guidelines/#message-guidelines","text":"","title":"Message guidelines"},{"location":"contributing/coding-guidelines/ros-nodes/message-guidelines/#format","text":"All messages should follow ROS message description specification . The accepted formats are: .msg .srv .action","title":"Format"},{"location":"contributing/coding-guidelines/ros-nodes/message-guidelines/#default-units","text":"All the fields by default have the following units depending on their types: type default unit distance meter (m) angle radians (rad) time second (s) speed m/s velocity m/s acceleration m/s\u00b2 angular vel. rad/s angular accel. rad/s\u00b2 If a field in a message has any of these default units, don't add any suffix or prefix denoting the type.","title":"Default units"},{"location":"contributing/coding-guidelines/ros-nodes/message-guidelines/#non-default-units","text":"For non-default units, use following suffixes: type non-default unit suffix distance nanometer _nm distance micrometer _um distance millimeter _mm distance kilometer _km angle degree (deg) _deg time nanosecond _ns time microsecond _us time millisecond _ms time minute _min time hour (h) _hour velocity km/h _kmph If a unit that you'd like to use doesn't exist here, create an issue/PR to add it to this list.","title":"Non-default units"},{"location":"contributing/coding-guidelines/ros-nodes/message-guidelines/#message-field-types","text":"For list of types supported by the ROS interfaces see here . Also copied here for convenience: Message Field Type C++ equivalent bool bool byte uint8_t char char float32 float float64 double int8 int8_t uint8 uint8_t int16 int16_t uint16 uint16_t int32 int32_t uint32 uint32_t int64 int64_t uint64 uint64_t string std::string wstring std::u16string","title":"Message field types"},{"location":"contributing/coding-guidelines/ros-nodes/message-guidelines/#arrays","text":"For arrays, use unbounded dynamic array type. Example: int32[] unbounded_integer_array","title":"Arrays"},{"location":"contributing/coding-guidelines/ros-nodes/message-guidelines/#enumerations","text":"ROS 2 interfaces don't support enumerations directly. It is possible to define integers constants and assign them to a non-constant integer parameter. Constants are written in CONSTANT_CASE . Assign a different value to each element of a constant. Example from shape_msgs/msg/SolidPrimitive.msg uint8 BOX=1 uint8 SPHERE=2 uint8 CYLINDER=3 uint8 CONE=4 uint8 PRISM=5 # The type of the shape uint8 type","title":"Enumerations"},{"location":"contributing/coding-guidelines/ros-nodes/message-guidelines/#comments","text":"On top of the message, briefly explain what the message contains and/or what it is used for. For an example, see sensor_msgs/msg/Imu.msg . If necessary, add line comments before the fields that explain the context and/or meaning. For simple fields like x, y, z, w you might not need to add comments. Even though it is not strictly checked, try not to pass 100 characters in a line. Example: # Number of times the vehicle performed an emergency brake uint32 count_emergency_brake # Seconds passed since the last emergency brake uint64 duration","title":"Comments"},{"location":"contributing/coding-guidelines/ros-nodes/message-guidelines/#example-usages","text":"Don't use unit suffixes for default types: Bad: float32 path_length_m Good: float32 path_length Don't prefix the units: Bad: float32 kmph_velocity_vehicle Good: float32 velocity_vehicle_kmph Use recommended suffixes if they are available in the table : Bad: float32 velocity_vehicle_km_h Good: float32 velocity_vehicle_kmph","title":"Example usages"},{"location":"contributing/coding-guidelines/ros-nodes/naming/","text":"Topic namespaces # Warning Under Construction","title":"Topic namespaces"},{"location":"contributing/coding-guidelines/ros-nodes/naming/#topic-namespaces","text":"Warning Under Construction","title":"Topic namespaces"},{"location":"contributing/coding-guidelines/ros-nodes/parameters/","text":"Parameters # Warning Under Construction","title":"Parameters"},{"location":"contributing/coding-guidelines/ros-nodes/parameters/#parameters","text":"Warning Under Construction","title":"Parameters"},{"location":"contributing/coding-guidelines/ros-nodes/task-scheduling/","text":"Task scheduling # Warning Under Construction","title":"Task scheduling"},{"location":"contributing/coding-guidelines/ros-nodes/task-scheduling/#task-scheduling","text":"Warning Under Construction","title":"Task scheduling"},{"location":"contributing/coding-guidelines/ros-nodes/topic-namespaces/","text":"Topic namespaces # Warning Under Construction","title":"Topic namespaces"},{"location":"contributing/coding-guidelines/ros-nodes/topic-namespaces/#topic-namespaces","text":"Warning Under Construction","title":"Topic namespaces"},{"location":"contributing/discussion-guidelines/","text":"Discussion guidelines # Warning Under Construction Refer to the following links for now: https://docs.github.com/en/discussions/guides/best-practices-for-community-conversations-on-github https://opensource.guide/how-to-contribute/#communicating-effectively","title":"Discussion guidelines"},{"location":"contributing/discussion-guidelines/#discussion-guidelines","text":"Warning Under Construction Refer to the following links for now: https://docs.github.com/en/discussions/guides/best-practices-for-community-conversations-on-github https://opensource.guide/how-to-contribute/#communicating-effectively","title":"Discussion guidelines"},{"location":"contributing/documentation-guidelines/","text":"Documentation guidelines # Workflow # Contributions to Autoware's documentation are welcome, and the same principles described in the contribution guidelines should be followed. Small, limited changes can be made by forking this repository and submitting a pull request, but larger changes should be discussed with the community and Autoware maintainers via GitHub Discussion first. Examples of small changes include: Fixing spelling or grammatical mistakes Fixing broken links Making an addition to an existing, well-defined page, such as the Troubleshooting guide. Examples of larger changes include: Adding new pages with a large amount of detail, such as a tutorial Re-organization of the existing documentation structure Style guide # You should refer to the Google developer documentation style guide as much as possible. Reading the Highlights page of that guide is recommended, but if not then the key points below should be noted. Use standard American English spelling and punctuation. Use sentence case for document titles and section headings. Use descriptive link text . Write short sentences that are easy to understand and translate. Tips # How to preview your modification # There are two ways to preview your modification on a documentation website. 1. Using GitHub Actions workflow # Follow the steps below. Create a pull request to the repository. Add the documentation label from the sidebar (See below figure). Wait for a couple of minutes, and the github-actions bot will notify the URL for the pull request's preview. 2. Running an MkDocs server in your local environment # Instead of creating a PR, you can use the mkdocs command to build Autoware's documentation websites on your local computer. Assuming that you are using Ubuntu OS, run the following to install the required libraries. python3 -m pip install -U $( curl -fsSL https://raw.githubusercontent.com/autowarefoundation/autoware-github-actions/main/deploy-docs/mkdocs-requirements.txt ) Then, run mkdocs serve on your documentation directory. cd /PATH/TO/YOUR-autoware-documentation mkdocs serve It will launch the MkDocs server. Access http://127.0.0.1:8000/ to see the preview of the website.","title":"Documentation guidelines"},{"location":"contributing/documentation-guidelines/#documentation-guidelines","text":"","title":"Documentation guidelines"},{"location":"contributing/documentation-guidelines/#workflow","text":"Contributions to Autoware's documentation are welcome, and the same principles described in the contribution guidelines should be followed. Small, limited changes can be made by forking this repository and submitting a pull request, but larger changes should be discussed with the community and Autoware maintainers via GitHub Discussion first. Examples of small changes include: Fixing spelling or grammatical mistakes Fixing broken links Making an addition to an existing, well-defined page, such as the Troubleshooting guide. Examples of larger changes include: Adding new pages with a large amount of detail, such as a tutorial Re-organization of the existing documentation structure","title":"Workflow"},{"location":"contributing/documentation-guidelines/#style-guide","text":"You should refer to the Google developer documentation style guide as much as possible. Reading the Highlights page of that guide is recommended, but if not then the key points below should be noted. Use standard American English spelling and punctuation. Use sentence case for document titles and section headings. Use descriptive link text . Write short sentences that are easy to understand and translate.","title":"Style guide"},{"location":"contributing/documentation-guidelines/#tips","text":"","title":"Tips"},{"location":"contributing/documentation-guidelines/#how-to-preview-your-modification","text":"There are two ways to preview your modification on a documentation website.","title":"How to preview your modification"},{"location":"contributing/pull-request-guidelines/","text":"Pull request guidelines # General pull request workflow # Autoware uses the fork-and-pull model. For more details about the model, refer to GitHub Docs . The following is a general example of the pull request workflow based on the fork-and-pull model. Use this workflow as a reference when you contribute to Autoware. Create an issue. Discuss the approaches to the issue with maintainers. Confirm the support guidelines before creating an issue. Follow the discussion guidelines when you discuss with other contributors. Create a fork repository. (for the first time only) Write code in your fork repository according to the approach agreed upon in the issue. Write the tests and documentation as appropriate. Follow the coding guidelines guidelines when you write code. Follow the Testing guidelines guidelines when you write tests. Follow the Documentation guidelines guidelines when you write documentation. Follow the commit guidelines when you commit your changes. Test the code. It is recommended that you summarize the test results, because you will need to explain the test results in the later review process. If you are not sure what tests should be done, discuss them with maintainers. Create a pull request. Follow the pull request rules when you create a pull request. Wait for the pull request to be reviewed. The reviewers will review your code following the review guidelines . Not only the reviewers, but also the author is encouraged to understand the review guidelines. If CI checks have failed, fix the errors. Address the review comments pointed out by the reviewers. If you don't understand the meaning of a review comment, ask the reviewers until you understand it. Fixing without understanding the reason is not recommended because the author should be responsible for the final content of their own pull request. If you don't agree with a review comment, ask the reviewers for a rational reason. The reviewers are obligated to make the author understand the meanings of each comment. After you have done with the review comments, re-request a review to the reviewers and back to 6. If there are no more new review comments, the reviewers will approve the pull request and proceed to 8. Merge the pull request. Anyone with write access can merge the pull request if there is no special request from maintainers. The author is encouraged to merge the pull request to feel responsible for their own pull request. If the author does not have write access, ask the reviewers or maintainers. Pull request rules # Use an appropriate pull request template (required, non-automated) # Rationale # The unified style of descriptions by templates can make reviews efficient. Example # Select the appropriate template, as shown in this video . Read the selected template carefully and fill the required content. Check the checkboxes during a review. There are pre-review checklist and post-review checklist for the author. Set appropriate reviewers after creating a pull request (required, partially automated) # Rationale # Pull requests must be reviewed by appropriate reviewers to keep the quality of the codebase. Example # For most ROS packages, reviewers will be automatically assigned based on the maintainer information in package.xml . If no reviewer is assigned automatically, assign reviewers manually following the instructions in GitHub Docs . You can find the reviewers by seeing the .github/CODEOWNERS file of the repository. If you are not sure the appropriate reviewers, ask @autoware-maintainers . If you have no rights to assign reviewers, mention reviewers instead. Apply Conventional Commits to the pull request title (required, automated) # Rationale # Conventional Commits can generate categorized changelogs, for example using git-cliff . Example # feat(trajectory_follower): add an awesome feature Note You have to start the description part (here add an awesome feature ) with a lowercase. If your change breaks some interfaces, use the ! (breaking changes) mark as follows: feat(trajectory_follower)!: remove package feat(trajectory_follower)!: change parameter names feat(planning)!: change topic names feat(autoware_utils)!: change function names For the repositories that contain code (most repositories), use the definition of conventional-commit-types for the type. For documentation repositories such as autoware-documentation , use the following definition: feat Add new pages. Add contents to the existing pages. fix Fix the contents in the existing pages. refactor Move contents to different pages. docs Update documentation for the documentation repository itself. build Update the settings of the documentation site builder. ! (breaking changes) Remove pages. Change the URL of pages. perf and test are generally unused. Other types have the same meaning as the code repositories. Add the related component names to the scope of Conventional Commits (advisory, non-automated) # Rationale # It helps contributors find pull requests that are relevant to them. It makes the changelog clearer. Example # For ROS packages, adding the package name or component name is good. feat(trajectory_follower): add an awesome feature refactor(planning, control): use common utils Keep a pull request small (advisory, non-automated) # Rationale # Small pull requests are easy to understand for reviewers. Small pull requests are easy to revert for maintainers. Exception # It is acceptable if it is agreed with maintainers that there is no other way but to submit a big pull request. Example # Avoid developing two features in one pull request. Avoid mixing different types ( feat , fix , refactor , etc.) of changes in the same commit. Remind reviewers if there is no response for more than a week (advisory, non-automated) # Rationale # It is the author's responsibility to care about their own pull request until it is merged. Example # @{some-of-developers} Would it be possible for you to review this PR? @autoware-maintainers friendly ping.","title":"Pull request guidelines"},{"location":"contributing/pull-request-guidelines/#pull-request-guidelines","text":"","title":"Pull request guidelines"},{"location":"contributing/pull-request-guidelines/#general-pull-request-workflow","text":"Autoware uses the fork-and-pull model. For more details about the model, refer to GitHub Docs . The following is a general example of the pull request workflow based on the fork-and-pull model. Use this workflow as a reference when you contribute to Autoware. Create an issue. Discuss the approaches to the issue with maintainers. Confirm the support guidelines before creating an issue. Follow the discussion guidelines when you discuss with other contributors. Create a fork repository. (for the first time only) Write code in your fork repository according to the approach agreed upon in the issue. Write the tests and documentation as appropriate. Follow the coding guidelines guidelines when you write code. Follow the Testing guidelines guidelines when you write tests. Follow the Documentation guidelines guidelines when you write documentation. Follow the commit guidelines when you commit your changes. Test the code. It is recommended that you summarize the test results, because you will need to explain the test results in the later review process. If you are not sure what tests should be done, discuss them with maintainers. Create a pull request. Follow the pull request rules when you create a pull request. Wait for the pull request to be reviewed. The reviewers will review your code following the review guidelines . Not only the reviewers, but also the author is encouraged to understand the review guidelines. If CI checks have failed, fix the errors. Address the review comments pointed out by the reviewers. If you don't understand the meaning of a review comment, ask the reviewers until you understand it. Fixing without understanding the reason is not recommended because the author should be responsible for the final content of their own pull request. If you don't agree with a review comment, ask the reviewers for a rational reason. The reviewers are obligated to make the author understand the meanings of each comment. After you have done with the review comments, re-request a review to the reviewers and back to 6. If there are no more new review comments, the reviewers will approve the pull request and proceed to 8. Merge the pull request. Anyone with write access can merge the pull request if there is no special request from maintainers. The author is encouraged to merge the pull request to feel responsible for their own pull request. If the author does not have write access, ask the reviewers or maintainers.","title":"General pull request workflow"},{"location":"contributing/pull-request-guidelines/#pull-request-rules","text":"","title":"Pull request rules"},{"location":"contributing/pull-request-guidelines/#use-an-appropriate-pull-request-template-required-non-automated","text":"","title":"Use an appropriate pull request template (required, non-automated)"},{"location":"contributing/pull-request-guidelines/#set-appropriate-reviewers-after-creating-a-pull-request-required-partially-automated","text":"","title":"Set appropriate reviewers after creating a pull request (required, partially automated)"},{"location":"contributing/pull-request-guidelines/#apply-conventional-commits-to-the-pull-request-title-required-automated","text":"","title":"Apply Conventional Commits to the pull request title (required, automated)"},{"location":"contributing/pull-request-guidelines/#add-the-related-component-names-to-the-scope-of-conventional-commits-advisory-non-automated","text":"","title":"Add the related component names to the scope of Conventional Commits (advisory, non-automated)"},{"location":"contributing/pull-request-guidelines/#keep-a-pull-request-small-advisory-non-automated","text":"","title":"Keep a pull request small (advisory, non-automated)"},{"location":"contributing/pull-request-guidelines/#remind-reviewers-if-there-is-no-response-for-more-than-a-week-advisory-non-automated","text":"","title":"Remind reviewers if there is no response for more than a week (advisory, non-automated)"},{"location":"contributing/pull-request-guidelines/ci-checks/","text":"CI checks # Autoware has several checks for a pull request. The results are shown at the bottom of the pull request page as below. If the \u274c mark is shown, click the Details button and investigate the failure reason. If the Required mark is shown, you cannot merge the pull request unless you resolve the error. If not, it is optional, but preferably it should be fixed. The following sections explain about common CI checks in Autoware. Note that some repositories may have different settings. DCO # The Developer Certificate of Origin (DCO) is a lightweight way for contributors to certify that they wrote or otherwise have the right to submit the code they are contributing to the project. This workflow checks whether the pull request fulfills DCO . You need to confirm the required items and commit with git commit -s . For more information, refer to the GitHub App page . semantic-pull-request # This workflow checks whether the pull request follows Conventional Commits . For the detailed rules, see the pull request rules . pre-commit # pre-commit is a tool to run formatters or linters when you commit. This workflow checks whether the pull request has no error with pre-commit . In the workflow pre-commit.ci - pr is enabled in the repository, it will automatically fix errors by pre-commit.ci as many as possible. If there are some errors remain, fix them manually. You can run pre-commit in your local environment by the following command: pre-commit run -a Or you can install pre-commit to the repository and automatically run it before committing: pre-commit install Since it is difficult to detect errors with no false positives, some jobs are split into another config file and marked as optional. To check them, use the --config option: pre-commit run -a --config .pre-commit-config-optional.yaml spell-check-differential # This workflow detects spelling mistakes using CSpell with our dictionary file . You can submit pull requests to tier4/autoware-spell-check-dict to update the dictionary. Since it is difficult to detect errors with no false positives, it is an optional workflow, but it is preferable to remove spelling mistakes as many as possible. build-and-test-differential # This workflow checks colcon build and colcon test for the pull request. To make the CI faster, it doesn't check all packages but only modified packages and the dependencies. build-and-test-differential-self-hosted # This workflow is the ARM64 version of build-and-test-differential . You need to add the ARM64 label to run this workflow. For reference information, since ARM machines are not supported by GitHub-hosted runners, we use self-hosted runners prepared by the AWF . For the details about self-hosted runners, refer to GitHub Docs . deploy-docs # This workflow deploys the preview documentation site for the pull request. You need to add the documentation label to run this workflow.","title":"CI checks"},{"location":"contributing/pull-request-guidelines/ci-checks/#ci-checks","text":"Autoware has several checks for a pull request. The results are shown at the bottom of the pull request page as below. If the \u274c mark is shown, click the Details button and investigate the failure reason. If the Required mark is shown, you cannot merge the pull request unless you resolve the error. If not, it is optional, but preferably it should be fixed. The following sections explain about common CI checks in Autoware. Note that some repositories may have different settings.","title":"CI checks"},{"location":"contributing/pull-request-guidelines/ci-checks/#dco","text":"The Developer Certificate of Origin (DCO) is a lightweight way for contributors to certify that they wrote or otherwise have the right to submit the code they are contributing to the project. This workflow checks whether the pull request fulfills DCO . You need to confirm the required items and commit with git commit -s . For more information, refer to the GitHub App page .","title":"DCO"},{"location":"contributing/pull-request-guidelines/ci-checks/#semantic-pull-request","text":"This workflow checks whether the pull request follows Conventional Commits . For the detailed rules, see the pull request rules .","title":"semantic-pull-request"},{"location":"contributing/pull-request-guidelines/ci-checks/#pre-commit","text":"pre-commit is a tool to run formatters or linters when you commit. This workflow checks whether the pull request has no error with pre-commit . In the workflow pre-commit.ci - pr is enabled in the repository, it will automatically fix errors by pre-commit.ci as many as possible. If there are some errors remain, fix them manually. You can run pre-commit in your local environment by the following command: pre-commit run -a Or you can install pre-commit to the repository and automatically run it before committing: pre-commit install Since it is difficult to detect errors with no false positives, some jobs are split into another config file and marked as optional. To check them, use the --config option: pre-commit run -a --config .pre-commit-config-optional.yaml","title":"pre-commit"},{"location":"contributing/pull-request-guidelines/ci-checks/#spell-check-differential","text":"This workflow detects spelling mistakes using CSpell with our dictionary file . You can submit pull requests to tier4/autoware-spell-check-dict to update the dictionary. Since it is difficult to detect errors with no false positives, it is an optional workflow, but it is preferable to remove spelling mistakes as many as possible.","title":"spell-check-differential"},{"location":"contributing/pull-request-guidelines/ci-checks/#build-and-test-differential","text":"This workflow checks colcon build and colcon test for the pull request. To make the CI faster, it doesn't check all packages but only modified packages and the dependencies.","title":"build-and-test-differential"},{"location":"contributing/pull-request-guidelines/ci-checks/#build-and-test-differential-self-hosted","text":"This workflow is the ARM64 version of build-and-test-differential . You need to add the ARM64 label to run this workflow. For reference information, since ARM machines are not supported by GitHub-hosted runners, we use self-hosted runners prepared by the AWF . For the details about self-hosted runners, refer to GitHub Docs .","title":"build-and-test-differential-self-hosted"},{"location":"contributing/pull-request-guidelines/ci-checks/#deploy-docs","text":"This workflow deploys the preview documentation site for the pull request. You need to add the documentation label to run this workflow.","title":"deploy-docs"},{"location":"contributing/pull-request-guidelines/commit-guidelines/","text":"Commit guidelines # Branch rules # Start branch names with the corresponding issue numbers (advisory, non-automated) # Rationale # Developers can quickly find the corresponding issues. It is helpful for tools. It is consistent with GitHub's default behavior. Exception # If there are no corresponding issues, you can ignore this rule. Example # 123-add-feature Reference # GitHub Docs Use dash-case for the separator of branch names (advisory, non-automated) # Rationale # It is consistent with GitHub's default behavior. Example # 123-add-feature Reference # GitHub Docs Make branch names descriptive (advisory, non-automated) # Rationale # It can avoid conflicts of names. Developers can understand the purpose of the branch. Exception # If you have already submitted a pull request, you do not have to change the branch name because you need to re-create a pull request, which is noisy and a waste of time. Be careful from the next time. Example # Usually it is good to start with a verb. 123-fix-memory-leak-of-trajectory-follower Commit rules # Sign-off your commits (required, automated) # Developers must certify that they wrote or otherwise have the right to submit the code they are contributing to the project. Rationale # If not, it will lead to complex license problems. Example # git commit -s feat: add a feature Signed-off-by: Autoware <autoware@example.com> Reference # GitHub Apps - DCO","title":"Commit guidelines"},{"location":"contributing/pull-request-guidelines/commit-guidelines/#commit-guidelines","text":"","title":"Commit guidelines"},{"location":"contributing/pull-request-guidelines/commit-guidelines/#branch-rules","text":"","title":"Branch rules"},{"location":"contributing/pull-request-guidelines/commit-guidelines/#start-branch-names-with-the-corresponding-issue-numbers-advisory-non-automated","text":"","title":"Start branch names with the corresponding issue numbers (advisory, non-automated)"},{"location":"contributing/pull-request-guidelines/commit-guidelines/#use-dash-case-for-the-separator-of-branch-names-advisory-non-automated","text":"","title":"Use dash-case for the separator of branch names (advisory, non-automated)"},{"location":"contributing/pull-request-guidelines/commit-guidelines/#make-branch-names-descriptive-advisory-non-automated","text":"","title":"Make branch names descriptive (advisory, non-automated)"},{"location":"contributing/pull-request-guidelines/commit-guidelines/#commit-rules","text":"","title":"Commit rules"},{"location":"contributing/pull-request-guidelines/commit-guidelines/#sign-off-your-commits-required-automated","text":"Developers must certify that they wrote or otherwise have the right to submit the code they are contributing to the project.","title":"Sign-off your commits (required, automated)"},{"location":"contributing/pull-request-guidelines/review-guidelines/","text":"Review guidelines # Warning Under Construction Refer to the following links for now: https://google.github.io/eng-practices/review/ https://docs.gitlab.com/ee/development/code_review.html https://www.swarmia.com/blog/a-complete-guide-to-code-reviews/ https://rewind.com/blog/best-practices-for-reviewing-pull-requests-in-github/","title":"Review guidelines"},{"location":"contributing/pull-request-guidelines/review-guidelines/#review-guidelines","text":"Warning Under Construction Refer to the following links for now: https://google.github.io/eng-practices/review/ https://docs.gitlab.com/ee/development/code_review.html https://www.swarmia.com/blog/a-complete-guide-to-code-reviews/ https://rewind.com/blog/best-practices-for-reviewing-pull-requests-in-github/","title":"Review guidelines"},{"location":"contributing/pull-request-guidelines/review-tips/","text":"Review tips # Toggle annotations or review comments in the diff view # There might be some annotations or review comments in the diff view during your review. To toggle annotations, press the A key. Before: After: To toggle review comments, press the I key. For other keyboard shortcuts, refer to GitHub Docs . View code in the web-based Visual Studio Code # You can open Visual Studio Code from your browser to view code in a rich UI. To use it, press the . key on any repository or pull request. For more detailed usage, refer to github/dev . Check out the branch of a pull request quickly # If you want to check out the branch of a pull request, it's generally troublesome with the fork-and-pull model. # Copy the user name and the fork URL. git remote add { user-name } { fork-url } git checkout { user-name } / { branch-name } git remote rm { user-name } # To clean up Instead, you can use GitHub CLI to simplify the steps, just run gh pr checkout {pr-number} . You can copy the command from the top right of the pull request page.","title":"Review tips"},{"location":"contributing/pull-request-guidelines/review-tips/#review-tips","text":"","title":"Review tips"},{"location":"contributing/pull-request-guidelines/review-tips/#toggle-annotations-or-review-comments-in-the-diff-view","text":"There might be some annotations or review comments in the diff view during your review. To toggle annotations, press the A key. Before: After: To toggle review comments, press the I key. For other keyboard shortcuts, refer to GitHub Docs .","title":"Toggle annotations or review comments in the diff view"},{"location":"contributing/pull-request-guidelines/review-tips/#view-code-in-the-web-based-visual-studio-code","text":"You can open Visual Studio Code from your browser to view code in a rich UI. To use it, press the . key on any repository or pull request. For more detailed usage, refer to github/dev .","title":"View code in the web-based Visual Studio Code"},{"location":"contributing/pull-request-guidelines/review-tips/#check-out-the-branch-of-a-pull-request-quickly","text":"If you want to check out the branch of a pull request, it's generally troublesome with the fork-and-pull model. # Copy the user name and the fork URL. git remote add { user-name } { fork-url } git checkout { user-name } / { branch-name } git remote rm { user-name } # To clean up Instead, you can use GitHub CLI to simplify the steps, just run gh pr checkout {pr-number} . You can copy the command from the top right of the pull request page.","title":"Check out the branch of a pull request quickly"},{"location":"contributing/testing-guidelines/","text":"Testing guidelines # Unit testing # Unit testing is a software testing method that tests individual units of source code to determine whether they satisfy the specification. For details, see the Unit testing guidelines . Integration testing # Integration testing combines and tests the individual software modules as a group, and is done after unit testing. While performing integration testing, the following subtypes of tests are written: Fault injection testing Back-to-back comparison between a model and code Requirements-based testing Anomaly detection during integration testing Random input testing For details, see the Integration testing guidelines .","title":"Testing guidelines"},{"location":"contributing/testing-guidelines/#testing-guidelines","text":"","title":"Testing guidelines"},{"location":"contributing/testing-guidelines/#unit-testing","text":"Unit testing is a software testing method that tests individual units of source code to determine whether they satisfy the specification. For details, see the Unit testing guidelines .","title":"Unit testing"},{"location":"contributing/testing-guidelines/#integration-testing","text":"Integration testing combines and tests the individual software modules as a group, and is done after unit testing. While performing integration testing, the following subtypes of tests are written: Fault injection testing Back-to-back comparison between a model and code Requirements-based testing Anomaly detection during integration testing Random input testing For details, see the Integration testing guidelines .","title":"Integration testing"},{"location":"contributing/testing-guidelines/integration-testing/","text":"Integration testing # An integration test is defined as the phase in software testing where individual software modules are combined and tested as a group. Integration tests occur after unit tests, and before validation tests. The input to an integration test is a set of independent modules that have been unit tested. The set of modules is tested against the defined integration test plan, and the output is a set of properly integrated software modules that is ready for system testing. Value of integration testing # Integration tests determine if independently developed software modules work correctly when the modules are connected to each other. In ROS 2, the software modules are called nodes. Testing a single node is a special type of integration test that is commonly referred to as component testing. Integration tests help to find the following types of errors: Incompatible interactions between nodes, such as non-matching topics, different message types, or incompatible QoS settings. Edge cases that were not touched by unit testing, such as a critical timing issue, network communication delays, disk I/O failures, and other such problems that can occur in production environments. Issues that can occur while the system is under high CPU/memory load, such as malloc failures. This can be tested using tools like stress and udpreplay to test the performance of nodes with real data. With ROS 2, it is possible to program complex autonomous-driving applications with a large number of nodes. Therefore, a lot of effort has been made to provide an integration-test framework that helps developers test the interaction of ROS 2 nodes. Integration-test framework # A typical integration-test framework has three parts: A series of executables with arguments that work together and generate outputs. A series of expected outputs that should match the output of the executables. A launcher that starts the tests, compares the outputs to the expected outputs, and determines if the test passes. In Autoware, we use the launch_testing framework. Smoke tests # Autoware has a dedicated API for smoke testing. To use this framework, in package.xml add: <test_depend> autoware_testing </test_depend> And in CMakeLists.txt add: if ( BUILD_TESTING ) find_package ( autoware_testing REQUIRED ) add_smoke_test ( ${ PROJECT_NAME } ${ NODE_NAME } ) endif () Doing so adds smoke tests that ensure that a node can be: Launched with a default parameter file. Terminated with a standard SIGTERM signal. For the full API documentation, refer to the package design page . Note This API is not suitable for all smoke test cases. It cannot be used when a specific file location (eg: for a map) is required to be passed to the node, or if some preparation needs to be conducted before node launch. In such cases use the manual solution from the component test section below . Integration test with a single node: component test # The simplest scenario is a single node. In this case, the integration test is commonly referred to as a component test. To add a component test to an existing node, you can follow the example of the lanelet2_map_loader in the map_loader package (added in this PR ). In package.xml , add: <test_depend> ros_testing </test_depend> In CMakeLists.txt , add or modify the BUILD_TESTING section: if ( BUILD_TESTING ) add_ros_test ( test/lanelet2_map_loader_launch.test.py TIMEOUT \"30\" ) install ( DIRECTORY test/data/ DESTINATION share/ ${ PROJECT_NAME } /test/data/ ) endif () In addition to the command add_ros_test , we also install any data that is required by the test using the install command. Note The TIMEOUT argument is given in seconds; see the add_ros_test.cmake file for details. The add_ros_test command will run the test in a unique ROS_DOMAIN_ID which avoids interference between tests running in parallel. To create a test, either read the launch_testing quick-start example , or follow the steps below. Taking test/lanelet2_map_loader_launch.test.py as an example, first dependencies are imported: import os import unittest from ament_index_python import get_package_share_directory import launch from launch import LaunchDescription from launch_ros.actions import Node import launch_testing import pytest Then a launch description is created to launch the node under test. Note that the test_map.osm file path is found and passed to the node, something that cannot be done with the smoke testing API : @pytest . mark . launch_test def generate_test_description (): lanelet2_map_path = os . path . join ( get_package_share_directory ( \"map_loader\" ), \"test/data/test_map.osm\" ) lanelet2_map_loader = Node ( package = \"map_loader\" , executable = \"lanelet2_map_loader\" , parameters = [{ \"lanelet2_map_path\" : lanelet2_map_path }], ) context = {} return ( LaunchDescription ( [ lanelet2_map_loader , # Start test after 1s - gives time for the map_loader to finish initialization launch . actions . TimerAction ( period = 1.0 , actions = [ launch_testing . actions . ReadyToTest ()] ), ] ), context , ) Note Since the node need time to process the input lanelet2 map, we use a TimerAction to delay the start of the test by 1s. In the example above, the context is empty but it can be used to pass objects to the test cases. You can find an example of using the context in the ROS 2 context_launch_test.py test example. Finally, a test is executed after the node executable has been shut down ( post_shutdown_test ). Here we ensure that the node was launched without error and exited cleanly. @launch_testing . post_shutdown_test () class TestProcessOutput ( unittest . TestCase ): def test_exit_code ( self , proc_info ): # Check that process exits with code 0: no error launch_testing . asserts . assertExitCodes ( proc_info ) Running the test # Continuing the example from above, first build your package: colcon build --packages-up-to map_loader source install/setup.bash Then either execute the component test manually: ros2 test src/universe/autoware.universe/map/map_loader/test/lanelet2_map_loader_launch.test.py Or as part of testing the entire package: colcon test --packages-select map_loader Verify that the test is executed; e.g. $ colcon test-result --all --verbose ... build/map_loader/test_results/map_loader/test_lanelet2_map_loader_launch.test.py.xunit.xml: 1 test, 0 errors, 0 failures, 0 skipped Next steps # The simple test described in Integration test with a single node: component test can be extended in numerous directions, such as testing a node's output. Testing the output of a node # To test while the node is running, create an active test by adding a subclass of Python's unittest.TestCase to *launch.test.py . Some boilerplate code is required to access output by creating a node and a subscription to a particular topic, e.g. import unittest class TestRunningDataPublisher ( unittest . TestCase ): @classmethod def setUpClass ( cls ): cls . context = Context () rclpy . init ( context = cls . context ) cls . node = rclpy . create_node ( \"test_node\" , context = cls . context ) @classmethod def tearDownClass ( cls ): rclpy . shutdown ( context = cls . context ) def setUp ( self ): self . msgs = [] sub = self . node . create_subscription ( msg_type = my_msg_type , topic = \"/info_test\" , callback = self . _msg_received ) self . addCleanup ( self . node . destroy_subscription , sub ) def _msg_received ( self , msg ): # Callback for ROS 2 subscriber used in the test self . msgs . append ( msg ) def get_message ( self ): startlen = len ( self . msgs ) executor = rclpy . executors . SingleThreadedExecutor ( context = self . context ) executor . add_node ( self . node ) try : # Try up to 60 s to receive messages end_time = time . time () + 60.0 while time . time () < end_time : executor . spin_once ( timeout_sec = 0.1 ) if startlen != len ( self . msgs ): break self . assertNotEqual ( startlen , len ( self . msgs )) return self . msgs [ - 1 ] finally : executor . remove_node ( self . node ) def test_message_content (): msg = self . get_message () self . assertEqual ( msg , \"Hello, world\" ) References # colcon is used to build and run tests. launch testing launches nodes and runs tests. Testing guidelines describes the different types of tests performed in Autoware and links to the corresponding guidelines.","title":"Integration testing"},{"location":"contributing/testing-guidelines/integration-testing/#integration-testing","text":"An integration test is defined as the phase in software testing where individual software modules are combined and tested as a group. Integration tests occur after unit tests, and before validation tests. The input to an integration test is a set of independent modules that have been unit tested. The set of modules is tested against the defined integration test plan, and the output is a set of properly integrated software modules that is ready for system testing.","title":"Integration testing"},{"location":"contributing/testing-guidelines/integration-testing/#value-of-integration-testing","text":"Integration tests determine if independently developed software modules work correctly when the modules are connected to each other. In ROS 2, the software modules are called nodes. Testing a single node is a special type of integration test that is commonly referred to as component testing. Integration tests help to find the following types of errors: Incompatible interactions between nodes, such as non-matching topics, different message types, or incompatible QoS settings. Edge cases that were not touched by unit testing, such as a critical timing issue, network communication delays, disk I/O failures, and other such problems that can occur in production environments. Issues that can occur while the system is under high CPU/memory load, such as malloc failures. This can be tested using tools like stress and udpreplay to test the performance of nodes with real data. With ROS 2, it is possible to program complex autonomous-driving applications with a large number of nodes. Therefore, a lot of effort has been made to provide an integration-test framework that helps developers test the interaction of ROS 2 nodes.","title":"Value of integration testing"},{"location":"contributing/testing-guidelines/integration-testing/#integration-test-framework","text":"A typical integration-test framework has three parts: A series of executables with arguments that work together and generate outputs. A series of expected outputs that should match the output of the executables. A launcher that starts the tests, compares the outputs to the expected outputs, and determines if the test passes. In Autoware, we use the launch_testing framework.","title":"Integration-test framework"},{"location":"contributing/testing-guidelines/integration-testing/#smoke-tests","text":"Autoware has a dedicated API for smoke testing. To use this framework, in package.xml add: <test_depend> autoware_testing </test_depend> And in CMakeLists.txt add: if ( BUILD_TESTING ) find_package ( autoware_testing REQUIRED ) add_smoke_test ( ${ PROJECT_NAME } ${ NODE_NAME } ) endif () Doing so adds smoke tests that ensure that a node can be: Launched with a default parameter file. Terminated with a standard SIGTERM signal. For the full API documentation, refer to the package design page . Note This API is not suitable for all smoke test cases. It cannot be used when a specific file location (eg: for a map) is required to be passed to the node, or if some preparation needs to be conducted before node launch. In such cases use the manual solution from the component test section below .","title":"Smoke tests"},{"location":"contributing/testing-guidelines/integration-testing/#integration-test-with-a-single-node-component-test","text":"The simplest scenario is a single node. In this case, the integration test is commonly referred to as a component test. To add a component test to an existing node, you can follow the example of the lanelet2_map_loader in the map_loader package (added in this PR ). In package.xml , add: <test_depend> ros_testing </test_depend> In CMakeLists.txt , add or modify the BUILD_TESTING section: if ( BUILD_TESTING ) add_ros_test ( test/lanelet2_map_loader_launch.test.py TIMEOUT \"30\" ) install ( DIRECTORY test/data/ DESTINATION share/ ${ PROJECT_NAME } /test/data/ ) endif () In addition to the command add_ros_test , we also install any data that is required by the test using the install command. Note The TIMEOUT argument is given in seconds; see the add_ros_test.cmake file for details. The add_ros_test command will run the test in a unique ROS_DOMAIN_ID which avoids interference between tests running in parallel. To create a test, either read the launch_testing quick-start example , or follow the steps below. Taking test/lanelet2_map_loader_launch.test.py as an example, first dependencies are imported: import os import unittest from ament_index_python import get_package_share_directory import launch from launch import LaunchDescription from launch_ros.actions import Node import launch_testing import pytest Then a launch description is created to launch the node under test. Note that the test_map.osm file path is found and passed to the node, something that cannot be done with the smoke testing API : @pytest . mark . launch_test def generate_test_description (): lanelet2_map_path = os . path . join ( get_package_share_directory ( \"map_loader\" ), \"test/data/test_map.osm\" ) lanelet2_map_loader = Node ( package = \"map_loader\" , executable = \"lanelet2_map_loader\" , parameters = [{ \"lanelet2_map_path\" : lanelet2_map_path }], ) context = {} return ( LaunchDescription ( [ lanelet2_map_loader , # Start test after 1s - gives time for the map_loader to finish initialization launch . actions . TimerAction ( period = 1.0 , actions = [ launch_testing . actions . ReadyToTest ()] ), ] ), context , ) Note Since the node need time to process the input lanelet2 map, we use a TimerAction to delay the start of the test by 1s. In the example above, the context is empty but it can be used to pass objects to the test cases. You can find an example of using the context in the ROS 2 context_launch_test.py test example. Finally, a test is executed after the node executable has been shut down ( post_shutdown_test ). Here we ensure that the node was launched without error and exited cleanly. @launch_testing . post_shutdown_test () class TestProcessOutput ( unittest . TestCase ): def test_exit_code ( self , proc_info ): # Check that process exits with code 0: no error launch_testing . asserts . assertExitCodes ( proc_info )","title":"Integration test with a single node: component test"},{"location":"contributing/testing-guidelines/integration-testing/#running-the-test","text":"Continuing the example from above, first build your package: colcon build --packages-up-to map_loader source install/setup.bash Then either execute the component test manually: ros2 test src/universe/autoware.universe/map/map_loader/test/lanelet2_map_loader_launch.test.py Or as part of testing the entire package: colcon test --packages-select map_loader Verify that the test is executed; e.g. $ colcon test-result --all --verbose ... build/map_loader/test_results/map_loader/test_lanelet2_map_loader_launch.test.py.xunit.xml: 1 test, 0 errors, 0 failures, 0 skipped","title":"Running the test"},{"location":"contributing/testing-guidelines/integration-testing/#next-steps","text":"The simple test described in Integration test with a single node: component test can be extended in numerous directions, such as testing a node's output.","title":"Next steps"},{"location":"contributing/testing-guidelines/integration-testing/#references","text":"colcon is used to build and run tests. launch testing launches nodes and runs tests. Testing guidelines describes the different types of tests performed in Autoware and links to the corresponding guidelines.","title":"References"},{"location":"contributing/testing-guidelines/unit-testing/","text":"Unit testing # Unit testing is the first phase of testing and is used to validate units of source code such as classes and functions. Typically, a unit of code is tested by validating its output for various inputs. Unit testing helps ensure that the code behaves as intended and prevents accidental changes of behavior. Autoware uses the ament_cmake framework to build and run tests. The same framework is also used to analyze the test results. ament_cmake provides several convenience functions to make it easy to register tests in a CMake-based package and to ensure that JUnit-compatible result files are generated. It currently supports a few different testing frameworks like pytest , gtest , and gmock . In order to prevent tests running in parallel from interfering with each other when publishing and subscribing to ROS topics, it is recommended to use commands from ament_cmake_ros to run tests in isolation. See below for an example of using ament_add_ros_isolated_gtest with colcon test . All other tests follow a similar pattern. Create a unit test with gtest # In my_cool_pkg/test , create the gtest code file test_my_cool_pkg.cpp : #include \"gtest/gtest.h\" #include \"my_cool_pkg/my_cool_pkg.hpp\" TEST ( TestMyCoolPkg , TestHello ) { EXPECT_EQ ( my_cool_pkg :: print_hello (), 0 ); } In package.xml , add the following line: <test_depend> ament_cmake_ros </test_depend> Next add an entry under BUILD_TESTING in the CMakeLists.txt to compile the test source files: if ( BUILD_TESTING ) ament_add_ros_isolated_gtest ( test_my_cool_pkg test/test_my_cool_pkg.cpp ) target_link_libraries ( test_my_cool_pkg ${ PROJECT_NAME } ) ... endif () This automatically links the test with the default main function provided by gtest . The code under test is usually in a different CMake target ( ${PROJECT_NAME} in the example) and its shared object for linking needs to be added. To register a new gtest item, wrap the test code with the macro TEST () . TEST () is a predefined macro that helps generate the final test code, and also registers a gtest item to be available for execution. The test case name should be in CamelCase, since gtest inserts an underscore between the fixture name and the class case name when creating the test executable. gtest/gtest.h also contains predefined macros of gtest like ASSERT_TRUE(condition) , ASSERT_FALSE(condition) , ASSERT_EQ(val1,val2) , ASSERT_STREQ(str1,str2) , EXPECT_EQ() , etc. ASSERT_* will abort the test if the condition is not satisfied, while EXPECT_* will mark the test as failed but continue on to the next test condition. Info More information about gtest and its features can be found in the gtest repo . In the demo CMakeLists.txt , ament_add_ros_isolated_gtest is a predefined macro in ament_cmake_ros that helps simplify adding gtest code. Details can be viewed in ament_add_gtest.cmake . Build test # By default, all necessary test files ( ELF , CTestTestfile.cmake , etc.) are compiled by colcon : cd ~/workspace/ colcon build --packages-select my_cool_pkg Test files are generated under ~/workspace/build/my_cool_pkg . Run test # To run all tests for a specific package, call: $ colcon test --packages-select my_cool_pkg Starting >>> my_cool_pkg Finished <<< my_cool_pkg [7.80s] Summary: 1 package finished [9.27s] The test command output contains a brief report of all the test results. To get job-wise information of all executed tests, call: $ colcon test-result --all build/my_cool_pkg/test_results/my_cool_pkg/copyright.xunit.xml: 8 tests, 0 errors, 0 failures, 0 skipped build/my_cool_pkg/test_results/my_cool_pkg/cppcheck.xunit.xml: 6 tests, 0 errors, 0 failures, 0 skipped build/my_cool_pkg/test_results/my_cool_pkg/lint_cmake.xunit.xml: 1 test, 0 errors, 0 failures, 0 skipped build/my_cool_pkg/test_results/my_cool_pkg/my_cool_pkg_exe_integration_test.xunit.xml: 1 test, 0 errors, 0 failures, 0 skipped build/my_cool_pkg/test_results/my_cool_pkg/test_my_cool_pkg.gtest.xml: 1 test, 0 errors, 0 failures, 0 skipped build/my_cool_pkg/test_results/my_cool_pkg/xmllint.xunit.xml: 1 test, 0 errors, 0 failures, 0 skipped Summary: 18 tests, 0 errors, 0 failures, 0 skipped Look in the ~/workspace/log/test_<date>/<package_name> directory for all the raw test commands, std_out , and std_err . There is also the ~/workspace/log/latest_*/ directory containing symbolic links to the most recent package-level build and test output. To print the tests' details while the tests are being run, use the --event-handlers console_cohesion+ option to print the details directly to the console: $ colcon test --event-handlers console_cohesion+ --packages-select my_cool_pkg ... test 1 Start 1: test_my_cool_pkg 1: Test command: /usr/bin/python3 \"-u\" \"~/workspace/install/share/ament_cmake_test/cmake/run_test.py\" \"~/workspace/build/my_cool_pkg/test_results/my_cool_pkg/test_my_cool_pkg.gtest.xml\" \"--package-name\" \"my_cool_pkg\" \"--output-file\" \"~/workspace/build/my_cool_pkg/ament_cmake_gtest/test_my_cool_pkg.txt\" \"--command\" \"~/workspace/build/my_cool_pkg/test_my_cool_pkg\" \"--gtest_output=xml:~/workspace/build/my_cool_pkg/test_results/my_cool_pkg/test_my_cool_pkg.gtest.xml\" 1: Test timeout computed to be: 60 1: -- run_test.py: invoking following command in '~/workspace/src/my_cool_pkg': 1: - ~/workspace/build/my_cool_pkg/test_my_cool_pkg --gtest_output=xml:~/workspace/build/my_cool_pkg/test_results/my_cool_pkg/test_my_cool_pkg.gtest.xml 1: [==========] Running 1 test from 1 test case. 1: [----------] Global test environment set-up. 1: [----------] 1 test from test_my_cool_pkg 1: [ RUN ] test_my_cool_pkg.test_hello 1: Hello World 1: [ OK ] test_my_cool_pkg.test_hello (0 ms) 1: [----------] 1 test from test_my_cool_pkg (0 ms total) 1: 1: [----------] Global test environment tear-down 1: [==========] 1 test from 1 test case ran. (0 ms total) 1: [ PASSED ] 1 test. 1: -- run_test.py: return code 0 1: -- run_test.py: inject classname prefix into gtest result file '~/workspace/build/my_cool_pkg/test_results/my_cool_pkg/test_my_cool_pkg.gtest.xml' 1: -- run_test.py: verify result file '~/workspace/build/my_cool_pkg/test_results/my_cool_pkg/test_my_cool_pkg.gtest.xml' 1/5 Test #1: test_my_cool_pkg ................... Passed 0.09 sec ... 100% tests passed, 0 tests failed out of 5 Label Time Summary: copyright = 0.49 sec*proc (1 test) cppcheck = 0.20 sec*proc (1 test) gtest = 0.05 sec*proc (1 test) lint_cmake = 0.18 sec*proc (1 test) linter = 1.34 sec*proc (4 tests) xmllint = 0.47 sec*proc (1 test) Total Test time (real) = 7.91 sec ... Code coverage # Loosely described, a code coverage metric is a measure of how much of the program code has been exercised (covered) during testing. In the Autoware repositories, Codecov is used to automatically calculate coverage of any open pull request. More details about the code coverage metrics can be found in the Codecov documentation .","title":"Unit testing"},{"location":"contributing/testing-guidelines/unit-testing/#unit-testing","text":"Unit testing is the first phase of testing and is used to validate units of source code such as classes and functions. Typically, a unit of code is tested by validating its output for various inputs. Unit testing helps ensure that the code behaves as intended and prevents accidental changes of behavior. Autoware uses the ament_cmake framework to build and run tests. The same framework is also used to analyze the test results. ament_cmake provides several convenience functions to make it easy to register tests in a CMake-based package and to ensure that JUnit-compatible result files are generated. It currently supports a few different testing frameworks like pytest , gtest , and gmock . In order to prevent tests running in parallel from interfering with each other when publishing and subscribing to ROS topics, it is recommended to use commands from ament_cmake_ros to run tests in isolation. See below for an example of using ament_add_ros_isolated_gtest with colcon test . All other tests follow a similar pattern.","title":"Unit testing"},{"location":"contributing/testing-guidelines/unit-testing/#create-a-unit-test-with-gtest","text":"In my_cool_pkg/test , create the gtest code file test_my_cool_pkg.cpp : #include \"gtest/gtest.h\" #include \"my_cool_pkg/my_cool_pkg.hpp\" TEST ( TestMyCoolPkg , TestHello ) { EXPECT_EQ ( my_cool_pkg :: print_hello (), 0 ); } In package.xml , add the following line: <test_depend> ament_cmake_ros </test_depend> Next add an entry under BUILD_TESTING in the CMakeLists.txt to compile the test source files: if ( BUILD_TESTING ) ament_add_ros_isolated_gtest ( test_my_cool_pkg test/test_my_cool_pkg.cpp ) target_link_libraries ( test_my_cool_pkg ${ PROJECT_NAME } ) ... endif () This automatically links the test with the default main function provided by gtest . The code under test is usually in a different CMake target ( ${PROJECT_NAME} in the example) and its shared object for linking needs to be added. To register a new gtest item, wrap the test code with the macro TEST () . TEST () is a predefined macro that helps generate the final test code, and also registers a gtest item to be available for execution. The test case name should be in CamelCase, since gtest inserts an underscore between the fixture name and the class case name when creating the test executable. gtest/gtest.h also contains predefined macros of gtest like ASSERT_TRUE(condition) , ASSERT_FALSE(condition) , ASSERT_EQ(val1,val2) , ASSERT_STREQ(str1,str2) , EXPECT_EQ() , etc. ASSERT_* will abort the test if the condition is not satisfied, while EXPECT_* will mark the test as failed but continue on to the next test condition. Info More information about gtest and its features can be found in the gtest repo . In the demo CMakeLists.txt , ament_add_ros_isolated_gtest is a predefined macro in ament_cmake_ros that helps simplify adding gtest code. Details can be viewed in ament_add_gtest.cmake .","title":"Create a unit test with gtest"},{"location":"contributing/testing-guidelines/unit-testing/#build-test","text":"By default, all necessary test files ( ELF , CTestTestfile.cmake , etc.) are compiled by colcon : cd ~/workspace/ colcon build --packages-select my_cool_pkg Test files are generated under ~/workspace/build/my_cool_pkg .","title":"Build test"},{"location":"contributing/testing-guidelines/unit-testing/#run-test","text":"To run all tests for a specific package, call: $ colcon test --packages-select my_cool_pkg Starting >>> my_cool_pkg Finished <<< my_cool_pkg [7.80s] Summary: 1 package finished [9.27s] The test command output contains a brief report of all the test results. To get job-wise information of all executed tests, call: $ colcon test-result --all build/my_cool_pkg/test_results/my_cool_pkg/copyright.xunit.xml: 8 tests, 0 errors, 0 failures, 0 skipped build/my_cool_pkg/test_results/my_cool_pkg/cppcheck.xunit.xml: 6 tests, 0 errors, 0 failures, 0 skipped build/my_cool_pkg/test_results/my_cool_pkg/lint_cmake.xunit.xml: 1 test, 0 errors, 0 failures, 0 skipped build/my_cool_pkg/test_results/my_cool_pkg/my_cool_pkg_exe_integration_test.xunit.xml: 1 test, 0 errors, 0 failures, 0 skipped build/my_cool_pkg/test_results/my_cool_pkg/test_my_cool_pkg.gtest.xml: 1 test, 0 errors, 0 failures, 0 skipped build/my_cool_pkg/test_results/my_cool_pkg/xmllint.xunit.xml: 1 test, 0 errors, 0 failures, 0 skipped Summary: 18 tests, 0 errors, 0 failures, 0 skipped Look in the ~/workspace/log/test_<date>/<package_name> directory for all the raw test commands, std_out , and std_err . There is also the ~/workspace/log/latest_*/ directory containing symbolic links to the most recent package-level build and test output. To print the tests' details while the tests are being run, use the --event-handlers console_cohesion+ option to print the details directly to the console: $ colcon test --event-handlers console_cohesion+ --packages-select my_cool_pkg ... test 1 Start 1: test_my_cool_pkg 1: Test command: /usr/bin/python3 \"-u\" \"~/workspace/install/share/ament_cmake_test/cmake/run_test.py\" \"~/workspace/build/my_cool_pkg/test_results/my_cool_pkg/test_my_cool_pkg.gtest.xml\" \"--package-name\" \"my_cool_pkg\" \"--output-file\" \"~/workspace/build/my_cool_pkg/ament_cmake_gtest/test_my_cool_pkg.txt\" \"--command\" \"~/workspace/build/my_cool_pkg/test_my_cool_pkg\" \"--gtest_output=xml:~/workspace/build/my_cool_pkg/test_results/my_cool_pkg/test_my_cool_pkg.gtest.xml\" 1: Test timeout computed to be: 60 1: -- run_test.py: invoking following command in '~/workspace/src/my_cool_pkg': 1: - ~/workspace/build/my_cool_pkg/test_my_cool_pkg --gtest_output=xml:~/workspace/build/my_cool_pkg/test_results/my_cool_pkg/test_my_cool_pkg.gtest.xml 1: [==========] Running 1 test from 1 test case. 1: [----------] Global test environment set-up. 1: [----------] 1 test from test_my_cool_pkg 1: [ RUN ] test_my_cool_pkg.test_hello 1: Hello World 1: [ OK ] test_my_cool_pkg.test_hello (0 ms) 1: [----------] 1 test from test_my_cool_pkg (0 ms total) 1: 1: [----------] Global test environment tear-down 1: [==========] 1 test from 1 test case ran. (0 ms total) 1: [ PASSED ] 1 test. 1: -- run_test.py: return code 0 1: -- run_test.py: inject classname prefix into gtest result file '~/workspace/build/my_cool_pkg/test_results/my_cool_pkg/test_my_cool_pkg.gtest.xml' 1: -- run_test.py: verify result file '~/workspace/build/my_cool_pkg/test_results/my_cool_pkg/test_my_cool_pkg.gtest.xml' 1/5 Test #1: test_my_cool_pkg ................... Passed 0.09 sec ... 100% tests passed, 0 tests failed out of 5 Label Time Summary: copyright = 0.49 sec*proc (1 test) cppcheck = 0.20 sec*proc (1 test) gtest = 0.05 sec*proc (1 test) lint_cmake = 0.18 sec*proc (1 test) linter = 1.34 sec*proc (4 tests) xmllint = 0.47 sec*proc (1 test) Total Test time (real) = 7.91 sec ...","title":"Run test"},{"location":"contributing/testing-guidelines/unit-testing/#code-coverage","text":"Loosely described, a code coverage metric is a measure of how much of the program code has been exercised (covered) during testing. In the Autoware repositories, Codecov is used to automatically calculate coverage of any open pull request. More details about the code coverage metrics can be found in the Codecov documentation .","title":"Code coverage"},{"location":"datasets/","text":"Datasets # Autoware partners provide datasets for testing and development. These datasets are available for download here. Bus- ODD (Operational Design Domain) datasets # Leo Drive - ISUZU sensor data # This dataset contains data from the Isuzu bus used in the Bus ODD project. The data contains data from following sensors: 1 x VLP16 2 x VLP32C 1 x Applanix POS LV 120 GNSS /INS 3 x Lucid Vision Triton 5.4MP cameras (left, right, front) Vehicle status report It also contains /tf topic for static transformations between sensors. Required message types # The GNSS data is available in sensor_msgs/msg/NavSatFix message type. But also the Applanix raw messages are also included in applanix_msgs/msg/NavigationPerformanceGsof50 and applanix_msgs/msg/NavigationSolutionGsof49 message types. In order to be able to play back these messages, you need to build and source the applanix_msgs package. # Create a workspace and clone the repository mkdir -p ~/applanix_ws/src && cd \" $_ \" git clone https://github.com/autowarefoundation/applanix.git cd .. # Build the workspace colcon build --symlink-install --packages-select applanix_msgs # Source the workspace source ~/applanix_ws/install/setup.bash # Now you can play back the messages Also make sure to source Autoware Universe workspace too. Download instructions # # Install awscli $ sudo apt update && sudo apt install awscli -y # This will download the entire dataset to the current directory. # ( About 10 .9GB of data ) $ aws s3 sync s3://autoware-files/collected_data/2022-08-22_leo_drive_isuzu_bags/ ./2022-08-22_leo_drive_isuzu_bags --no-sign-request # Optionally, # If you instead want to download a single bag file, you can get a list of the available files with following: $ aws s3 ls s3://autoware-files/collected_data/2022-08-22_leo_drive_isuzu_bags/ --no-sign-request PRE all-sensors-bag1_compressed/ PRE all-sensors-bag2_compressed/ PRE all-sensors-bag3_compressed/ PRE all-sensors-bag4_compressed/ PRE all-sensors-bag5_compressed/ PRE all-sensors-bag6_compressed/ PRE driving_20_kmh_2022_06_10-16_01_55_compressed/ PRE driving_30_kmh_2022_06_10-15_47_42_compressed/ # Then you can download a single bag file with the following: aws s3 sync s3://autoware-files/collected_data/2022-08-22_leo_drive_isuzu_bags/all-sensors-bag1_compressed/ ./all-sensors-bag1_compressed --no-sign-request AutoCore.ai - lidar ROS2 bag file and pcap # This dataset contains pcap files and ros2 bag files from Ouster OS1-64 Lidar. The pcap file and ros2 bag file is recorded in the same time with slight difference in duration. Click here to download (~553MB) Reference Issue","title":"Datasets"},{"location":"datasets/#datasets","text":"Autoware partners provide datasets for testing and development. These datasets are available for download here.","title":"Datasets"},{"location":"datasets/#bus-odd-operational-design-domain-datasets","text":"","title":"Bus-ODD (Operational Design Domain) datasets"},{"location":"datasets/#leo-drive-isuzu-sensor-data","text":"This dataset contains data from the Isuzu bus used in the Bus ODD project. The data contains data from following sensors: 1 x VLP16 2 x VLP32C 1 x Applanix POS LV 120 GNSS /INS 3 x Lucid Vision Triton 5.4MP cameras (left, right, front) Vehicle status report It also contains /tf topic for static transformations between sensors.","title":"Leo Drive - ISUZU sensor data"},{"location":"datasets/#autocoreai-lidar-ros2-bag-file-and-pcap","text":"This dataset contains pcap files and ros2 bag files from Ouster OS1-64 Lidar. The pcap file and ros2 bag file is recorded in the same time with slight difference in duration. Click here to download (~553MB) Reference Issue","title":"AutoCore.ai - lidar ROS2 bag file and pcap"},{"location":"design/","text":"Autoware's Design # Architecture # Core and Universe. Autoware provides the runtimes and technology components by open-source software. The runtimes are based on the Robot Operating System ( ROS ). The technology components are provided by contributors, which include, but are not limited to: Sensing Camera Component LiDAR Component RADAR Component GNSS Component Computing Localization Component Perception Component Planning Component Control Component Logging Component System Monitoring Component Actuation DBW Component Tools Simulator Component Mapping Component Remote Component ML Component Annotation Component Calibration Component Concern, Assumption, and Limitation # The downside of the microautonomy architecture is that the computational performance of end applications is sacrificed due to its data path overhead attributed to functional modularity. In other words, the trade-off characteristic of the microautonomy architecture exists between computational performance and functional modularity. This trade-off problem can be solved technically by introducing real-time capability. This is because autonomous driving systems are not really designed to be real-fast, that is, low-latency computing is nice-to-have but not must-have. The must-have feature for autonomous driving systems is that the latency of computing is predictable, that is, the systems are real-time. As a whole, we can compromise computational performance to an extent that is predictable enough to meet the given timing constraints of autonomous driving systems, often referred to as deadlines of computation. Design # Warning Under Construction Autoware concepts # The Autoware concepts page describes the design philosophy of Autoware. Readers (service providers and all Autoware users) will learn the basic concepts underlying Autoware development, such as microautonomy and the Core/Universe architecture. Autoware architecture # The Autoware architecture page describes an overview of each module that makes up Autoware. Readers (all Autoware users) will gain a high-level picture of how each module that composes Autoware works. Autoware interfaces # The Autoware interfaces page describes in detail the interface of each module that makes up Autoware. Readers (intermediate developers) will learn how to add new functionality to Autoware and how to integrate their own modules with Autoware. Configuration management # Conclusion #","title":"Autoware's Design"},{"location":"design/#autowares-design","text":"","title":"Autoware's Design"},{"location":"design/#architecture","text":"Core and Universe. Autoware provides the runtimes and technology components by open-source software. The runtimes are based on the Robot Operating System ( ROS ). The technology components are provided by contributors, which include, but are not limited to: Sensing Camera Component LiDAR Component RADAR Component GNSS Component Computing Localization Component Perception Component Planning Component Control Component Logging Component System Monitoring Component Actuation DBW Component Tools Simulator Component Mapping Component Remote Component ML Component Annotation Component Calibration Component","title":"Architecture"},{"location":"design/#concern-assumption-and-limitation","text":"The downside of the microautonomy architecture is that the computational performance of end applications is sacrificed due to its data path overhead attributed to functional modularity. In other words, the trade-off characteristic of the microautonomy architecture exists between computational performance and functional modularity. This trade-off problem can be solved technically by introducing real-time capability. This is because autonomous driving systems are not really designed to be real-fast, that is, low-latency computing is nice-to-have but not must-have. The must-have feature for autonomous driving systems is that the latency of computing is predictable, that is, the systems are real-time. As a whole, we can compromise computational performance to an extent that is predictable enough to meet the given timing constraints of autonomous driving systems, often referred to as deadlines of computation.","title":"Concern, Assumption, and Limitation"},{"location":"design/#design","text":"Warning Under Construction","title":"Design"},{"location":"design/#autoware-concepts","text":"The Autoware concepts page describes the design philosophy of Autoware. Readers (service providers and all Autoware users) will learn the basic concepts underlying Autoware development, such as microautonomy and the Core/Universe architecture.","title":"Autoware concepts"},{"location":"design/#autoware-architecture","text":"The Autoware architecture page describes an overview of each module that makes up Autoware. Readers (all Autoware users) will gain a high-level picture of how each module that composes Autoware works.","title":"Autoware architecture"},{"location":"design/#autoware-interfaces","text":"The Autoware interfaces page describes in detail the interface of each module that makes up Autoware. Readers (intermediate developers) will learn how to add new functionality to Autoware and how to integrate their own modules with Autoware.","title":"Autoware interfaces"},{"location":"design/#configuration-management","text":"","title":"Configuration management"},{"location":"design/#conclusion","text":"","title":"Conclusion"},{"location":"design/autoware-architecture/","text":"Architecture overview # This page describes the architecture of Autoware. Introduction # The current Autoware is defined to be a layered architecture that clarifies each module's role and simplifies the interface between them. By doing so: Autoware's internal processing becomes more transparent. Collaborative development is made easier because of the reduced interdependency between modules. Users can easily replace an existing module (e.g. localization) with their own software component by simply wrapping their software to fit in with Autoware's interface. Note that the initial focus of this architecture design was solely on driving capability, and so the following features were left as future work: Fail safe Human Machine Interface Real-time processing Redundant system State monitoring system High-level architecture design # Autoware's architecture consists of the following six stacks. Each linked page contains a more detailed set of requirements and use cases specific to that stack: Sensing design Map design Localization design Perception design Planning design Control design Vehicle Interface design Node diagram # A diagram showing Autoware's nodes in the default configuration can be found on the Node diagram page. Detailed documents for each node are available in the Autoware Universe docs . Note that Autoware configurations are scalable / selectable and will vary depending on the environment and required use cases. References # The architecture presentation given to the AWF Technical Steering Committee, March 2020","title":"Architecture overview"},{"location":"design/autoware-architecture/#architecture-overview","text":"This page describes the architecture of Autoware.","title":"Architecture overview"},{"location":"design/autoware-architecture/#introduction","text":"The current Autoware is defined to be a layered architecture that clarifies each module's role and simplifies the interface between them. By doing so: Autoware's internal processing becomes more transparent. Collaborative development is made easier because of the reduced interdependency between modules. Users can easily replace an existing module (e.g. localization) with their own software component by simply wrapping their software to fit in with Autoware's interface. Note that the initial focus of this architecture design was solely on driving capability, and so the following features were left as future work: Fail safe Human Machine Interface Real-time processing Redundant system State monitoring system","title":"Introduction"},{"location":"design/autoware-architecture/#high-level-architecture-design","text":"Autoware's architecture consists of the following six stacks. Each linked page contains a more detailed set of requirements and use cases specific to that stack: Sensing design Map design Localization design Perception design Planning design Control design Vehicle Interface design","title":"High-level architecture design"},{"location":"design/autoware-architecture/#node-diagram","text":"A diagram showing Autoware's nodes in the default configuration can be found on the Node diagram page. Detailed documents for each node are available in the Autoware Universe docs . Note that Autoware configurations are scalable / selectable and will vary depending on the environment and required use cases.","title":"Node diagram"},{"location":"design/autoware-architecture/#references","text":"The architecture presentation given to the AWF Technical Steering Committee, March 2020","title":"References"},{"location":"design/autoware-architecture/control/","text":"Control component design # Warning Under Construction","title":"Control component design"},{"location":"design/autoware-architecture/control/#control-component-design","text":"Warning Under Construction","title":"Control component design"},{"location":"design/autoware-architecture/localization/","text":"LOCALIZATION COMPONENT DESIGN DOC Abstract # 1. Requirements # Localization aims to estimate vehicle pose, velocity, and acceleration. Goals: Propose a system that can estimate vehicle pose, velocity, and acceleration for as long as possible. Propose a system that can diagnose the stability of estimation and send a warning message to the error-monitoring system if the estimation result is unreliable. Design a vehicle localization function that can work with various sensor configurations. Non-goals: This design document does not aim to develop a localization system that is infallible in all environments works outside of the pre-defined ODD (Operational Design Domain) has better performance than is required for autonomous driving 2. Sensor Configuration Examples # This section shows example sensor configurations and their expected performances. Each sensor has its own advantages and disadvantages, but overall performance can be improved by fusing multiple sensors. 3D-LiDAR + PointCloud Map # Expected situation # The vehicle is located in a structure-rich environment, such as an urban area Situations that can make the system unstable # The vehicle is placed in a structure-less environment, such as a rural landscape, highway, or tunnel Environmental changes have occurred since the map was created, such as snow cover or the construction/destruction of buildings. Surrounding objects are occluded The car is surrounded by objects undetectable by LiDAR, e.g., glass windows, reflections, or absorption (dark objects) The environment contains laser beams at the same frequency as the car's LiDAR sensor(s) Functionality # The system can estimate the vehicle location on the point cloud map with the error of ~10cm. The system is operable at night. 3D-LiDAR or Camera + Vector Map # Expected situation # Road with clear white lines and loose curvatures, such as a highway or an ordinary local road. Situations that can make the system unstable # White lines are scratchy or covered by rain or snow Tight curvature such as intersections Large reflection change of the road surface caused by rain or paint Functionalities # Correct vehicle positions along the lateral direction. Pose correction along the longitudinal can be inaccurate, but can be resolved by fusing with GNSS . GNSS # Expected situation # The vehicle is placed in an open environment with few to no surrounding objects, such as a rural landscape. Situation that can make the system unstable # GNSS signals are blocked by surrounding objects, e.g., tunnels or buildings. Functionality # The system can estimate vehicle position in the world coordinate within an error of ~10m. With a RKT- GNSS (Real Time Kinematic Global Navigation Satellite System) attached, the accuracy can be improved to ~10cm. A system with this configuration can work without environment maps (both point cloud and vector map types). Camera (Visual Odometry, Visual SLAM ) # Expected situation # The vehicle is placed in an environment with rich visual features, such as an urban area. Situations that can make the system unstable # The vehicle is placed in a texture-less environment. The vehicle is surrounded by other objects. The camera observes significant illumination changes, such as those caused by sunshine, headlights from other vehicles or when approaching the exit of a tunnel. The vehicle is placed in a dark environment. Functionality # The system can estimate odometry by tracking visual features. Wheel speed sensor # Expected situation # The vehicle is running on a flat and smooth road. Situations that can make the system unstable # The vehicle is running on a slippery or bumpy road, which can cause incorrect observations of wheel speed. Functionality # The system can acquire the vehicle velocity and estimate distance traveled. IMU # Expected environments # Flat, smooth roads Situations that can make the system unstable # IMUs have a bias 1 that is dependent on the surrounding temperature, and can cause incorrect sensor observation or odometry drift. Functionality # The system can observe acceleration and angular velocity. By integrating these observations, the system can estimate the local pose change and realize dead-reckoning Geomagnetic sensor # Expected situation # The vehicle is placed in an environment with low magnetic noise Situations that can make the system unstable # The vehicle is placed in an environment with high magnetic noise, such as one containing buildings or structures with reinforced steel or other materials that generate electromagnetic waves. Functionality # The system can estimate the vehicle's direction in the world coordinate system. Magnetic markers # Expected situation # The car is placed in an environment with magnetic markers installed. Situations where the system becomes unstable # The markers are not maintained. Functionality # Vehicle location can be obtained on the world coordinate by detecting the magnetic markers. The system can work even if the road is covered with snow. 3. Requirements # By implementing different modules, various sensor configurations and algorithms can be used. The localization system can start pose estimation from an ambiguous initial location. The system can produce a reliable initial location estimation. The system can manage the state of the initial location estimation (uninitialized, initializable, or non-initializable) and can report to the error monitor. 4. Architecture # Abstract # Two architectures are defined, \"Required\" and \"Recommended\". However, the \"Required\" architecture only contains the inputs and outputs necessary to accept various localization algorithms. To improve the reusability of each module, the required components are defined in the \"Recommended\" architecture section along with a more detailed explanation. Required Architecture # Input # Sensor message e.g., LiDAR, camera, GNSS , IMU , CAN Bus, etc. Data types should be ROS primitives for reusability Map data e.g., point cloud map, lanelet2 map, feature map, etc. The map format should be chosen based on use case and sensor configuration Note that map data is not required for some specific cases (e.g., GNSS -only localization) tf, static_tf map frame base_link frame Output # Pose with covariance stamped Vehicle pose, covariance, and timestamp on the map coordinate 50Hz~ frequency (depending on the requirements of the Planning and Control components) Twist with covariance stamped Vehicle velocity, covariance, and timestamp on the base_link coordinate 50Hz~ frequency Accel with covariance stamped Acceleration, covariance, and timestamp on the base_link coordinate 50Hz~ frequency Diagnostics Diagnostics information that indicates if the localization module works properly tf tf of map to base_link Recommended Architecture # Pose Estimator # Estimates the vehicle pose on the map coordinate by matching external sensor observation to the map Provides the obtained pose and its covariance to PoseTwistFusionFilter Twist-Accel Estimator # Produces the vehicle velocity, angular velocity, acceleration, angular acceleration, and their covariances It is possible to create a single module for both twist and acceleration or to create two separate modules - the choice of architecture is up to the developer The twist estimator produces velocity and angular velocity from internal sensor observation The accel estimator produces acceleration and angular acceleration from internal sensor observations Kinematics Fusion Filter # Produces the likeliest pose, velocity, acceleration, and their covariances, computed by fusing two kinds of information: The pose obtained from the pose estimator. The velocity and acceleration obtained from the twist-accel estimator Produces tf of map to base_link according to the pose estimation result Localization Diagnostics # Monitors and guarantees the stability and reliability of pose estimation by fusing information obtained from multiple localization modules Reports error status to the error monitor TF tree # frame meaning earth ECEF (Earth Centered Earth Fixed\uff09 map Origin of the map coordinate (ex. MGRS origin) viewer User-defined frame for rviz base_link Reference pose of the ego-vehicle (projection of the rear-axle center onto the ground surface) sensor Reference pose of each sensor Developers can optionally add other frames such as odom or base_footprint as long as the tf structure above is maintained. The localization module's ideal functionality # The localization module should provide pose, velocity, and acceleration for control, planning, and perception. Latency and stagger should be sufficiently small or adjustable such that the estimated values can be used for control within the ODD (Operational Design Domain). The localization module should produce the pose on a fixed coordinate frame. Sensors should be independent of each other so that they can be easily replaced. The localization module should provide a status indicating whether or not the autonomous vehicle can operate with the self-contained function or map information. Tools or manuals should describe how to set proper parameters for the localization module Valid calibration parameters should be provided to align different frame or pose coordinates and sensor timestamps. KPI # To maintain sufficient pose estimation performance for safe operation, the following metrics are considered: Safety The distance traveled within the ODD where pose estimation met the required accuracy, divided by the overall distance traveled within the ODD , as a percentage. The anomaly detection rate for situations where the localization module cannot estimate pose within the ODD The accuracy of detecting when the vehicle goes outside of the ODD , as a percentage. Computational load Latency 5. Interface and Data Structure # 6. Concerns, Assumptions, and Limitations # Prerequisites of sensors and inputs # Sensor prerequisites # Input data is not defective. Internal sensor observation such as IMU continuously keeps the proper frequency. Input data has correct and exact time stamps. Estimated poses can be inaccurate or unstable if the timestamps are not exact. Sensors are correctly mounted with exact positioning and accessible from TF. If the sensor positions are inaccurate, estimation results may be incorrect or unstable. A sensor calibration framework is required to properly obtain the sensor positions. Map prerequisites # Sufficient information is contained within the map. Pose estimation might be unstable if there is insufficient information in the map. A testing framework is necessary to check if the map has adequate information for pose estimation. Map does not differ greatly from the actual environment. Pose estimation might be unstable if the actual environment has different objects from the map. Maps need updates according to new objects and seasonal changes. Maps must be aligned to a uniform coordinate, or an alignment framework is in place. If multiple maps with different coordinate systems are used, the misalignment between them can affect the localization performance. Computational resources # Sufficient computational resources should be provided to maintain accuracy and computation speed. For more details about bias, refer to the VectorNav IMU specifications page . \u21a9","title":"Index"},{"location":"design/autoware-architecture/localization/#abstract","text":"","title":"Abstract"},{"location":"design/autoware-architecture/localization/#1-requirements","text":"Localization aims to estimate vehicle pose, velocity, and acceleration. Goals: Propose a system that can estimate vehicle pose, velocity, and acceleration for as long as possible. Propose a system that can diagnose the stability of estimation and send a warning message to the error-monitoring system if the estimation result is unreliable. Design a vehicle localization function that can work with various sensor configurations. Non-goals: This design document does not aim to develop a localization system that is infallible in all environments works outside of the pre-defined ODD (Operational Design Domain) has better performance than is required for autonomous driving","title":"1. Requirements"},{"location":"design/autoware-architecture/localization/#2-sensor-configuration-examples","text":"This section shows example sensor configurations and their expected performances. Each sensor has its own advantages and disadvantages, but overall performance can be improved by fusing multiple sensors.","title":"2. Sensor Configuration Examples"},{"location":"design/autoware-architecture/localization/#3d-lidar-pointcloud-map","text":"","title":"3D-LiDAR + PointCloud Map"},{"location":"design/autoware-architecture/localization/#3d-lidar-or-camera-vector-map","text":"","title":"3D-LiDAR or Camera + Vector Map"},{"location":"design/autoware-architecture/localization/#gnss","text":"","title":"GNSS"},{"location":"design/autoware-architecture/localization/#camera-visual-odometry-visual-slam","text":"","title":"Camera (Visual Odometry, Visual SLAM)"},{"location":"design/autoware-architecture/localization/#wheel-speed-sensor","text":"","title":"Wheel speed sensor"},{"location":"design/autoware-architecture/localization/#imu","text":"","title":"IMU"},{"location":"design/autoware-architecture/localization/#geomagnetic-sensor","text":"","title":"Geomagnetic sensor"},{"location":"design/autoware-architecture/localization/#magnetic-markers","text":"","title":"Magnetic markers"},{"location":"design/autoware-architecture/localization/#3-requirements","text":"By implementing different modules, various sensor configurations and algorithms can be used. The localization system can start pose estimation from an ambiguous initial location. The system can produce a reliable initial location estimation. The system can manage the state of the initial location estimation (uninitialized, initializable, or non-initializable) and can report to the error monitor.","title":"3. Requirements"},{"location":"design/autoware-architecture/localization/#4-architecture","text":"","title":"4. Architecture"},{"location":"design/autoware-architecture/localization/#abstract_1","text":"Two architectures are defined, \"Required\" and \"Recommended\". However, the \"Required\" architecture only contains the inputs and outputs necessary to accept various localization algorithms. To improve the reusability of each module, the required components are defined in the \"Recommended\" architecture section along with a more detailed explanation.","title":"Abstract"},{"location":"design/autoware-architecture/localization/#required-architecture","text":"","title":"Required Architecture"},{"location":"design/autoware-architecture/localization/#recommended-architecture","text":"","title":"Recommended Architecture"},{"location":"design/autoware-architecture/localization/#the-localization-modules-ideal-functionality","text":"The localization module should provide pose, velocity, and acceleration for control, planning, and perception. Latency and stagger should be sufficiently small or adjustable such that the estimated values can be used for control within the ODD (Operational Design Domain). The localization module should produce the pose on a fixed coordinate frame. Sensors should be independent of each other so that they can be easily replaced. The localization module should provide a status indicating whether or not the autonomous vehicle can operate with the self-contained function or map information. Tools or manuals should describe how to set proper parameters for the localization module Valid calibration parameters should be provided to align different frame or pose coordinates and sensor timestamps.","title":"The localization module's ideal functionality"},{"location":"design/autoware-architecture/localization/#kpi","text":"To maintain sufficient pose estimation performance for safe operation, the following metrics are considered: Safety The distance traveled within the ODD where pose estimation met the required accuracy, divided by the overall distance traveled within the ODD , as a percentage. The anomaly detection rate for situations where the localization module cannot estimate pose within the ODD The accuracy of detecting when the vehicle goes outside of the ODD , as a percentage. Computational load Latency","title":"KPI"},{"location":"design/autoware-architecture/localization/#5-interface-and-data-structure","text":"","title":"5. Interface and Data Structure"},{"location":"design/autoware-architecture/localization/#6-concerns-assumptions-and-limitations","text":"","title":"6. Concerns, Assumptions, and Limitations"},{"location":"design/autoware-architecture/localization/#prerequisites-of-sensors-and-inputs","text":"","title":"Prerequisites of sensors and inputs"},{"location":"design/autoware-architecture/map/","text":"Map component design # Warning Under Construction","title":"Map component design"},{"location":"design/autoware-architecture/map/#map-component-design","text":"Warning Under Construction","title":"Map component design"},{"location":"design/autoware-architecture/node-diagram/","text":"Node diagram # This page depicts the node diagram designs for Autoware Core/Universe architecture. Autoware Core # TBD. Autoware Universe # Note that the diagram is for reference. We are planning to update this diagram every release and may have old information between the releases. If you wish to check the latest node diagram use rqt_graph after launching the Autoware. Open in draw.io for fullscreen","title":"Node diagram"},{"location":"design/autoware-architecture/node-diagram/#node-diagram","text":"This page depicts the node diagram designs for Autoware Core/Universe architecture.","title":"Node diagram"},{"location":"design/autoware-architecture/node-diagram/#autoware-core","text":"TBD.","title":"Autoware Core"},{"location":"design/autoware-architecture/node-diagram/#autoware-universe","text":"Note that the diagram is for reference. We are planning to update this diagram every release and may have old information between the releases. If you wish to check the latest node diagram use rqt_graph after launching the Autoware. Open in draw.io for fullscreen","title":"Autoware Universe"},{"location":"design/autoware-architecture/perception/","text":"Perception component design # Warning Under Construction","title":"Perception component design"},{"location":"design/autoware-architecture/perception/#perception-component-design","text":"Warning Under Construction","title":"Perception component design"},{"location":"design/autoware-architecture/planning/","text":"Planning component design # Overview # Planning stack acts as the \u201cbrain\u201d of autonomous driving. It uses all the results from Localization, Perception, and Map stacks to decide its maneuver and gives final trajectory to Control stack. Role # These are high-level roles of Planning stack: Calculates route that navigates to desired goal Plans trajectory to follow the route Make sure that vehicle does not collide with obstacles, including pedestrians and other vehicles Make sure that the vehicle follows traffic rules during the navigation. This includes following traffic light, stopping at stoplines, stopping at crosswalks, etc. Plan sequences of trajectories that is feasible for the vehicle. (e.g. no sharp turns that is kinematically impossible) Input # The table below summarizes the overall input into Planning stack: Input Topic Name(Data Type) Explanation Vehicle Pose /tf (map->base_link) ( tf::tfMessage ) Planning requires vehicle pose in map frame, which is the frame where all planning takes place. Vehicle Kinematics /localization/kinematic_state ( nav_msgs/msg/Odometry ) This includes vehicle's pose and velocity information. It is used to predict future pose on trajectory to detect collision with other objects. Map data /map/vector_map ( autoware_auto_mapping_msgs/msg/HADMapBin ) This includes all static information about the environment, such as: Lane connection information used for route planning from starting position to goal position Lane geometry to generate reference path used to calculate trajectory All information related to traffic rules Detected Object Information /perception/object_recognition/objects ( autoware_auto_perception_msgs/msg/PredictedObjects ) This includes information that cannot be known beforehand such as pedestrians and other vehicles. Planning stack will plan maneuvers to avoid collision with such objects. Detected Obstacle Information /perception/obstacle_segmentation/pointcloud ( sensor_msgs/msg/PointCloud2 ) This includes information on the location of obstacles. This is more primitive information and is used for emergency stops, etc. Occupancy Map Information /perception/occupancy_grid_map/map ( nav_msgs/msg/OccupancyGrid ) This includes information that cannot be known beforehand such as pedestrians and other vehicles. Planning stack will plan maneuvers to avoid collision with such objects. TrafficLight recognition result /perception/traffic_light_recognition/traffic_signals ( autoware_auto_perception_msgs/msg/TrafficSignalArray ) This is the real time information about the state of each traffic light. Planning stack will extract the one that is relevant to planned path and use it to decide whether to stop at intersections. Goal position /planning/mission_planning/goal ( geometry_msgs::PoseStamped ) This is the final pose that Planning stack will try to achieve. Check point position /planning/mission_planning/check_point ( geometry_msgs::PoseStamped ) This is the midpoint that Planning will try to go at on the way to the destination. This is used when calculating the route. Output # The table below summarizes the final output from Planning stack: Output Topic(Data Type) Explanation Trajectory /planning/trajectory ( autoware_auto_planning_msgs/msg/Trajectory ) This is the sequence of pose, twist and acceleration that Control stack must follow. This must be smooth, and kinematically possible to follow by the Control stack. By default, the trajectory is 10 seconds long at 0.1 second resolution. Turn Signal /planning/turn_indicators_cmd ( autoware_auto_vehicle_msgs/msg/TurnIndicatorsCommand ) This is the output to control turn signals of the vehicle. Planning stack will make sure that turn signal will be turned on according to planned maneuver. Hazard Signal /planning/hazard_lights_cmd ( autoware_auto_vehicle_msgs/msg/HazardLightsCommand ) This is the output to control hazard signals of the vehicle. Planning stack will make sure that hazard signal will be turned on according to planned maneuver. Implementation # The implementation of the planning module in the latest version is shown as below. For more details, please refer to the design documents in each package. mission_planner : calculate route from start to goal based on the map information. behavior_path_planner : calculates path and drivable area based on the traffic rules. lane_following lane_change avoidance pull_over pull_out side_shift behavior_velocity_planner : calculates max speed based on the traffic rules. detection_area blind_spot cross_walk stop_line traffic_light intersection no_stopping_area virtual_traffic_light occlusion_spot run_out obstacle_avoidance_planner : calculate path shape under obstacle and drivable area constraints surround_obstacle_checker : keeps the vehicle being stopped when there are obstacles around the ego-vehicle. It works only when the vehicle is stopped. obstacle_stop_planner : When there are obstacles on or near the trajectory, it calculates the maximum velocity of the trajectory points depending on the situation: stopping, slowing down, or adaptive cruise (following the car). stop slow_down adaptive_cruise costmap_generator : generates a costmap for path generation from dynamic objects and lane information. freespace_planner : calculates trajectory considering the feasibility (e.g. curvature) for the freespace scene. Algorithms are described here . scenario_selector : chooses a trajectory according to the current scenario. external_velocity_limit_selector : takes an appropriate velocity limit from multiple candidates. motion_velocity_smoother : calculates final velocity considering velocity, acceleration, and jerk constraints. Supported Functions # Notation # [1] To support the self-crossing road and overlapped road in the opposite direction, each planning module has to meet the specifications Currently, the supported modules are as follows. lane_following (in behavior_path_planner) detection_area (in behavior_velocity_planner) stop_line (in behavior_velocity_planner) virtual_traffic_light (in behavior_velocity_planner) obstacle_avoidance_planner obstacle_stop_planner motion_velocity_smoother","title":"Planning component design"},{"location":"design/autoware-architecture/planning/#planning-component-design","text":"","title":"Planning component design"},{"location":"design/autoware-architecture/planning/#overview","text":"Planning stack acts as the \u201cbrain\u201d of autonomous driving. It uses all the results from Localization, Perception, and Map stacks to decide its maneuver and gives final trajectory to Control stack.","title":"Overview"},{"location":"design/autoware-architecture/planning/#role","text":"These are high-level roles of Planning stack: Calculates route that navigates to desired goal Plans trajectory to follow the route Make sure that vehicle does not collide with obstacles, including pedestrians and other vehicles Make sure that the vehicle follows traffic rules during the navigation. This includes following traffic light, stopping at stoplines, stopping at crosswalks, etc. Plan sequences of trajectories that is feasible for the vehicle. (e.g. no sharp turns that is kinematically impossible)","title":"Role"},{"location":"design/autoware-architecture/planning/#input","text":"The table below summarizes the overall input into Planning stack: Input Topic Name(Data Type) Explanation Vehicle Pose /tf (map->base_link) ( tf::tfMessage ) Planning requires vehicle pose in map frame, which is the frame where all planning takes place. Vehicle Kinematics /localization/kinematic_state ( nav_msgs/msg/Odometry ) This includes vehicle's pose and velocity information. It is used to predict future pose on trajectory to detect collision with other objects. Map data /map/vector_map ( autoware_auto_mapping_msgs/msg/HADMapBin ) This includes all static information about the environment, such as: Lane connection information used for route planning from starting position to goal position Lane geometry to generate reference path used to calculate trajectory All information related to traffic rules Detected Object Information /perception/object_recognition/objects ( autoware_auto_perception_msgs/msg/PredictedObjects ) This includes information that cannot be known beforehand such as pedestrians and other vehicles. Planning stack will plan maneuvers to avoid collision with such objects. Detected Obstacle Information /perception/obstacle_segmentation/pointcloud ( sensor_msgs/msg/PointCloud2 ) This includes information on the location of obstacles. This is more primitive information and is used for emergency stops, etc. Occupancy Map Information /perception/occupancy_grid_map/map ( nav_msgs/msg/OccupancyGrid ) This includes information that cannot be known beforehand such as pedestrians and other vehicles. Planning stack will plan maneuvers to avoid collision with such objects. TrafficLight recognition result /perception/traffic_light_recognition/traffic_signals ( autoware_auto_perception_msgs/msg/TrafficSignalArray ) This is the real time information about the state of each traffic light. Planning stack will extract the one that is relevant to planned path and use it to decide whether to stop at intersections. Goal position /planning/mission_planning/goal ( geometry_msgs::PoseStamped ) This is the final pose that Planning stack will try to achieve. Check point position /planning/mission_planning/check_point ( geometry_msgs::PoseStamped ) This is the midpoint that Planning will try to go at on the way to the destination. This is used when calculating the route.","title":"Input"},{"location":"design/autoware-architecture/planning/#output","text":"The table below summarizes the final output from Planning stack: Output Topic(Data Type) Explanation Trajectory /planning/trajectory ( autoware_auto_planning_msgs/msg/Trajectory ) This is the sequence of pose, twist and acceleration that Control stack must follow. This must be smooth, and kinematically possible to follow by the Control stack. By default, the trajectory is 10 seconds long at 0.1 second resolution. Turn Signal /planning/turn_indicators_cmd ( autoware_auto_vehicle_msgs/msg/TurnIndicatorsCommand ) This is the output to control turn signals of the vehicle. Planning stack will make sure that turn signal will be turned on according to planned maneuver. Hazard Signal /planning/hazard_lights_cmd ( autoware_auto_vehicle_msgs/msg/HazardLightsCommand ) This is the output to control hazard signals of the vehicle. Planning stack will make sure that hazard signal will be turned on according to planned maneuver.","title":"Output"},{"location":"design/autoware-architecture/planning/#implementation","text":"The implementation of the planning module in the latest version is shown as below. For more details, please refer to the design documents in each package. mission_planner : calculate route from start to goal based on the map information. behavior_path_planner : calculates path and drivable area based on the traffic rules. lane_following lane_change avoidance pull_over pull_out side_shift behavior_velocity_planner : calculates max speed based on the traffic rules. detection_area blind_spot cross_walk stop_line traffic_light intersection no_stopping_area virtual_traffic_light occlusion_spot run_out obstacle_avoidance_planner : calculate path shape under obstacle and drivable area constraints surround_obstacle_checker : keeps the vehicle being stopped when there are obstacles around the ego-vehicle. It works only when the vehicle is stopped. obstacle_stop_planner : When there are obstacles on or near the trajectory, it calculates the maximum velocity of the trajectory points depending on the situation: stopping, slowing down, or adaptive cruise (following the car). stop slow_down adaptive_cruise costmap_generator : generates a costmap for path generation from dynamic objects and lane information. freespace_planner : calculates trajectory considering the feasibility (e.g. curvature) for the freespace scene. Algorithms are described here . scenario_selector : chooses a trajectory according to the current scenario. external_velocity_limit_selector : takes an appropriate velocity limit from multiple candidates. motion_velocity_smoother : calculates final velocity considering velocity, acceleration, and jerk constraints.","title":"Implementation"},{"location":"design/autoware-architecture/planning/#supported-functions","text":"","title":"Supported Functions"},{"location":"design/autoware-architecture/planning/#notation","text":"[1] To support the self-crossing road and overlapped road in the opposite direction, each planning module has to meet the specifications Currently, the supported modules are as follows. lane_following (in behavior_path_planner) detection_area (in behavior_velocity_planner) stop_line (in behavior_velocity_planner) virtual_traffic_light (in behavior_velocity_planner) obstacle_avoidance_planner obstacle_stop_planner motion_velocity_smoother","title":"Notation"},{"location":"design/autoware-architecture/sensing/","text":"Sensing component design # Warning Under Construction","title":"Sensing component design"},{"location":"design/autoware-architecture/sensing/#sensing-component-design","text":"Warning Under Construction","title":"Sensing component design"},{"location":"design/autoware-architecture/vehicle/","text":"Vehicle Interface design # Abstract # The Vehicle Interface component provides an interface between Autoware and a vehicle that passes control signals to the vehicle\u2019s drive-by-wire system and receives vehicle information that is passed back to Autoware. 1. Requirements # Goals: The Vehicle Interface component converts Autoware commands to a vehicle-specific format and converts vehicle status in a vehicle-specific format to Autoware messages. The interface between Autoware and the Vehicle component is abstracted and independent of hardware. The interface is extensible such that additional vehicle-specific commands can be easily added. For example, headlight control. Non-goals: Accuracy of responses from the vehicle will not be defined, but example accuracy requirements from reference designs are provided as examples. Response speed will not be defined. 2. Architecture # The Vehicle Interface component consists of the following components: A Raw Vehicle Command Converter component that will pass through vehicle commands from the Control component if velocity/acceleration control is supported by the drive-by-wire system. Otherwise, the Control commands will be modified according to the control method (eg: converting a target acceleration from the Control component to a vehicle specific accel/brake pedal value through the use of an acceleration map) A Vehicle Interface component (vehicle specific) that acts as an interface between Autoware and a vehicle to communicate control signals and to obtain information about the vehicle (steer output, tyre angle etc) Each component contains static nodes of Autoware, while each module can be dynamically loaded and unloaded (corresponding to C++ classes). The mechanism of the Vehicle Interface component is depicted by the following figures: 3. Features # The Vehicle Interface component can provide the following features in functionality and capability: Basic functions Converting Autoware control commands to vehicle specific command Converting vehicle specific status information (velocity, steering) to Autoware status message Diagnostics List available features Provide a warning if the Control component tries to use a feature that is not available in the Vehicle Interface component Additional functionality and capability features may be added, depending on the vehicle hardware. Some example features are listed below: Safety features Disengage autonomous driving via manual intervention. This can be done through the use of an emergency disengage button, or by a safety driver manually turning the steering wheel or pressing the brake Optional controls Turn indicator Handbrake Headlights Hazard lights Doors Horn Wipers 4. Interface and Data Structure # The interface of the Vehicle Interface component for other components running in the same process space to access the functionality and capability of the Vehicle Interface component is defined as follows. From Control Actuation Command target acceleration, braking, and steering angle From Planning Vehicle Specific Commands (optional and a separate message for each type) Shift Door Wiper etc From the vehicle Vehicle status messages Vehicle-specific format messages for conversion into Autoware-specific format messages Velocity status Steering status (optional) Shift status (optional) Turn signal status (optional) Actuation status (optional) The output interface of the Vehicle Interface component: Vehicle control messages to the vehicle Control signals to drive the vehicle Depends on the vehicle type/protocol, but should include steering and velocity commands at a minimum Vehicle status messages to Autoware Actuation Status Acceleration, brake, steering status Vehicle odometry (output to Localization) Vehicle twist information Control mode Information about whether the vehicle is under autonomous control or manual control Shift status (optional) Vehicle shift status Turn signal status (optional) Vehicle turn signal status The data structure for the internal representation of semantics for the objects and trajectories used in the Vehicle Interface component is defined as follows: 5. Concerns, Assumptions, and Limitations # Concerns Architectural trade-offs and scalability Assumptions - Limitations 6. Examples of accuracy requirements by ODD #","title":"Vehicle Interface design"},{"location":"design/autoware-architecture/vehicle/#vehicle-interface-design","text":"","title":"Vehicle Interface design"},{"location":"design/autoware-architecture/vehicle/#abstract","text":"The Vehicle Interface component provides an interface between Autoware and a vehicle that passes control signals to the vehicle\u2019s drive-by-wire system and receives vehicle information that is passed back to Autoware.","title":"Abstract"},{"location":"design/autoware-architecture/vehicle/#1-requirements","text":"Goals: The Vehicle Interface component converts Autoware commands to a vehicle-specific format and converts vehicle status in a vehicle-specific format to Autoware messages. The interface between Autoware and the Vehicle component is abstracted and independent of hardware. The interface is extensible such that additional vehicle-specific commands can be easily added. For example, headlight control. Non-goals: Accuracy of responses from the vehicle will not be defined, but example accuracy requirements from reference designs are provided as examples. Response speed will not be defined.","title":"1. Requirements"},{"location":"design/autoware-architecture/vehicle/#2-architecture","text":"The Vehicle Interface component consists of the following components: A Raw Vehicle Command Converter component that will pass through vehicle commands from the Control component if velocity/acceleration control is supported by the drive-by-wire system. Otherwise, the Control commands will be modified according to the control method (eg: converting a target acceleration from the Control component to a vehicle specific accel/brake pedal value through the use of an acceleration map) A Vehicle Interface component (vehicle specific) that acts as an interface between Autoware and a vehicle to communicate control signals and to obtain information about the vehicle (steer output, tyre angle etc) Each component contains static nodes of Autoware, while each module can be dynamically loaded and unloaded (corresponding to C++ classes). The mechanism of the Vehicle Interface component is depicted by the following figures:","title":"2. Architecture"},{"location":"design/autoware-architecture/vehicle/#3-features","text":"The Vehicle Interface component can provide the following features in functionality and capability: Basic functions Converting Autoware control commands to vehicle specific command Converting vehicle specific status information (velocity, steering) to Autoware status message Diagnostics List available features Provide a warning if the Control component tries to use a feature that is not available in the Vehicle Interface component Additional functionality and capability features may be added, depending on the vehicle hardware. Some example features are listed below: Safety features Disengage autonomous driving via manual intervention. This can be done through the use of an emergency disengage button, or by a safety driver manually turning the steering wheel or pressing the brake Optional controls Turn indicator Handbrake Headlights Hazard lights Doors Horn Wipers","title":"3. Features"},{"location":"design/autoware-architecture/vehicle/#4-interface-and-data-structure","text":"The interface of the Vehicle Interface component for other components running in the same process space to access the functionality and capability of the Vehicle Interface component is defined as follows. From Control Actuation Command target acceleration, braking, and steering angle From Planning Vehicle Specific Commands (optional and a separate message for each type) Shift Door Wiper etc From the vehicle Vehicle status messages Vehicle-specific format messages for conversion into Autoware-specific format messages Velocity status Steering status (optional) Shift status (optional) Turn signal status (optional) Actuation status (optional) The output interface of the Vehicle Interface component: Vehicle control messages to the vehicle Control signals to drive the vehicle Depends on the vehicle type/protocol, but should include steering and velocity commands at a minimum Vehicle status messages to Autoware Actuation Status Acceleration, brake, steering status Vehicle odometry (output to Localization) Vehicle twist information Control mode Information about whether the vehicle is under autonomous control or manual control Shift status (optional) Vehicle shift status Turn signal status (optional) Vehicle turn signal status The data structure for the internal representation of semantics for the objects and trajectories used in the Vehicle Interface component is defined as follows:","title":"4. Interface and Data Structure"},{"location":"design/autoware-architecture/vehicle/#5-concerns-assumptions-and-limitations","text":"Concerns Architectural trade-offs and scalability Assumptions - Limitations","title":"5. Concerns, Assumptions, and Limitations"},{"location":"design/autoware-architecture/vehicle/#6-examples-of-accuracy-requirements-by-odd","text":"","title":"6. Examples of accuracy requirements by ODD"},{"location":"design/autoware-concepts/","text":"Autoware concepts # Autoware is the world\u2019s first open-source software for autonomous driving systems. Autoware provides value for both The technology developers of autonomous driving systems can create new components based on Autoware. The service operators of autonomous driving systems, on the other hand, can select appropriate technology components with Autoware. This is enabled by the microautonomy architecture that modularizes its software stack into the core and universe subsystems (modules). Microautonomy architecture # Autoware uses a pipeline architecture to enable the development of autonomous driving systems. The pipeline architecture used in Autoware consists of components similar to three-layer-architecture . And they run in parallel. There are 2 main modules: the Core and the Universe. The components in these modules are designed to be extensible and reusable. And we call it microautonomy architecture. The Core module # The Core module contains basic runtimes and technology components that satisfy the basic functionality and capability of sensing, computing, and actuation required for autonomous driving systems. AWF develops and maintains the Core module with their architects and leading members through their working groups. Anyone can contribute to the Core but the PR(Pull Request) acceptance criteria is more strict compared to the Universe. The Universe module # The Universe modules are extensions to the Core module that can be provided by the technology developers to enhance the functionality and capability of sensing, computing, and actuation. AWF provides the base Universe module to extend from. A key feature of the microautonomy architecture is that the Universe modules can be contributed to by any organization and individual. That is, you can even create your Universe and make it available for the Autoware community and ecosystem. AWF is responsible for quality control of the Universe modules through their development process. As a result, there are multiple types of the Universe modules - some are verified and validated by AWF and others are not. It is up to the users of Autoware which Universe modules are selected and integrated to build their end applications. Interface design # The interface design is the most essential piece of the microautonomy architecture, which is classified into internal and external interfaces. The component interface is designed for the components in a Universe module to communicate with those in other modules, including the Core module, within Autoware internally. The AD(Autonomous Driving) API, on the other hand, is designed for the applications of Autoware to access the technology components in the Core and Universe modules of Autoware externally. Designing solid interfaces, the microautonomy architecture is made possible with AWF 's partners, and at the same time is made feasible for the partners. Challenges # A grand challenge of the microautonomy architecture is to achieve real-time capability, which guarantees all the technology components activated in the system to predictably meet timing constraints (given deadlines). In general, it is difficult, if not impossible, to tightly estimate the worst-case execution times (WCETs) of components. In addition, it is also difficult, if not impossible, to tightly estimate the end-to-end latency of components connected by a DAG. Autonomous driving systems based on the microautonomy architecture, therefore, must be designed to be fail-safe but not never-fail. We accept that the timing constraints may be violated (the given deadlines may be missed) as far as the overrun is taken into account. The overrun handlers are two-fold: (i) platform-defined and (ii) user-defined. The platform-defined handler is implemented as part of the platform by default, while the user-defined handler can overwrite it or add a new handler to the system. This is what we call \u201cfail-safe\u201d on a timely basis. Requirements and roadmap # Goals: All open-source Use case driven Real-time (predictable) framework with overrun handling Code quality","title":"Autoware concepts"},{"location":"design/autoware-concepts/#autoware-concepts","text":"Autoware is the world\u2019s first open-source software for autonomous driving systems. Autoware provides value for both The technology developers of autonomous driving systems can create new components based on Autoware. The service operators of autonomous driving systems, on the other hand, can select appropriate technology components with Autoware. This is enabled by the microautonomy architecture that modularizes its software stack into the core and universe subsystems (modules).","title":"Autoware concepts"},{"location":"design/autoware-concepts/#microautonomy-architecture","text":"Autoware uses a pipeline architecture to enable the development of autonomous driving systems. The pipeline architecture used in Autoware consists of components similar to three-layer-architecture . And they run in parallel. There are 2 main modules: the Core and the Universe. The components in these modules are designed to be extensible and reusable. And we call it microautonomy architecture.","title":"Microautonomy architecture"},{"location":"design/autoware-concepts/#the-core-module","text":"The Core module contains basic runtimes and technology components that satisfy the basic functionality and capability of sensing, computing, and actuation required for autonomous driving systems. AWF develops and maintains the Core module with their architects and leading members through their working groups. Anyone can contribute to the Core but the PR(Pull Request) acceptance criteria is more strict compared to the Universe.","title":"The Core module"},{"location":"design/autoware-concepts/#the-universe-module","text":"The Universe modules are extensions to the Core module that can be provided by the technology developers to enhance the functionality and capability of sensing, computing, and actuation. AWF provides the base Universe module to extend from. A key feature of the microautonomy architecture is that the Universe modules can be contributed to by any organization and individual. That is, you can even create your Universe and make it available for the Autoware community and ecosystem. AWF is responsible for quality control of the Universe modules through their development process. As a result, there are multiple types of the Universe modules - some are verified and validated by AWF and others are not. It is up to the users of Autoware which Universe modules are selected and integrated to build their end applications.","title":"The Universe module"},{"location":"design/autoware-concepts/#interface-design","text":"The interface design is the most essential piece of the microautonomy architecture, which is classified into internal and external interfaces. The component interface is designed for the components in a Universe module to communicate with those in other modules, including the Core module, within Autoware internally. The AD(Autonomous Driving) API, on the other hand, is designed for the applications of Autoware to access the technology components in the Core and Universe modules of Autoware externally. Designing solid interfaces, the microautonomy architecture is made possible with AWF 's partners, and at the same time is made feasible for the partners.","title":"Interface design"},{"location":"design/autoware-concepts/#challenges","text":"A grand challenge of the microautonomy architecture is to achieve real-time capability, which guarantees all the technology components activated in the system to predictably meet timing constraints (given deadlines). In general, it is difficult, if not impossible, to tightly estimate the worst-case execution times (WCETs) of components. In addition, it is also difficult, if not impossible, to tightly estimate the end-to-end latency of components connected by a DAG. Autonomous driving systems based on the microautonomy architecture, therefore, must be designed to be fail-safe but not never-fail. We accept that the timing constraints may be violated (the given deadlines may be missed) as far as the overrun is taken into account. The overrun handlers are two-fold: (i) platform-defined and (ii) user-defined. The platform-defined handler is implemented as part of the platform by default, while the user-defined handler can overwrite it or add a new handler to the system. This is what we call \u201cfail-safe\u201d on a timely basis.","title":"Challenges"},{"location":"design/autoware-concepts/#requirements-and-roadmap","text":"Goals: All open-source Use case driven Real-time (predictable) framework with overrun handling Code quality","title":"Requirements and roadmap"},{"location":"design/autoware-concepts/difference-from-ai-and-auto/","text":"How is Autoware Core/Universe different from Autoware.AI and Autoware.Auto? # Autoware is the world's first \"all-in-one\" open-source software for self-driving vehicles. Since it was first released in 2015, there have been multiple releases made with differing underlying concepts, each one aimed at improving the software. Autoware.AI # Autoware.AI is the first distribution of Autoware that was released based on ROS 1. The repository contains a variety of packages covering different aspects of autonomous driving technologies - sensing, actuation, localization, mapping, perception and planning. While it was successful in attracting many developers and contributions, it was difficult to improve Autoware.AI's capabilities for a number of reasons: A lack of concrete architecture design leading to a lot of built-up technical debt, such as tight coupling between modules and unclear module responsibility. Differing coding standards for each package, with very low test coverage. Furthermore, there was no clear definition of the conditions under which an Autoware-enabled autonomous vehicle could operate, nor of the use cases or situations supported (eg: the ability to overtake a stationary vehicle). From the lessons learned from Autoware.AI development, a different development process was taken for Autoware.Auto to develop a ROS 2 version of Autoware. Warning Autoware.AI is currently in maintenance mode and will reach end-of-life at the end of 2022. Autoware.Auto # Autoware.Auto is the second distribution of Autoware that was released based on ROS 2. As part of the transition to ROS 2, it was decided to avoid simply porting Autoware.AI from ROS 1 to ROS 2. Instead, the codebase was rewritten from scratch with proper engineering practices, including defining target use cases and ODDs (eg: Autonomous Valet Parking [ AVP ], Cargo Delivery, etc.), designing a proper architecture, writing design documents and test code. Autoware.Auto development seemed to work fine initially, but after completing the AVP and and Cargo Delivery ODD projects, we started to see the following issues: The barrier to new engineers was too high. A lot of work was required to merge new features into Autoware.Auto, and so it was difficult for researchers and students to contribute to development. As a consequence, most Autoware.Auto developers were from companies in the Autoware Foundation and so there were very few people who were able to add state-of-the-art features from research papers. Making large-scale architecture changes was too difficult. To try out experimental architecture, there was a very large overhead involved in keeping the main branch stable whilst also making sure that every change satisfied the continuous integration requirements. Autoware Core/Universe # In order to address the issues with Autoware.Auto development, the Autoware Foundation decided to create a new architecture called Autoware Core/Universe. Autoware Core carries over the original policy of Autoware.Auto to be a stable and well-tested codebase. Alongside Autoware Core is a new concept called Autoware Universe, which acts as an extension of Autoware Core with the following benefits: Users can easily replace a Core component with a Universe equivalent in order to use more advanced features, such as a new Localization or Perception algorithm. Code quality requirements for Universe are more relaxed to make it easier for new developers, students and researchers to contribute, but will still be stricter than the requirements for Autoware.AI. Any advanced features added to Universe that are useful to the wider Autoware community will be reviewed and considered for potential inclusion in the main Autoware Core codebase. This way, the primary requirement of having a stable and safe autonomous driving system can be achieved, whilst simultaneously enabling access to state-of-the-art features created by third-party contributors. For more details about the design of Autoware Core/Universe, refer to the Autoware concepts documentation page .","title":"How is Autoware Core/Universe different from Autoware.AI and Autoware.Auto?"},{"location":"design/autoware-concepts/difference-from-ai-and-auto/#how-is-autoware-coreuniverse-different-from-autowareai-and-autowareauto","text":"Autoware is the world's first \"all-in-one\" open-source software for self-driving vehicles. Since it was first released in 2015, there have been multiple releases made with differing underlying concepts, each one aimed at improving the software.","title":"How is Autoware Core/Universe different from Autoware.AI and Autoware.Auto?"},{"location":"design/autoware-concepts/difference-from-ai-and-auto/#autowareai","text":"Autoware.AI is the first distribution of Autoware that was released based on ROS 1. The repository contains a variety of packages covering different aspects of autonomous driving technologies - sensing, actuation, localization, mapping, perception and planning. While it was successful in attracting many developers and contributions, it was difficult to improve Autoware.AI's capabilities for a number of reasons: A lack of concrete architecture design leading to a lot of built-up technical debt, such as tight coupling between modules and unclear module responsibility. Differing coding standards for each package, with very low test coverage. Furthermore, there was no clear definition of the conditions under which an Autoware-enabled autonomous vehicle could operate, nor of the use cases or situations supported (eg: the ability to overtake a stationary vehicle). From the lessons learned from Autoware.AI development, a different development process was taken for Autoware.Auto to develop a ROS 2 version of Autoware. Warning Autoware.AI is currently in maintenance mode and will reach end-of-life at the end of 2022.","title":"Autoware.AI"},{"location":"design/autoware-concepts/difference-from-ai-and-auto/#autowareauto","text":"Autoware.Auto is the second distribution of Autoware that was released based on ROS 2. As part of the transition to ROS 2, it was decided to avoid simply porting Autoware.AI from ROS 1 to ROS 2. Instead, the codebase was rewritten from scratch with proper engineering practices, including defining target use cases and ODDs (eg: Autonomous Valet Parking [ AVP ], Cargo Delivery, etc.), designing a proper architecture, writing design documents and test code. Autoware.Auto development seemed to work fine initially, but after completing the AVP and and Cargo Delivery ODD projects, we started to see the following issues: The barrier to new engineers was too high. A lot of work was required to merge new features into Autoware.Auto, and so it was difficult for researchers and students to contribute to development. As a consequence, most Autoware.Auto developers were from companies in the Autoware Foundation and so there were very few people who were able to add state-of-the-art features from research papers. Making large-scale architecture changes was too difficult. To try out experimental architecture, there was a very large overhead involved in keeping the main branch stable whilst also making sure that every change satisfied the continuous integration requirements.","title":"Autoware.Auto"},{"location":"design/autoware-concepts/difference-from-ai-and-auto/#autoware-coreuniverse","text":"In order to address the issues with Autoware.Auto development, the Autoware Foundation decided to create a new architecture called Autoware Core/Universe. Autoware Core carries over the original policy of Autoware.Auto to be a stable and well-tested codebase. Alongside Autoware Core is a new concept called Autoware Universe, which acts as an extension of Autoware Core with the following benefits: Users can easily replace a Core component with a Universe equivalent in order to use more advanced features, such as a new Localization or Perception algorithm. Code quality requirements for Universe are more relaxed to make it easier for new developers, students and researchers to contribute, but will still be stricter than the requirements for Autoware.AI. Any advanced features added to Universe that are useful to the wider Autoware community will be reviewed and considered for potential inclusion in the main Autoware Core codebase. This way, the primary requirement of having a stable and safe autonomous driving system can be achieved, whilst simultaneously enabling access to state-of-the-art features created by third-party contributors. For more details about the design of Autoware Core/Universe, refer to the Autoware concepts documentation page .","title":"Autoware Core/Universe"},{"location":"design/autoware-interfaces/","text":"Autoware interface design # Abstract # Autoware defines three categories of interfaces. The first one is Autoware AD API for operating the vehicle from outside the autonomous driving system such as the Fleet Management System ( FMS ) and Human Machine Interface ( HMI ) for operators or passengers. The second one is Autoware component interface for components to communicate with each other. The last one is the local interface used inside the component. Concept # Applications can operate multiple and various vehicles in a common way. Applications are not affected by version updates and implementation changes. Developers only need to know the interface to add new features and hardware. Requirements # Goals: AD API provides functionality to create the following applications: Drive the vehicle on the route or drive to the requested positions in order. Operate vehicle behavior such as starting and stopping. Display or announce the vehicle status to operators, passengers, and people around. Control vehicle devices such as doors. Monitor the vehicle or drive it manually. AD API provides stable and long-term specifications. This enables unified access to all vehicles. AD API hides differences in version and implementation and absorbs the impact of changes. AD API has a default implementation and can be applied to some simple ODDs with options. The AD API implementation is extensible with the third-party components as long as it meets the specifications. The component interface provides stable and medium-term specifications. This makes it easier to add components. The component interface clarifies the public and private parts of a component and improves maintainability. The component interface is extensible with the third-party design to improve the sub-components' reusability. Non-goals: AD API does not cover security. Use it with other reliable methods. The component interface is just a specification, it does not include an implementation. Architecture # The components of Autoware are connected via the component interface. Each component uses the interface to provide functionality and to access other components. AD API implementation is also a component. Since the functional elements required for AD API are defined as the component interface, other components do not need to consider AD API directly. Tools for evaluation and debugging, such as simulators, access both AD API and the component interface. The component interface has a hierarchical specification. The top-level architecture consists of some components. Each component has some options of the next-level architecture. Developers select one of them when implementing the component. The simplest next-level architecture is monolithic. This is an all-in-one and black box implementation, and is suitable for small group development, prototyping, and very complex functions. Others are arbitrary architecture consists of sub-components and have advantages for large group development. A sub-component can be combined with others that adopt the same architecture. Third parties can define and publish their own architecture and interface for open source development. It is desirable to propose them for standardization if they are sufficiently evaluated. Features # Communication methods # As shown in the table below, interfaces are classified into four communication methods to define their behavior. Function Call is a request-response communication and is used for processing that requires immediate results. The others are publish-subscribe communication. Notification is used to process data that changes with some event, typically a callback. Streams handle continuously changing data. Reliable Stream expects all data to arrive without loss, Realtime Stream expects the latest data to arrive with low delay. Communication Method ROS Implementation Optional Implementation Function Call Service HTTP Notification Topic (reliable, transient_local) MQTT (QoS=2, retain) Reliable Stream Topic (reliable, volatile) MQTT (QoS=2) Realtime Stream Topic (best_effort, volatile) MQTT (QoS=0) These methods are provided as services or topics of ROS since Autoware is developed using ROS and mainly communicates with its packages. On the other hand, FMS and HMI are often implemented without ROS , Autoware is also expected to communicate with applications that do not use ROS . It is wasteful for each of these applications to have an adapter for Autoware, and a more suitable means of communication is required. HTTP and MQTT are suggested as additional options because these protocols are widely used and can substitute the behavior of services and topics. In that case, text formats such as JSON where field names are repeated in an array of objects, are inefficient and it is necessary to consider the serialization. Naming convention # The name of the interface must be /<component name>/api/<interface name> , where <component name> is the name of the component. For an AD API component, omit this part and start with /api . The <interface name> is an arbitrary string separated by slashes. Note that this rule causes a restriction that the namespace api must not be used as a name other than AD API and the component interface. The following are examples of correct interface names for AD API and the component interface: /api/autoware/state /api/autoware/engage /planning/api/route/set /vehicle/api/status The following are examples of incorrect interface names for AD API and the component interface: /ad_api/autoware/state /autoware/engage /planning/route/set/api /vehicle/my_api/status Logging # It is recommended to log the interface for analysis of vehicle behavior. If logging is needed, rosbag is available for topics, and use logger in rclcpp or rclpy for services. Typically, create a wrapper for service and client classes that logs when a service is called. Restrictions # For each API, consider the restrictions such as following and describe them if necessary. Services: response time pre-condition post-condition execution order concurrent execution Topics: recommended delay range maximum delay recommended frequency range minimum frequency default frequency Data structure # Data type definition # Do not share the types in AD API unless they are obviously the same to avoid changes in one API affecting another. Also, implementation-dependent types, including the component interface, should not be used in AD API for the same reason. Use the type in AD API in implementation, or create the same type and copy the data to convert the type. Constants and enumeration # Since ROS don't support enumeration, use constants instead. The default value of type such as zero and empty string should not be used to detect that a variable is unassigned. Alternatively, assign it a dedicated name to indicate that it is undefined. If one type has multiple enumerations, comment on the correspondence between constants and variables. Assign unique values to all constants so that it can be distinguished from other enumerations. Do not use enumeration values directly, as assignments are subject to change when the version is updated. Time stamp # Clarify what the timestamp indicates. for example, send time, measurement time, update time, etc. Consider having multiple timestamps if necessary. Use std_msgs/msg/Header when using ROS transform. Also consider whether the header is common to all data, independent for each data, or additional timestamp is required. Request header # Currently, there is no required header. Response status # The interfaces whose communication method is Function Call use a common response status to unify the error format. These interfaces should include a variable of ResponseStatus with the name status in the response. See autoware_adapi_v1_msgs/msg/ResponseStatus for details. Concerns, assumptions and limitations # The applications use the version information provided by AD API to check compatibility. Unknown versions are also treated as available as long as the major versions match (excluding major version 0). Compatibility between AD API and the component interface is assumed to be maintained by the version management system. If an unintended behavior of AD API is detected, the application should take appropriate action. Autoware tries to keep working as long as possible, but it is not guaranteed to be safe. Safety should be considered for the entire system, including the applications.","title":"Autoware interface design"},{"location":"design/autoware-interfaces/#autoware-interface-design","text":"","title":"Autoware interface design"},{"location":"design/autoware-interfaces/#abstract","text":"Autoware defines three categories of interfaces. The first one is Autoware AD API for operating the vehicle from outside the autonomous driving system such as the Fleet Management System ( FMS ) and Human Machine Interface ( HMI ) for operators or passengers. The second one is Autoware component interface for components to communicate with each other. The last one is the local interface used inside the component.","title":"Abstract"},{"location":"design/autoware-interfaces/#concept","text":"Applications can operate multiple and various vehicles in a common way. Applications are not affected by version updates and implementation changes. Developers only need to know the interface to add new features and hardware.","title":"Concept"},{"location":"design/autoware-interfaces/#requirements","text":"Goals: AD API provides functionality to create the following applications: Drive the vehicle on the route or drive to the requested positions in order. Operate vehicle behavior such as starting and stopping. Display or announce the vehicle status to operators, passengers, and people around. Control vehicle devices such as doors. Monitor the vehicle or drive it manually. AD API provides stable and long-term specifications. This enables unified access to all vehicles. AD API hides differences in version and implementation and absorbs the impact of changes. AD API has a default implementation and can be applied to some simple ODDs with options. The AD API implementation is extensible with the third-party components as long as it meets the specifications. The component interface provides stable and medium-term specifications. This makes it easier to add components. The component interface clarifies the public and private parts of a component and improves maintainability. The component interface is extensible with the third-party design to improve the sub-components' reusability. Non-goals: AD API does not cover security. Use it with other reliable methods. The component interface is just a specification, it does not include an implementation.","title":"Requirements"},{"location":"design/autoware-interfaces/#architecture","text":"The components of Autoware are connected via the component interface. Each component uses the interface to provide functionality and to access other components. AD API implementation is also a component. Since the functional elements required for AD API are defined as the component interface, other components do not need to consider AD API directly. Tools for evaluation and debugging, such as simulators, access both AD API and the component interface. The component interface has a hierarchical specification. The top-level architecture consists of some components. Each component has some options of the next-level architecture. Developers select one of them when implementing the component. The simplest next-level architecture is monolithic. This is an all-in-one and black box implementation, and is suitable for small group development, prototyping, and very complex functions. Others are arbitrary architecture consists of sub-components and have advantages for large group development. A sub-component can be combined with others that adopt the same architecture. Third parties can define and publish their own architecture and interface for open source development. It is desirable to propose them for standardization if they are sufficiently evaluated.","title":"Architecture"},{"location":"design/autoware-interfaces/#features","text":"","title":"Features"},{"location":"design/autoware-interfaces/#communication-methods","text":"As shown in the table below, interfaces are classified into four communication methods to define their behavior. Function Call is a request-response communication and is used for processing that requires immediate results. The others are publish-subscribe communication. Notification is used to process data that changes with some event, typically a callback. Streams handle continuously changing data. Reliable Stream expects all data to arrive without loss, Realtime Stream expects the latest data to arrive with low delay. Communication Method ROS Implementation Optional Implementation Function Call Service HTTP Notification Topic (reliable, transient_local) MQTT (QoS=2, retain) Reliable Stream Topic (reliable, volatile) MQTT (QoS=2) Realtime Stream Topic (best_effort, volatile) MQTT (QoS=0) These methods are provided as services or topics of ROS since Autoware is developed using ROS and mainly communicates with its packages. On the other hand, FMS and HMI are often implemented without ROS , Autoware is also expected to communicate with applications that do not use ROS . It is wasteful for each of these applications to have an adapter for Autoware, and a more suitable means of communication is required. HTTP and MQTT are suggested as additional options because these protocols are widely used and can substitute the behavior of services and topics. In that case, text formats such as JSON where field names are repeated in an array of objects, are inefficient and it is necessary to consider the serialization.","title":"Communication methods"},{"location":"design/autoware-interfaces/#naming-convention","text":"The name of the interface must be /<component name>/api/<interface name> , where <component name> is the name of the component. For an AD API component, omit this part and start with /api . The <interface name> is an arbitrary string separated by slashes. Note that this rule causes a restriction that the namespace api must not be used as a name other than AD API and the component interface. The following are examples of correct interface names for AD API and the component interface: /api/autoware/state /api/autoware/engage /planning/api/route/set /vehicle/api/status The following are examples of incorrect interface names for AD API and the component interface: /ad_api/autoware/state /autoware/engage /planning/route/set/api /vehicle/my_api/status","title":"Naming convention"},{"location":"design/autoware-interfaces/#logging","text":"It is recommended to log the interface for analysis of vehicle behavior. If logging is needed, rosbag is available for topics, and use logger in rclcpp or rclpy for services. Typically, create a wrapper for service and client classes that logs when a service is called.","title":"Logging"},{"location":"design/autoware-interfaces/#restrictions","text":"For each API, consider the restrictions such as following and describe them if necessary. Services: response time pre-condition post-condition execution order concurrent execution Topics: recommended delay range maximum delay recommended frequency range minimum frequency default frequency","title":"Restrictions"},{"location":"design/autoware-interfaces/#data-structure","text":"","title":"Data structure"},{"location":"design/autoware-interfaces/#data-type-definition","text":"Do not share the types in AD API unless they are obviously the same to avoid changes in one API affecting another. Also, implementation-dependent types, including the component interface, should not be used in AD API for the same reason. Use the type in AD API in implementation, or create the same type and copy the data to convert the type.","title":"Data type definition"},{"location":"design/autoware-interfaces/#constants-and-enumeration","text":"Since ROS don't support enumeration, use constants instead. The default value of type such as zero and empty string should not be used to detect that a variable is unassigned. Alternatively, assign it a dedicated name to indicate that it is undefined. If one type has multiple enumerations, comment on the correspondence between constants and variables. Assign unique values to all constants so that it can be distinguished from other enumerations. Do not use enumeration values directly, as assignments are subject to change when the version is updated.","title":"Constants and enumeration"},{"location":"design/autoware-interfaces/#time-stamp","text":"Clarify what the timestamp indicates. for example, send time, measurement time, update time, etc. Consider having multiple timestamps if necessary. Use std_msgs/msg/Header when using ROS transform. Also consider whether the header is common to all data, independent for each data, or additional timestamp is required.","title":"Time stamp"},{"location":"design/autoware-interfaces/#request-header","text":"Currently, there is no required header.","title":"Request header"},{"location":"design/autoware-interfaces/#response-status","text":"The interfaces whose communication method is Function Call use a common response status to unify the error format. These interfaces should include a variable of ResponseStatus with the name status in the response. See autoware_adapi_v1_msgs/msg/ResponseStatus for details.","title":"Response status"},{"location":"design/autoware-interfaces/#concerns-assumptions-and-limitations","text":"The applications use the version information provided by AD API to check compatibility. Unknown versions are also treated as available as long as the major versions match (excluding major version 0). Compatibility between AD API and the component interface is assumed to be maintained by the version management system. If an unintended behavior of AD API is detected, the application should take appropriate action. Autoware tries to keep working as long as possible, but it is not guaranteed to be safe. Safety should be considered for the entire system, including the applications.","title":"Concerns, assumptions and limitations"},{"location":"design/autoware-interfaces/ad-api/","text":"AD API # Warning Under Construction","title":"AD API"},{"location":"design/autoware-interfaces/ad-api/#ad-api","text":"Warning Under Construction","title":"AD API"},{"location":"design/autoware-interfaces/ad-api/list/","text":"List of Autoware AD API # Interface Operation Mode Routing Localization Motion Planning Fail-safe","title":"List of Autoware AD API"},{"location":"design/autoware-interfaces/ad-api/list/#list-of-autoware-ad-api","text":"Interface Operation Mode Routing Localization Motion Planning Fail-safe","title":"List of Autoware AD API"},{"location":"design/autoware-interfaces/ad-api/list/api/fail_safe/","text":"Fail-safe API # /api/fail_safe/mrm_state Description # This API manages the behavior related to the abnormality of the vehicle. It provides the state of Request to Intervene (RTI), Minimal Risk Maneuver (MRM) and Minimal Risk Condition (MRC). As shown below, Autoware has the gate to switch between the command during normal operation and the command during abnormal operation. For safety, Autoware switches the operation to MRM when an abnormality is detected. Since the required behavior differs depending on the situation, MRM is implemented in various places as a specific mode in a normal module or as an independent module. The fail-safe module selects the behavior of MRM according to the abnormality and switches the gate output to that command. States # The MRM state indicates whether MRM is operating. This state also provides success or failure. Generally, MRM will switch to another behavior if it fails. State Description NONE MRM is not operating. OPERATING MRM is operating because an abnormality has been detected. SUCCEEDED MRM succeeded. The vehicle is in a safe condition. FAILED MRM failed. The vehicle is still in an unsafe condition. Behavior # There is a dependency between MRM behaviors. For example, it switches from a comfortable stop to a emergency stop, but not the other way around. This is service dependent. Autoware supports the following transitions by default. State Description NONE MRM is not operating or is operating but no special behavior is required. COMFORTABLE_STOP The vehicle will stop quickly with a comfortable deceleration. EMERGENCY_STOP The vehicle will stop immediately with as much deceleration as possible.","title":"Fail-safe API"},{"location":"design/autoware-interfaces/ad-api/list/api/fail_safe/#fail-safe-api","text":"/api/fail_safe/mrm_state","title":"Fail-safe API"},{"location":"design/autoware-interfaces/ad-api/list/api/fail_safe/#description","text":"This API manages the behavior related to the abnormality of the vehicle. It provides the state of Request to Intervene (RTI), Minimal Risk Maneuver (MRM) and Minimal Risk Condition (MRC). As shown below, Autoware has the gate to switch between the command during normal operation and the command during abnormal operation. For safety, Autoware switches the operation to MRM when an abnormality is detected. Since the required behavior differs depending on the situation, MRM is implemented in various places as a specific mode in a normal module or as an independent module. The fail-safe module selects the behavior of MRM according to the abnormality and switches the gate output to that command.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/fail_safe/#states","text":"The MRM state indicates whether MRM is operating. This state also provides success or failure. Generally, MRM will switch to another behavior if it fails. State Description NONE MRM is not operating. OPERATING MRM is operating because an abnormality has been detected. SUCCEEDED MRM succeeded. The vehicle is in a safe condition. FAILED MRM failed. The vehicle is still in an unsafe condition.","title":"States"},{"location":"design/autoware-interfaces/ad-api/list/api/fail_safe/#behavior","text":"There is a dependency between MRM behaviors. For example, it switches from a comfortable stop to a emergency stop, but not the other way around. This is service dependent. Autoware supports the following transitions by default. State Description NONE MRM is not operating or is operating but no special behavior is required. COMFORTABLE_STOP The vehicle will stop quickly with a comfortable deceleration. EMERGENCY_STOP The vehicle will stop immediately with as much deceleration as possible.","title":"Behavior"},{"location":"design/autoware-interfaces/ad-api/list/api/fail_safe/mrm_state/","text":"/api/fail_safe/mrm_state # Method: notification Type: autoware_ad_api_msgs/msg/MrmState Description # Get the MRM state. For details, see the fail-safe . Message # Name Type Description state uint16 The state of MRM operation. behavior uint16 The currently selected behavior of MRM.","title":"/api/fail_safe/mrm_state"},{"location":"design/autoware-interfaces/ad-api/list/api/fail_safe/mrm_state/#apifail_safemrm_state","text":"Method: notification Type: autoware_ad_api_msgs/msg/MrmState","title":"/api/fail_safe/mrm_state"},{"location":"design/autoware-interfaces/ad-api/list/api/fail_safe/mrm_state/#description","text":"Get the MRM state. For details, see the fail-safe .","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/fail_safe/mrm_state/#message","text":"Name Type Description state uint16 The state of MRM operation. behavior uint16 The currently selected behavior of MRM.","title":"Message"},{"location":"design/autoware-interfaces/ad-api/list/api/interface/","text":"Interface API # /api/interface/version Description # This API provides the interface version of the set of AD APIs. It follows Semantic Versioning in order to provide an intuitive understanding of the changes between versions.","title":"Interface API"},{"location":"design/autoware-interfaces/ad-api/list/api/interface/#interface-api","text":"/api/interface/version","title":"Interface API"},{"location":"design/autoware-interfaces/ad-api/list/api/interface/#description","text":"This API provides the interface version of the set of AD APIs. It follows Semantic Versioning in order to provide an intuitive understanding of the changes between versions.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/interface/version/","text":"/api/interface/version # Method: function call Type: autoware_ad_api_msgs/srv/InterfaceVersion Description # Get the interface version. The version follows Semantic Versioning. Request # None Response # Name Type Description major uint16 major version minor uint16 minor version patch uint16 patch version","title":"/api/interface/version"},{"location":"design/autoware-interfaces/ad-api/list/api/interface/version/#apiinterfaceversion","text":"Method: function call Type: autoware_ad_api_msgs/srv/InterfaceVersion","title":"/api/interface/version"},{"location":"design/autoware-interfaces/ad-api/list/api/interface/version/#description","text":"Get the interface version. The version follows Semantic Versioning.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/interface/version/#request","text":"None","title":"Request"},{"location":"design/autoware-interfaces/ad-api/list/api/interface/version/#response","text":"Name Type Description major uint16 major version minor uint16 minor version patch uint16 patch version","title":"Response"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/","text":"Pose API # /api/localization/initialization_state /api/localization/initialize Description # This API manages the initialization of localization. Autoware requires a global pose as the initial guess for localization. States # State Description UNINITIALIZED Localization is not initialized. Waiting for a global pose as the initial guess. INITIALIZING Localization is initializing. INITIALIZED Localization is initialized. Initialization can be requested again if necessary.","title":"Pose API"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/#pose-api","text":"/api/localization/initialization_state /api/localization/initialize","title":"Pose API"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/#description","text":"This API manages the initialization of localization. Autoware requires a global pose as the initial guess for localization.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/#states","text":"State Description UNINITIALIZED Localization is not initialized. Waiting for a global pose as the initial guess. INITIALIZING Localization is initializing. INITIALIZED Localization is initialized. Initialization can be requested again if necessary.","title":"States"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/initialization_state/","text":"/api/localization/initialization_state # Method: notification Type: autoware_ad_api_msgs/msg/LocalizationInitializationState Description # Get the initialization state of localization. For details, see the localization initialization state . Message # Name Type Description state uint16 A value of the localization initialization state .","title":"/api/localization/initialization_state"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/initialization_state/#apilocalizationinitialization_state","text":"Method: notification Type: autoware_ad_api_msgs/msg/LocalizationInitializationState","title":"/api/localization/initialization_state"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/initialization_state/#description","text":"Get the initialization state of localization. For details, see the localization initialization state .","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/initialization_state/#message","text":"Name Type Description state uint16 A value of the localization initialization state .","title":"Message"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/initialize/","text":"/api/localization/initialize # Method: function call Type: autoware_ad_api_msgs/srv/InitializeLocalization Description # Request to initialize localization. For details, see the pose state . Request # Name Type Description pose geometry_msgs/msg/PoseWithCovarianceStamped[<=1] A global pose as the initial guess. If omitted, the GNSS pose will be used. Response # Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"/api/localization/initialize"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/initialize/#apilocalizationinitialize","text":"Method: function call Type: autoware_ad_api_msgs/srv/InitializeLocalization","title":"/api/localization/initialize"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/initialize/#description","text":"Request to initialize localization. For details, see the pose state .","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/initialize/#request","text":"Name Type Description pose geometry_msgs/msg/PoseWithCovarianceStamped[<=1] A global pose as the initial guess. If omitted, the GNSS pose will be used.","title":"Request"},{"location":"design/autoware-interfaces/ad-api/list/api/localization/initialize/#response","text":"Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"Response"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/","text":"Planning API # /api/motion/state /api/motion/accept_start Description # This API manages the current behavior of the vehicle. Applications can notify the vehicle behavior to the people around and visualize it for operator and passengers. States # The motion state manages the stop and start of the vehicle. Once the vehicle has stopped, the state will be STOPPED. After this, when the vehicle tries to start (is still stopped), the state will be STARTING. In this state, calling the start API changes the state to MOVING and the vehicle starts. This mechanism can add processing such as announcements before the vehicle starts. Depending on the configuration, the state may transition directly from STOPPED to MOVING. State Description STOPPED The vehicle is stopped. STARTING The vehicle is stopped, but is trying to start. MOVING The vehicle is moving. BRAKING (T.B.D.) The vehicle is decelerating strongly.","title":"Planning API"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/#planning-api","text":"/api/motion/state /api/motion/accept_start","title":"Planning API"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/#description","text":"This API manages the current behavior of the vehicle. Applications can notify the vehicle behavior to the people around and visualize it for operator and passengers.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/#states","text":"The motion state manages the stop and start of the vehicle. Once the vehicle has stopped, the state will be STOPPED. After this, when the vehicle tries to start (is still stopped), the state will be STARTING. In this state, calling the start API changes the state to MOVING and the vehicle starts. This mechanism can add processing such as announcements before the vehicle starts. Depending on the configuration, the state may transition directly from STOPPED to MOVING. State Description STOPPED The vehicle is stopped. STARTING The vehicle is stopped, but is trying to start. MOVING The vehicle is moving. BRAKING (T.B.D.) The vehicle is decelerating strongly.","title":"States"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/accept_start/","text":"/api/motion/accept_start # Method: function call Type: autoware_ad_api_msgs/srv/AcceptStart Description # Accept the vehicle to start. This API can be used when the motion state is STARTING. Request # None Response # Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"/api/motion/accept_start"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/accept_start/#apimotionaccept_start","text":"Method: function call Type: autoware_ad_api_msgs/srv/AcceptStart","title":"/api/motion/accept_start"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/accept_start/#description","text":"Accept the vehicle to start. This API can be used when the motion state is STARTING.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/accept_start/#request","text":"None","title":"Request"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/accept_start/#response","text":"Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"Response"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/state/","text":"/api/motion/state # Method: notification Type: autoware_ad_api_msgs/msg/MotionState Description # Get the motion state. For details, see the motion state . Message # Name Type Description state uint16 A value of the motion state.","title":"/api/motion/state"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/state/#apimotionstate","text":"Method: notification Type: autoware_ad_api_msgs/msg/MotionState","title":"/api/motion/state"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/state/#description","text":"Get the motion state. For details, see the motion state .","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/motion/state/#message","text":"Name Type Description state uint16 A value of the motion state.","title":"Message"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/","text":"Operation Mode # /api/operation_mode/state /api/operation_mode/change_to_autonomous /api/operation_mode/change_to_stop /api/operation_mode/change_to_local /api/operation_mode/change_to_remote /api/operation_mode/enable_autoware_control /api/operation_mode/disable_autoware_control Description # As shown below, Autoware assumes that the vehicle interface has two modes, Autoware control and direct control. In direct control mode, the vehicle is operated using devices such as steering and pedals. If the vehicle does not support direct control mode, it is always treated as Autoware control mode. Autoware control mode has four operation modes. Mode Description Stop Keep the vehicle stopped. Autonomous Autonomously control the vehicle. Local Manually control the vehicle from nearby with some device such as a joystick. Remote Manually control the vehicle from a web application on the cloud. States # Autoware control flag # The flag is_autoware_control_enabled indicates if the vehicle is controlled by Autoware. The enable and disable APIs can be used if the control can be switched by software. These APIs will always fail if the vehicle does not support mode switching or is switched by hardware. Operation mode and change flags # The state operation_mode indicates what command is used when Autoware control is enabled. The flags change_to_* can be used to check if it is possible to transition to each mode. Transition flag # Since Autoware may not be able to guarantee safety, such as switching to autonomous mode during overspeed. There is the flag is_in_transition for this situation and it will be true when changing modes. The operator who changed the mode should ensure safety while this flag is true. The flag will be false when the mode change is complete.","title":"Operation Mode"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/#operation-mode","text":"/api/operation_mode/state /api/operation_mode/change_to_autonomous /api/operation_mode/change_to_stop /api/operation_mode/change_to_local /api/operation_mode/change_to_remote /api/operation_mode/enable_autoware_control /api/operation_mode/disable_autoware_control","title":"Operation Mode"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/#description","text":"As shown below, Autoware assumes that the vehicle interface has two modes, Autoware control and direct control. In direct control mode, the vehicle is operated using devices such as steering and pedals. If the vehicle does not support direct control mode, it is always treated as Autoware control mode. Autoware control mode has four operation modes. Mode Description Stop Keep the vehicle stopped. Autonomous Autonomously control the vehicle. Local Manually control the vehicle from nearby with some device such as a joystick. Remote Manually control the vehicle from a web application on the cloud.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/#states","text":"","title":"States"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/#autoware-control-flag","text":"The flag is_autoware_control_enabled indicates if the vehicle is controlled by Autoware. The enable and disable APIs can be used if the control can be switched by software. These APIs will always fail if the vehicle does not support mode switching or is switched by hardware.","title":"Autoware control flag"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/#operation-mode-and-change-flags","text":"The state operation_mode indicates what command is used when Autoware control is enabled. The flags change_to_* can be used to check if it is possible to transition to each mode.","title":"Operation mode and change flags"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/#transition-flag","text":"Since Autoware may not be able to guarantee safety, such as switching to autonomous mode during overspeed. There is the flag is_in_transition for this situation and it will be true when changing modes. The operator who changed the mode should ensure safety while this flag is true. The flag will be false when the mode change is complete.","title":"Transition flag"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_autonomous/","text":"/api/operation_mode/change_to_autonomous # Method: function call Type: autoware_ad_api_msgs/srv/ChangeOperationMode Description # Change the operation mode to autonomous. For details, see the operation mode . Request # None Response # Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"/api/operation_mode/change_to_autonomous"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_autonomous/#apioperation_modechange_to_autonomous","text":"Method: function call Type: autoware_ad_api_msgs/srv/ChangeOperationMode","title":"/api/operation_mode/change_to_autonomous"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_autonomous/#description","text":"Change the operation mode to autonomous. For details, see the operation mode .","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_autonomous/#request","text":"None","title":"Request"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_autonomous/#response","text":"Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"Response"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_local/","text":"/api/operation_mode/change_to_local # Method: function call Type: autoware_ad_api_msgs/srv/ChangeOperationMode Description # Change the operation mode to local. For details, see the operation mode . Request # None Response # Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"/api/operation_mode/change_to_local"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_local/#apioperation_modechange_to_local","text":"Method: function call Type: autoware_ad_api_msgs/srv/ChangeOperationMode","title":"/api/operation_mode/change_to_local"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_local/#description","text":"Change the operation mode to local. For details, see the operation mode .","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_local/#request","text":"None","title":"Request"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_local/#response","text":"Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"Response"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_remote/","text":"/api/operation_mode/change_to_remote # Method: function call Type: autoware_ad_api_msgs/srv/ChangeOperationMode Description # Change the operation mode to remote. For details, see the operation mode . Request # None Response # Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"/api/operation_mode/change_to_remote"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_remote/#apioperation_modechange_to_remote","text":"Method: function call Type: autoware_ad_api_msgs/srv/ChangeOperationMode","title":"/api/operation_mode/change_to_remote"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_remote/#description","text":"Change the operation mode to remote. For details, see the operation mode .","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_remote/#request","text":"None","title":"Request"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_remote/#response","text":"Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"Response"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_stop/","text":"/api/operation_mode/change_to_stop # Method: function call Type: autoware_ad_api_msgs/srv/ChangeOperationMode Description # Change the operation mode to stop. For details, see the operation mode . Request # None Response # Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"/api/operation_mode/change_to_stop"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_stop/#apioperation_modechange_to_stop","text":"Method: function call Type: autoware_ad_api_msgs/srv/ChangeOperationMode","title":"/api/operation_mode/change_to_stop"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_stop/#description","text":"Change the operation mode to stop. For details, see the operation mode .","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_stop/#request","text":"None","title":"Request"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/change_to_stop/#response","text":"Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"Response"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/disable_autoware_control/","text":"/api/operation_mode/disable_autoware_control # Method: function call Type: autoware_ad_api_msgs/srv/ChangeOperationMode Description # Disable vehicle control by Autoware. For details, see the operation mode . This API fails if the vehicle does not support mode change by software. Request # None Response # Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"/api/operation_mode/disable_autoware_control"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/disable_autoware_control/#apioperation_modedisable_autoware_control","text":"Method: function call Type: autoware_ad_api_msgs/srv/ChangeOperationMode","title":"/api/operation_mode/disable_autoware_control"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/disable_autoware_control/#description","text":"Disable vehicle control by Autoware. For details, see the operation mode . This API fails if the vehicle does not support mode change by software.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/disable_autoware_control/#request","text":"None","title":"Request"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/disable_autoware_control/#response","text":"Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"Response"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/enable_autoware_control/","text":"/api/operation_mode/enable_autoware_control # Method: function call Type: autoware_ad_api_msgs/srv/ChangeOperationMode Description # Enable vehicle control by Autoware. For details, see the operation mode . This API fails if the vehicle does not support mode change by software. Request # None Response # Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"/api/operation_mode/enable_autoware_control"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/enable_autoware_control/#apioperation_modeenable_autoware_control","text":"Method: function call Type: autoware_ad_api_msgs/srv/ChangeOperationMode","title":"/api/operation_mode/enable_autoware_control"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/enable_autoware_control/#description","text":"Enable vehicle control by Autoware. For details, see the operation mode . This API fails if the vehicle does not support mode change by software.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/enable_autoware_control/#request","text":"None","title":"Request"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/enable_autoware_control/#response","text":"Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"Response"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/state/","text":"/api/operation_mode/state # Method: notification Type: autoware_ad_api_msgs/msg/OperationModeState Description # Get the operation mode state. For details, see the operation mode . Message # Name Type Description operation_mode uint16 The selected command for Autoware control. is_autoware_control_enabled bool True if vehicle control by Autoware is enabled. is_in_transition bool True if the operation mode is in transition. change_to_stop bool True if the operation mode can be changed to stop. change_to_autonomous bool True if the operation mode can be changed to autonomous. change_to_local bool True if the operation mode can be changed to local. change_to_remote bool True if the operation mode can be changed to remote.","title":"/api/operation_mode/state"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/state/#apioperation_modestate","text":"Method: notification Type: autoware_ad_api_msgs/msg/OperationModeState","title":"/api/operation_mode/state"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/state/#description","text":"Get the operation mode state. For details, see the operation mode .","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/operation_mode/state/#message","text":"Name Type Description operation_mode uint16 The selected command for Autoware control. is_autoware_control_enabled bool True if vehicle control by Autoware is enabled. is_in_transition bool True if the operation mode is in transition. change_to_stop bool True if the operation mode can be changed to stop. change_to_autonomous bool True if the operation mode can be changed to autonomous. change_to_local bool True if the operation mode can be changed to local. change_to_remote bool True if the operation mode can be changed to remote.","title":"Message"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/","text":"Planning API # /api/planning/velocity_factors /api/planning/steering_factors Description # This API manages the planned behavior of the vehicle. Applications can notify the vehicle behavior to the people around and visualize it for operator and passengers. Velocity factors # The velocity factors is an array of information on the behavior that the vehicle stops (or slows down). Each factor has a type shown below, pose, distance from the vehicle head to that pose, status, and detailed data depending on its type. As the vehicle approaches the stop position, this factor appears with a status of APPROACHING. And when the vehicle reaches that position and stops, the status will be STOPPED. The pose indicates the stop position or the vehicle head if the stop position cannot be calculated. Factor Type Description SURROUNDING_OBSTACLE There are obstacles immediately around the vehicle. ROUTE_OBSTACLE There are obstacles along the route ahead. INTERSECTION There are obstacles in other lanes in the path. CROSSWALK There are obstacles on the crosswalk. REAR_CHECK There are obstacles behind that would be in a human driver's blind spot. USER_DEFINED_DETECTION_AREA There are obstacles in the predefined detection area. NO_STOPPING_AREA There is not enough space beyond the no stopping area. STOP_SIGN A stop by a stop sign. TRAFFIC_SIGNAL A stop by a traffic signal. V2I_GATE_CONTROL_ENTER A stop by a V2I gate entering. V2I_GATE_CONTROL_LEAVE A stop by a V2I gate leaving. MERGE A stop before merging lanes. SIDEWALK A stop before crossing the sidewalk. LANE_CHANGE A lane change. AVOIDANCE A path change to avoid an obstacle in the current lane. EMERGENCY_OPERATION A stop by emergency instruction from the operator. Steering factors # The steering factors is an array of information on the maneuver that requires use of turn indicators, such as turning left or right. Each factor has a type shown below, pose, distance from the vehicle head to that pose, status, and detailed data depending on its type. As the vehicle approaches the position to start steering, this factor appears with a status of APPROACHING. And when the vehicle reaches that position, the status will be TURNING. The pose indicates the start position when APPROACHING and the end position when TURNING. In cases such as lane change and avoidance, the vehicle will start steering at any position in the range depending on the situation. As the vehicle approaches the start position of the range, this factor appears with a status of APPROACHING. And when the vehicle reaches that position, the status will be TRYING. Then, when it is possible, the vehicle will start steering and the status will be TURNING. The pose indicates the start of the range (A) when APPROACHING and the end of the range (B) when TRYING. The position to end steering (C to D) for TURNING depends on the position to start steering. Factor Type Description INTERSECTION A turning left or right at an intersection. LANE_CHANGE A lane change. AVOIDANCE_PATH_CHANGE A path change to avoid an obstacle in the current lane. AVOIDANCE_PATH_RETURN A path change to return to the original lane after avoiding an obstacle. STATION T.B.D. (bus stop) PULL_OUT T.B.D. PULL_OVER T.B.D. EMERGENCY_OPERATION A path change by emergency instruction from the operator.","title":"Planning API"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/#planning-api","text":"/api/planning/velocity_factors /api/planning/steering_factors","title":"Planning API"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/#description","text":"This API manages the planned behavior of the vehicle. Applications can notify the vehicle behavior to the people around and visualize it for operator and passengers.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/#velocity-factors","text":"The velocity factors is an array of information on the behavior that the vehicle stops (or slows down). Each factor has a type shown below, pose, distance from the vehicle head to that pose, status, and detailed data depending on its type. As the vehicle approaches the stop position, this factor appears with a status of APPROACHING. And when the vehicle reaches that position and stops, the status will be STOPPED. The pose indicates the stop position or the vehicle head if the stop position cannot be calculated. Factor Type Description SURROUNDING_OBSTACLE There are obstacles immediately around the vehicle. ROUTE_OBSTACLE There are obstacles along the route ahead. INTERSECTION There are obstacles in other lanes in the path. CROSSWALK There are obstacles on the crosswalk. REAR_CHECK There are obstacles behind that would be in a human driver's blind spot. USER_DEFINED_DETECTION_AREA There are obstacles in the predefined detection area. NO_STOPPING_AREA There is not enough space beyond the no stopping area. STOP_SIGN A stop by a stop sign. TRAFFIC_SIGNAL A stop by a traffic signal. V2I_GATE_CONTROL_ENTER A stop by a V2I gate entering. V2I_GATE_CONTROL_LEAVE A stop by a V2I gate leaving. MERGE A stop before merging lanes. SIDEWALK A stop before crossing the sidewalk. LANE_CHANGE A lane change. AVOIDANCE A path change to avoid an obstacle in the current lane. EMERGENCY_OPERATION A stop by emergency instruction from the operator.","title":"Velocity factors"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/#steering-factors","text":"The steering factors is an array of information on the maneuver that requires use of turn indicators, such as turning left or right. Each factor has a type shown below, pose, distance from the vehicle head to that pose, status, and detailed data depending on its type. As the vehicle approaches the position to start steering, this factor appears with a status of APPROACHING. And when the vehicle reaches that position, the status will be TURNING. The pose indicates the start position when APPROACHING and the end position when TURNING. In cases such as lane change and avoidance, the vehicle will start steering at any position in the range depending on the situation. As the vehicle approaches the start position of the range, this factor appears with a status of APPROACHING. And when the vehicle reaches that position, the status will be TRYING. Then, when it is possible, the vehicle will start steering and the status will be TURNING. The pose indicates the start of the range (A) when APPROACHING and the end of the range (B) when TRYING. The position to end steering (C to D) for TURNING depends on the position to start steering. Factor Type Description INTERSECTION A turning left or right at an intersection. LANE_CHANGE A lane change. AVOIDANCE_PATH_CHANGE A path change to avoid an obstacle in the current lane. AVOIDANCE_PATH_RETURN A path change to return to the original lane after avoiding an obstacle. STATION T.B.D. (bus stop) PULL_OUT T.B.D. PULL_OVER T.B.D. EMERGENCY_OPERATION A path change by emergency instruction from the operator.","title":"Steering factors"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/steering_factors/","text":"/api/planning/steering_factors # Method: realtime stream Type: autoware_ad_api_msgs/msg/SteeringFactorArray Description # Get the steering factors, sorted in ascending order of distance. For details, see the planning . Message # Name Type Description factors.pose geometry_msgs/msg/Pose The pose related to the steering factor. factors.distance float32 The distance from the vehicle head to the above pose. factors.type uint16 The type of the steering factor. factors.direction uint16 The direction of the steering factor. factors.status uint16 The status of the steering factor. factors.detail string The additional information of the steering factor.","title":"/api/planning/steering_factors"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/steering_factors/#apiplanningsteering_factors","text":"Method: realtime stream Type: autoware_ad_api_msgs/msg/SteeringFactorArray","title":"/api/planning/steering_factors"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/steering_factors/#description","text":"Get the steering factors, sorted in ascending order of distance. For details, see the planning .","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/steering_factors/#message","text":"Name Type Description factors.pose geometry_msgs/msg/Pose The pose related to the steering factor. factors.distance float32 The distance from the vehicle head to the above pose. factors.type uint16 The type of the steering factor. factors.direction uint16 The direction of the steering factor. factors.status uint16 The status of the steering factor. factors.detail string The additional information of the steering factor.","title":"Message"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/velocity_factors/","text":"/api/planning/velocity_factors # Method: realtime stream Type: autoware_ad_api_msgs/msg/VelocityFactorArray Description # Get the velocity factors, sorted in ascending order of distance. For details, see the planning . Message # Name Type Description factors.pose geometry_msgs/msg/Pose The pose related to the velocity factor. factors.distance float32 The distance from the vehicle head to the above pose. factors.type uint16 The type of the velocity factor. factors.status uint16 The status of the velocity factor. factors.detail string The additional information of the velocity factor.","title":"/api/planning/velocity_factors"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/velocity_factors/#apiplanningvelocity_factors","text":"Method: realtime stream Type: autoware_ad_api_msgs/msg/VelocityFactorArray","title":"/api/planning/velocity_factors"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/velocity_factors/#description","text":"Get the velocity factors, sorted in ascending order of distance. For details, see the planning .","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/planning/velocity_factors/#message","text":"Name Type Description factors.pose geometry_msgs/msg/Pose The pose related to the velocity factor. factors.distance float32 The distance from the vehicle head to the above pose. factors.type uint16 The type of the velocity factor. factors.status uint16 The status of the velocity factor. factors.detail string The additional information of the velocity factor.","title":"Message"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/","text":"Route API # /api/routing/state /api/routing/route /api/routing/set_route_points /api/routing/set_route /api/routing/clear_route Description # This API manages destination and waypoints. Note that waypoints are not like stops and just points passing through. In other words, Autoware does not support the route with multiple stops, the application needs to split it up and switch them. There are two ways to set the route. The one is a generic method that uses pose, another is a map-dependent. States # State Description WAITING The route is not set. Waiting for a route request. SET The route is set. ARRIVED The vehicle has arrived at the destination. CHANGING Trying to change the route. Not implemented yet.","title":"Route API"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/#route-api","text":"/api/routing/state /api/routing/route /api/routing/set_route_points /api/routing/set_route /api/routing/clear_route","title":"Route API"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/#description","text":"This API manages destination and waypoints. Note that waypoints are not like stops and just points passing through. In other words, Autoware does not support the route with multiple stops, the application needs to split it up and switch them. There are two ways to set the route. The one is a generic method that uses pose, another is a map-dependent.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/#states","text":"State Description WAITING The route is not set. Waiting for a route request. SET The route is set. ARRIVED The vehicle has arrived at the destination. CHANGING Trying to change the route. Not implemented yet.","title":"States"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/clear_route/","text":"/api/routing/clear_route # Method: function call Type: autoware_ad_api_msgs/srv/ClearRoute Description # Clear the route. Request # None Response # Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"/api/routing/clear_route"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/clear_route/#apiroutingclear_route","text":"Method: function call Type: autoware_ad_api_msgs/srv/ClearRoute","title":"/api/routing/clear_route"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/clear_route/#description","text":"Clear the route.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/clear_route/#request","text":"None","title":"Request"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/clear_route/#response","text":"Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"Response"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/route/","text":"/api/routing/route # Method: notification Type: autoware_ad_api_msgs/msg/RouteOptional Description # Get the route with the waypoint segments in lanelet format. It is empty if route is not set. Message # Name Type Description route autoware_ad_api_msgs/msg/Route[<=1] The route in lanelet format","title":"/api/routing/route"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/route/#apiroutingroute","text":"Method: notification Type: autoware_ad_api_msgs/msg/RouteOptional","title":"/api/routing/route"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/route/#description","text":"Get the route with the waypoint segments in lanelet format. It is empty if route is not set.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/route/#message","text":"Name Type Description route autoware_ad_api_msgs/msg/Route[<=1] The route in lanelet format","title":"Message"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/set_route/","text":"/api/routing/set_route # Method: function call Type: autoware_ad_api_msgs/srv/SetRoute Description # Set the route with the waypoint segments in lanelet format. If start pose is not specified, the current pose will be used. Request # Name Type Description header std_msgs/msg/Header header for pose transformation start geometry_msgs/msg/Pose[<=1] start pose goal geometry_msgs/msg/Pose goal pose segments autoware_ad_api_msgs/msg/RouteSegment[] waypoint segments in lanelet format Response # Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"/api/routing/set_route"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/set_route/#apiroutingset_route","text":"Method: function call Type: autoware_ad_api_msgs/srv/SetRoute","title":"/api/routing/set_route"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/set_route/#description","text":"Set the route with the waypoint segments in lanelet format. If start pose is not specified, the current pose will be used.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/set_route/#request","text":"Name Type Description header std_msgs/msg/Header header for pose transformation start geometry_msgs/msg/Pose[<=1] start pose goal geometry_msgs/msg/Pose goal pose segments autoware_ad_api_msgs/msg/RouteSegment[] waypoint segments in lanelet format","title":"Request"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/set_route/#response","text":"Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"Response"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/set_route_points/","text":"/api/routing/set_route_points # Method: function call Type: autoware_ad_api_msgs/srv/SetRoutePoints Description # Set the route with the waypoint poses. If start pose is not specified, the current pose will be used. Request # Name Type Description header std_msgs/msg/Header header for pose transformation start geometry_msgs/msg/Pose[<=1] start pose goal geometry_msgs/msg/Pose goal pose waypoints geometry_msgs/msg/Pose[] waypoint poses Response # Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"/api/routing/set_route_points"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/set_route_points/#apiroutingset_route_points","text":"Method: function call Type: autoware_ad_api_msgs/srv/SetRoutePoints","title":"/api/routing/set_route_points"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/set_route_points/#description","text":"Set the route with the waypoint poses. If start pose is not specified, the current pose will be used.","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/set_route_points/#request","text":"Name Type Description header std_msgs/msg/Header header for pose transformation start geometry_msgs/msg/Pose[<=1] start pose goal geometry_msgs/msg/Pose goal pose waypoints geometry_msgs/msg/Pose[] waypoint poses","title":"Request"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/set_route_points/#response","text":"Name Type Description status autoware_ad_api_msgs/msg/ResponseStatus response status","title":"Response"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/state/","text":"/api/routing/state # Method: notification Type: autoware_ad_api_msgs/msg/RouteState Description # Get the route state. For details, see the route state . Message # Name Type Description state uint16 A value of the route state .","title":"/api/routing/state"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/state/#apiroutingstate","text":"Method: notification Type: autoware_ad_api_msgs/msg/RouteState","title":"/api/routing/state"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/state/#description","text":"Get the route state. For details, see the route state .","title":"Description"},{"location":"design/autoware-interfaces/ad-api/list/api/routing/state/#message","text":"Name Type Description state uint16 A value of the route state .","title":"Message"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/localization_initialization_state/","text":"autoware_ad_api_msgs/msg/LocalizationInitializationState # Definition # uint16 UNKNOWN = 0 uint16 UNINITIALIZED = 1 uint16 INITIALIZING = 2 uint16 INITIALIZED = 3 uint16 state This type uses # None","title":"autoware_ad_api_msgs/msg/LocalizationInitializationState"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/localization_initialization_state/#autoware_ad_api_msgsmsglocalizationinitializationstate","text":"","title":"autoware_ad_api_msgs/msg/LocalizationInitializationState"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/localization_initialization_state/#definition","text":"uint16 UNKNOWN = 0 uint16 UNINITIALIZED = 1 uint16 INITIALIZING = 2 uint16 INITIALIZED = 3 uint16 state","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/localization_initialization_state/#this-type-uses","text":"None","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/motion_state/","text":"autoware_ad_api_msgs/msg/MotionState # Definition # uint16 UNKNOWN = 0 uint16 STOPPED = 1 uint16 STARTING = 2 uint16 MOVING = 3 builtin_interfaces/Time stamp uint16 state This type uses # None","title":"autoware_ad_api_msgs/msg/MotionState"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/motion_state/#autoware_ad_api_msgsmsgmotionstate","text":"","title":"autoware_ad_api_msgs/msg/MotionState"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/motion_state/#definition","text":"uint16 UNKNOWN = 0 uint16 STOPPED = 1 uint16 STARTING = 2 uint16 MOVING = 3 builtin_interfaces/Time stamp uint16 state","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/motion_state/#this-type-uses","text":"None","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/mrm_state/","text":"autoware_ad_api_msgs/msg/MrmState # Definition # # constants for both uint16 UNKNOWN = 0 # constants for stamp uint16 NONE = 1 uint16 OPERATING = 2 uint16 SUCCEEDED = 3 uint16 FAILED = 4 # constants for behavior uint16 NONE = 101 uint16 EMERGENCY_STOP = 102 uint16 COMFORTABLE_STOP = 103 # variables builtin_interfaces/Time stamp uint16 state uint16 behavior This type uses # None","title":"autoware_ad_api_msgs/msg/MrmState"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/mrm_state/#autoware_ad_api_msgsmsgmrmstate","text":"","title":"autoware_ad_api_msgs/msg/MrmState"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/mrm_state/#definition","text":"# constants for both uint16 UNKNOWN = 0 # constants for stamp uint16 NONE = 1 uint16 OPERATING = 2 uint16 SUCCEEDED = 3 uint16 FAILED = 4 # constants for behavior uint16 NONE = 101 uint16 EMERGENCY_STOP = 102 uint16 COMFORTABLE_STOP = 103 # variables builtin_interfaces/Time stamp uint16 state uint16 behavior","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/mrm_state/#this-type-uses","text":"None","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/operation_mode_state/","text":"autoware_ad_api_msgs/msg/OperationModeState # Definition # # constants for operation_mode uint16 UNKNOWN = 0 uint16 STOP = 1 uint16 AUTONOMOUS = 2 uint16 LOCAL = 3 uint16 REMOTE = 4 # variables uint16 operation_mode bool is_autoware_control_enabled bool is_in_transition bool change_to_stop bool change_to_autonomous bool change_to_local bool change_to_remote This type uses # None","title":"autoware_ad_api_msgs/msg/OperationModeState"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/operation_mode_state/#autoware_ad_api_msgsmsgoperationmodestate","text":"","title":"autoware_ad_api_msgs/msg/OperationModeState"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/operation_mode_state/#definition","text":"# constants for operation_mode uint16 UNKNOWN = 0 uint16 STOP = 1 uint16 AUTONOMOUS = 2 uint16 LOCAL = 3 uint16 REMOTE = 4 # variables uint16 operation_mode bool is_autoware_control_enabled bool is_in_transition bool change_to_stop bool change_to_autonomous bool change_to_local bool change_to_remote","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/operation_mode_state/#this-type-uses","text":"None","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/response_status/","text":"autoware_ad_api_msgs/msg/ResponseStatus # Definition # # constants for code uint16 DEPRECATED = 50000 uint16 SERVICE_UNREADY = 50001 uint16 SERVICE_TIMEOUT = 50002 # variables bool success uint16 code string message This type uses # None","title":"autoware_ad_api_msgs/msg/ResponseStatus"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/response_status/#autoware_ad_api_msgsmsgresponsestatus","text":"","title":"autoware_ad_api_msgs/msg/ResponseStatus"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/response_status/#definition","text":"# constants for code uint16 DEPRECATED = 50000 uint16 SERVICE_UNREADY = 50001 uint16 SERVICE_TIMEOUT = 50002 # variables bool success uint16 code string message","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/response_status/#this-type-uses","text":"None","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route/","text":"autoware_ad_api_msgs/msg/Route # Definition # std_msgs/Header header geometry_msgs/Pose start geometry_msgs/Pose goal autoware_ad_api_msgs/RouteSegment[] segments This type uses # autoware_ad_api_msgs/msg/RouteSegment","title":"autoware_ad_api_msgs/msg/Route"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route/#autoware_ad_api_msgsmsgroute","text":"","title":"autoware_ad_api_msgs/msg/Route"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route/#definition","text":"std_msgs/Header header geometry_msgs/Pose start geometry_msgs/Pose goal autoware_ad_api_msgs/RouteSegment[] segments","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route/#this-type-uses","text":"autoware_ad_api_msgs/msg/RouteSegment","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_optional/","text":"autoware_ad_api_msgs/msg/RouteOptional # Definition # autoware_ad_api_msgs/Route[<=1] route This type uses # autoware_ad_api_msgs/msg/Route","title":"autoware_ad_api_msgs/msg/RouteOptional"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_optional/#autoware_ad_api_msgsmsgrouteoptional","text":"","title":"autoware_ad_api_msgs/msg/RouteOptional"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_optional/#definition","text":"autoware_ad_api_msgs/Route[<=1] route","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_optional/#this-type-uses","text":"autoware_ad_api_msgs/msg/Route","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_primitive/","text":"autoware_ad_api_msgs/msg/RoutePrimitive # Definition # int64 id string type # The same id may be used for each type. This type uses # None","title":"autoware_ad_api_msgs/msg/RoutePrimitive"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_primitive/#autoware_ad_api_msgsmsgrouteprimitive","text":"","title":"autoware_ad_api_msgs/msg/RoutePrimitive"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_primitive/#definition","text":"int64 id string type # The same id may be used for each type.","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_primitive/#this-type-uses","text":"None","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_segment/","text":"autoware_ad_api_msgs/msg/RouteSegment # Definition # autoware_ad_api_msgs/RoutePrimitive[] preferred autoware_ad_api_msgs/RoutePrimitive[] alternatives This type uses # autoware_ad_api_msgs/msg/RoutePrimitive","title":"autoware_ad_api_msgs/msg/RouteSegment"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_segment/#autoware_ad_api_msgsmsgroutesegment","text":"","title":"autoware_ad_api_msgs/msg/RouteSegment"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_segment/#definition","text":"autoware_ad_api_msgs/RoutePrimitive[] preferred autoware_ad_api_msgs/RoutePrimitive[] alternatives","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_segment/#this-type-uses","text":"autoware_ad_api_msgs/msg/RoutePrimitive","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_state/","text":"autoware_ad_api_msgs/msg/RouteState # Definition # uint16 UNKNOWN = 0 uint16 UNSET = 1 uint16 SET = 2 uint16 ARRIVED = 3 uint16 CHANGING = 4 uint16 state This type uses # None","title":"autoware_ad_api_msgs/msg/RouteState"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_state/#autoware_ad_api_msgsmsgroutestate","text":"","title":"autoware_ad_api_msgs/msg/RouteState"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_state/#definition","text":"uint16 UNKNOWN = 0 uint16 UNSET = 1 uint16 SET = 2 uint16 ARRIVED = 3 uint16 CHANGING = 4 uint16 state","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/route_state/#this-type-uses","text":"None","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/steering_factor/","text":"autoware_ad_api_msgs/msg/SteeringFactor # Definition # # constants for common use uint16 UNKNOWN = 0 # constants for type uint16 INTERSECTION = 1 uint16 LANE_CHANGE = 2 uint16 AVOIDANCE_PATH_CHANGE = 3 uint16 AVOIDANCE_PATH_RETURN = 4 uint16 STATION = 5 uint16 PULL_OUT = 6 uint16 PULL_OVER = 7 uint16 EMERGENCY_OPERATION = 8 # constants for direction uint16 LEFT = 1 uint16 RIGHT = 2 uint16 STRAIGHT = 3 # constants for status uint16 APPROACHING = 1 uint16 TRYING = 2 uint16 TURNING = 3 # variables geometry_msgs/Pose[2] pose float32[2] distance uint16 type uint16 direction uint16 status string detail This type uses # None","title":"autoware_ad_api_msgs/msg/SteeringFactor"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/steering_factor/#autoware_ad_api_msgsmsgsteeringfactor","text":"","title":"autoware_ad_api_msgs/msg/SteeringFactor"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/steering_factor/#definition","text":"# constants for common use uint16 UNKNOWN = 0 # constants for type uint16 INTERSECTION = 1 uint16 LANE_CHANGE = 2 uint16 AVOIDANCE_PATH_CHANGE = 3 uint16 AVOIDANCE_PATH_RETURN = 4 uint16 STATION = 5 uint16 PULL_OUT = 6 uint16 PULL_OVER = 7 uint16 EMERGENCY_OPERATION = 8 # constants for direction uint16 LEFT = 1 uint16 RIGHT = 2 uint16 STRAIGHT = 3 # constants for status uint16 APPROACHING = 1 uint16 TRYING = 2 uint16 TURNING = 3 # variables geometry_msgs/Pose[2] pose float32[2] distance uint16 type uint16 direction uint16 status string detail","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/steering_factor/#this-type-uses","text":"None","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/steering_factor_array/","text":"autoware_ad_api_msgs/msg/SteeringFactorArray # Definition # std_msgs/Header header autoware_ad_api_msgs/SteeringFactor[] factors This type uses # autoware_ad_api_msgs/msg/SteeringFactor","title":"autoware_ad_api_msgs/msg/SteeringFactorArray"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/steering_factor_array/#autoware_ad_api_msgsmsgsteeringfactorarray","text":"","title":"autoware_ad_api_msgs/msg/SteeringFactorArray"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/steering_factor_array/#definition","text":"std_msgs/Header header autoware_ad_api_msgs/SteeringFactor[] factors","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/steering_factor_array/#this-type-uses","text":"autoware_ad_api_msgs/msg/SteeringFactor","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/velocity_factor/","text":"autoware_ad_api_msgs/msg/VelocityFactor # Definition # # constants for common use uint16 UNKNOWN = 0 # constants for type uint16 SURROUNDING_OBSTACLE = 1 uint16 ROUTE_OBSTACLE = 2 uint16 INTERSECTION = 3 uint16 CROSSWALK = 4 uint16 REAR_CHECK = 5 uint16 USER_DEFINED_DETECTION_AREA = 6 uint16 NO_STOPPING_AREA = 7 uint16 STOP_SIGN = 8 uint16 TRAFFIC_SIGNAL = 9 uint16 V2I_GATE_CONTROL_ENTER = 10 uint16 V2I_GATE_CONTROL_LEAVE = 11 uint16 MERGE = 12 uint16 SIDEWALK = 13 uint16 LANE_CHANGE = 14 uint16 AVOIDANCE = 15 uint16 EMERGENCY_STOP_OPERATION = 16 # constants for status uint16 APPROACHING = 1 uint16 STOPPED = 2 # variables geometry_msgs/Pose pose float32 distance uint16 type uint16 status string detail This type uses # None","title":"autoware_ad_api_msgs/msg/VelocityFactor"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/velocity_factor/#autoware_ad_api_msgsmsgvelocityfactor","text":"","title":"autoware_ad_api_msgs/msg/VelocityFactor"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/velocity_factor/#definition","text":"# constants for common use uint16 UNKNOWN = 0 # constants for type uint16 SURROUNDING_OBSTACLE = 1 uint16 ROUTE_OBSTACLE = 2 uint16 INTERSECTION = 3 uint16 CROSSWALK = 4 uint16 REAR_CHECK = 5 uint16 USER_DEFINED_DETECTION_AREA = 6 uint16 NO_STOPPING_AREA = 7 uint16 STOP_SIGN = 8 uint16 TRAFFIC_SIGNAL = 9 uint16 V2I_GATE_CONTROL_ENTER = 10 uint16 V2I_GATE_CONTROL_LEAVE = 11 uint16 MERGE = 12 uint16 SIDEWALK = 13 uint16 LANE_CHANGE = 14 uint16 AVOIDANCE = 15 uint16 EMERGENCY_STOP_OPERATION = 16 # constants for status uint16 APPROACHING = 1 uint16 STOPPED = 2 # variables geometry_msgs/Pose pose float32 distance uint16 type uint16 status string detail","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/velocity_factor/#this-type-uses","text":"None","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/velocity_factor_array/","text":"autoware_ad_api_msgs/msg/VelocityFactorArray # Definition # std_msgs/Header header autoware_ad_api_msgs/VelocityFactor[] factors This type uses # autoware_ad_api_msgs/msg/VelocityFactor","title":"autoware_ad_api_msgs/msg/VelocityFactorArray"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/velocity_factor_array/#autoware_ad_api_msgsmsgvelocityfactorarray","text":"","title":"autoware_ad_api_msgs/msg/VelocityFactorArray"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/velocity_factor_array/#definition","text":"std_msgs/Header header autoware_ad_api_msgs/VelocityFactor[] factors","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/msg/velocity_factor_array/#this-type-uses","text":"autoware_ad_api_msgs/msg/VelocityFactor","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/accept_start/","text":"autoware_ad_api_msgs/srv/AcceptStart # Definition # --- autoware_ad_api_msgs/ResponseStatus status This type uses # autoware_ad_api_msgs/msg/ResponseStatus","title":"autoware_ad_api_msgs/srv/AcceptStart"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/accept_start/#autoware_ad_api_msgssrvacceptstart","text":"","title":"autoware_ad_api_msgs/srv/AcceptStart"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/accept_start/#definition","text":"--- autoware_ad_api_msgs/ResponseStatus status","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/accept_start/#this-type-uses","text":"autoware_ad_api_msgs/msg/ResponseStatus","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/change_operation_mode/","text":"autoware_ad_api_msgs/srv/ChangeOperationMode # Definition # --- autoware_ad_api_msgs/ResponseStatus status This type uses # autoware_ad_api_msgs/msg/ResponseStatus","title":"autoware_ad_api_msgs/srv/ChangeOperationMode"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/change_operation_mode/#autoware_ad_api_msgssrvchangeoperationmode","text":"","title":"autoware_ad_api_msgs/srv/ChangeOperationMode"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/change_operation_mode/#definition","text":"--- autoware_ad_api_msgs/ResponseStatus status","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/change_operation_mode/#this-type-uses","text":"autoware_ad_api_msgs/msg/ResponseStatus","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/clear_route/","text":"autoware_ad_api_msgs/srv/ClearRoute # Definition # --- autoware_ad_api_msgs/ResponseStatus status This type uses # autoware_ad_api_msgs/msg/ResponseStatus","title":"autoware_ad_api_msgs/srv/ClearRoute"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/clear_route/#autoware_ad_api_msgssrvclearroute","text":"","title":"autoware_ad_api_msgs/srv/ClearRoute"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/clear_route/#definition","text":"--- autoware_ad_api_msgs/ResponseStatus status","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/clear_route/#this-type-uses","text":"autoware_ad_api_msgs/msg/ResponseStatus","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/initialize_localization/","text":"autoware_ad_api_msgs/srv/InitializeLocalization # Definition # geometry_msgs/PoseWithCovarianceStamped[<=1] pose --- autoware_ad_api_msgs/ResponseStatus status This type uses # autoware_ad_api_msgs/msg/ResponseStatus","title":"autoware_ad_api_msgs/srv/InitializeLocalization"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/initialize_localization/#autoware_ad_api_msgssrvinitializelocalization","text":"","title":"autoware_ad_api_msgs/srv/InitializeLocalization"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/initialize_localization/#definition","text":"geometry_msgs/PoseWithCovarianceStamped[<=1] pose --- autoware_ad_api_msgs/ResponseStatus status","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/initialize_localization/#this-type-uses","text":"autoware_ad_api_msgs/msg/ResponseStatus","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/interface_version/","text":"autoware_ad_api_msgs/srv/InterfaceVersion # Definition # --- uint16 major uint16 minor uint16 patch This type uses # None","title":"autoware_ad_api_msgs/srv/InterfaceVersion"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/interface_version/#autoware_ad_api_msgssrvinterfaceversion","text":"","title":"autoware_ad_api_msgs/srv/InterfaceVersion"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/interface_version/#definition","text":"--- uint16 major uint16 minor uint16 patch","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/interface_version/#this-type-uses","text":"None","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/set_route/","text":"autoware_ad_api_msgs/srv/SetRoute # Definition # std_msgs/Header header geometry_msgs/Pose[<=1] start geometry_msgs/Pose goal autoware_ad_api_msgs/RouteSegment[] segments --- autoware_ad_api_msgs/ResponseStatus status This type uses # autoware_ad_api_msgs/msg/ResponseStatus autoware_ad_api_msgs/msg/RouteSegment","title":"autoware_ad_api_msgs/srv/SetRoute"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/set_route/#autoware_ad_api_msgssrvsetroute","text":"","title":"autoware_ad_api_msgs/srv/SetRoute"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/set_route/#definition","text":"std_msgs/Header header geometry_msgs/Pose[<=1] start geometry_msgs/Pose goal autoware_ad_api_msgs/RouteSegment[] segments --- autoware_ad_api_msgs/ResponseStatus status","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/set_route/#this-type-uses","text":"autoware_ad_api_msgs/msg/ResponseStatus autoware_ad_api_msgs/msg/RouteSegment","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/set_route_points/","text":"autoware_ad_api_msgs/srv/SetRoutePoints # Definition # std_msgs/Header header geometry_msgs/Pose[<=1] start geometry_msgs/Pose goal geometry_msgs/Pose[] waypoints --- autoware_ad_api_msgs/ResponseStatus status This type uses # autoware_ad_api_msgs/msg/ResponseStatus","title":"autoware_ad_api_msgs/srv/SetRoutePoints"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/set_route_points/#autoware_ad_api_msgssrvsetroutepoints","text":"","title":"autoware_ad_api_msgs/srv/SetRoutePoints"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/set_route_points/#definition","text":"std_msgs/Header header geometry_msgs/Pose[<=1] start geometry_msgs/Pose goal geometry_msgs/Pose[] waypoints --- autoware_ad_api_msgs/ResponseStatus status","title":"Definition"},{"location":"design/autoware-interfaces/ad-api/types/autoware_ad_api_msgs/srv/set_route_points/#this-type-uses","text":"autoware_ad_api_msgs/msg/ResponseStatus","title":"This type uses"},{"location":"design/autoware-interfaces/ad-api/use-cases/","text":"Use cases of Autoware AD API # User stories # The user stories are service scenarios that AD API assumes. AD API is designed based on these scenarios. Each scenario is realized by a combination of use cases described later. If there are scenarios that cannot be covered, please discuss adding a user story. Bus service Taxi service Use cases # Use cases are partial scenarios derived from the user story and generically designed. Service providers can combine these use cases to define user stories and check if AD API can be applied to their own scenarios. Launch and terminate Initialize the pose Change the operation mode Drive to the designated position Get on and get off","title":"Use cases of Autoware AD API"},{"location":"design/autoware-interfaces/ad-api/use-cases/#use-cases-of-autoware-ad-api","text":"","title":"Use cases of Autoware AD API"},{"location":"design/autoware-interfaces/ad-api/use-cases/#user-stories","text":"The user stories are service scenarios that AD API assumes. AD API is designed based on these scenarios. Each scenario is realized by a combination of use cases described later. If there are scenarios that cannot be covered, please discuss adding a user story. Bus service Taxi service","title":"User stories"},{"location":"design/autoware-interfaces/ad-api/use-cases/#use-cases","text":"Use cases are partial scenarios derived from the user story and generically designed. Service providers can combine these use cases to define user stories and check if AD API can be applied to their own scenarios. Launch and terminate Initialize the pose Change the operation mode Drive to the designated position Get on and get off","title":"Use cases"},{"location":"design/autoware-interfaces/ad-api/use-cases/bus-service/","text":"User story of bus service # Overview # This user story is a bus service that goes around the designated stops. Scenario # Step Operation Use Case 1 Startup the autonomous driving system. Launch and terminate 2 Drive the vehicle from the garage to the waiting position. Change the operation mode 3 Enable autonomous control. Change the operation mode 4 Drive the vehicle to the next bus stop. Drive to the designated position 5 Get on and off the vehicle. Get on and get off 6 Return to step 4 unless it's the last bus stop. 7 Drive the vehicle to the waiting position. Drive to the designated position 8 Drive the vehicle from the waiting position to the garage. Change the operation mode 9 Shutdown the autonomous driving system. Launch and terminate","title":"User story of bus service"},{"location":"design/autoware-interfaces/ad-api/use-cases/bus-service/#user-story-of-bus-service","text":"","title":"User story of bus service"},{"location":"design/autoware-interfaces/ad-api/use-cases/bus-service/#overview","text":"This user story is a bus service that goes around the designated stops.","title":"Overview"},{"location":"design/autoware-interfaces/ad-api/use-cases/bus-service/#scenario","text":"Step Operation Use Case 1 Startup the autonomous driving system. Launch and terminate 2 Drive the vehicle from the garage to the waiting position. Change the operation mode 3 Enable autonomous control. Change the operation mode 4 Drive the vehicle to the next bus stop. Drive to the designated position 5 Get on and off the vehicle. Get on and get off 6 Return to step 4 unless it's the last bus stop. 7 Drive the vehicle to the waiting position. Drive to the designated position 8 Drive the vehicle from the waiting position to the garage. Change the operation mode 9 Shutdown the autonomous driving system. Launch and terminate","title":"Scenario"},{"location":"design/autoware-interfaces/ad-api/use-cases/change-operation-mode/","text":"Change the operation mode # Related API # Operation mode Sequence # Change the mode with software switch. Change the mode with hardware switch.","title":"Change the operation mode"},{"location":"design/autoware-interfaces/ad-api/use-cases/change-operation-mode/#change-the-operation-mode","text":"","title":"Change the operation mode"},{"location":"design/autoware-interfaces/ad-api/use-cases/change-operation-mode/#related-api","text":"Operation mode","title":"Related API"},{"location":"design/autoware-interfaces/ad-api/use-cases/change-operation-mode/#sequence","text":"Change the mode with software switch. Change the mode with hardware switch.","title":"Sequence"},{"location":"design/autoware-interfaces/ad-api/use-cases/drive-designated-position/","text":"Drive to the designated position # Related API # Driving Route Sequence #","title":"Drive to the designated position"},{"location":"design/autoware-interfaces/ad-api/use-cases/drive-designated-position/#drive-to-the-designated-position","text":"","title":"Drive to the designated position"},{"location":"design/autoware-interfaces/ad-api/use-cases/drive-designated-position/#related-api","text":"Driving Route","title":"Related API"},{"location":"design/autoware-interfaces/ad-api/use-cases/drive-designated-position/#sequence","text":"","title":"Sequence"},{"location":"design/autoware-interfaces/ad-api/use-cases/get-on-off/","text":"Get on and get off # Related API # Door Sequence #","title":"Get on and get off"},{"location":"design/autoware-interfaces/ad-api/use-cases/get-on-off/#get-on-and-get-off","text":"","title":"Get on and get off"},{"location":"design/autoware-interfaces/ad-api/use-cases/get-on-off/#related-api","text":"Door","title":"Related API"},{"location":"design/autoware-interfaces/ad-api/use-cases/get-on-off/#sequence","text":"","title":"Sequence"},{"location":"design/autoware-interfaces/ad-api/use-cases/initialize-pose/","text":"Initialize the pose # Related API # Pose Sequence # Initialization of the pose using input. Initialization of the pose using GNSS .","title":"Initialize the pose"},{"location":"design/autoware-interfaces/ad-api/use-cases/initialize-pose/#initialize-the-pose","text":"","title":"Initialize the pose"},{"location":"design/autoware-interfaces/ad-api/use-cases/initialize-pose/#related-api","text":"Pose","title":"Related API"},{"location":"design/autoware-interfaces/ad-api/use-cases/initialize-pose/#sequence","text":"Initialization of the pose using input. Initialization of the pose using GNSS .","title":"Sequence"},{"location":"design/autoware-interfaces/ad-api/use-cases/launch-terminate/","text":"Launch and terminate # Related API # Interface Launcher Sequence #","title":"Launch and terminate"},{"location":"design/autoware-interfaces/ad-api/use-cases/launch-terminate/#launch-and-terminate","text":"","title":"Launch and terminate"},{"location":"design/autoware-interfaces/ad-api/use-cases/launch-terminate/#related-api","text":"Interface Launcher","title":"Related API"},{"location":"design/autoware-interfaces/ad-api/use-cases/launch-terminate/#sequence","text":"","title":"Sequence"},{"location":"design/autoware-interfaces/ad-api/use-cases/taxi-service/","text":"User story of bus service # Overview # This user story is a taxi service that picks up passengers and drives them to their destination. Scenario # Step Operation Use Case 1 Startup the autonomous driving system. Launch and terminate 2 Drive the vehicle from the garage to the waiting position. Change the operation mode 3 Enable autonomous control. Change the operation mode 4 Drive the vehicle to the position to pick up. Drive to the designated position 5 Get on the vehicle. Get on and get off 6 Drive the vehicle to the destination. Drive to the designated position 7 Get off the vehicle. Get on and get off 8 Drive the vehicle to the waiting position. Drive to the designated position 9 Return to step 4 if there is another request. 10 Drive the vehicle from the waiting position to the garage. Change the operation mode 11 Shutdown the autonomous driving system. Launch and terminate","title":"User story of bus service"},{"location":"design/autoware-interfaces/ad-api/use-cases/taxi-service/#user-story-of-bus-service","text":"","title":"User story of bus service"},{"location":"design/autoware-interfaces/ad-api/use-cases/taxi-service/#overview","text":"This user story is a taxi service that picks up passengers and drives them to their destination.","title":"Overview"},{"location":"design/autoware-interfaces/ad-api/use-cases/taxi-service/#scenario","text":"Step Operation Use Case 1 Startup the autonomous driving system. Launch and terminate 2 Drive the vehicle from the garage to the waiting position. Change the operation mode 3 Enable autonomous control. Change the operation mode 4 Drive the vehicle to the position to pick up. Drive to the designated position 5 Get on the vehicle. Get on and get off 6 Drive the vehicle to the destination. Drive to the designated position 7 Get off the vehicle. Get on and get off 8 Drive the vehicle to the waiting position. Drive to the designated position 9 Return to step 4 if there is another request. 10 Drive the vehicle from the waiting position to the garage. Change the operation mode 11 Shutdown the autonomous driving system. Launch and terminate","title":"Scenario"},{"location":"design/autoware-interfaces/components/","text":"Component interfaces # Warning Under Construction","title":"Component interfaces"},{"location":"design/autoware-interfaces/components/#component-interfaces","text":"Warning Under Construction","title":"Component interfaces"},{"location":"design/autoware-interfaces/components/control/","text":"Control # Inputs # Vehicle kinematic state # Current position and orientation of ego. Published by the Localization module. nav_msgs/Odometry std_msgs/Header header string child_frame_id geometry_msgs/PoseWithCovariance pose geometry_msgs/TwistWithCovariance twist Trajectory # trajectory to be followed by the controller. See Outputs of Planning. Steering Status # Current steering of the ego vehicle. Published by the Vehicle Interface. Steering message ( github discussion ). builtin_interfaces::msg::Time stamp float32 steering_angle Actuation Status # Actuation status of the ego vehicle for acceleration, steering, and brake. TODO This represents the reported physical efforts exerted by the vehicle actuators. Published by the Vehicle Interface. ActuationStatus ( github discussion ). builtin_interfaces::msg::Time stamp float32 acceleration float32 steering Output # Vehicle Control Command # A motion signal to drive the vehicle, achieved by the low-level controller in the vehicle layer. Used by the Vehicle Interface. [autoware_auto_control_msgs/AckermannControlCommand]( https://gitlab.com/autowarefoundation/autoware.auto/autoware_auto_msgs/-/blob/master/autoware_auto_control_msgs/msg/AckermannControlCommand.idl builtin_interfaces::msg::Time stamp autoware_auto_control_msgs/AckermannLateralCommand lateral builtin_interfaces::msg::Time stamp float steering_tire_angle float steering_tire_rotation_rate autoware_auto_control_msgs/LongitudinalCommand longitudinal builtin_interfaces::msg::Time stamp builtin_interfaces::msg::Duration duration builtin_interfaces::msg::Duration time_step float[] speeds float[] accelerations float[] jerks","title":"Control"},{"location":"design/autoware-interfaces/components/control/#control","text":"","title":"Control"},{"location":"design/autoware-interfaces/components/control/#inputs","text":"","title":"Inputs"},{"location":"design/autoware-interfaces/components/control/#vehicle-kinematic-state","text":"Current position and orientation of ego. Published by the Localization module. nav_msgs/Odometry std_msgs/Header header string child_frame_id geometry_msgs/PoseWithCovariance pose geometry_msgs/TwistWithCovariance twist","title":"Vehicle kinematic state"},{"location":"design/autoware-interfaces/components/control/#trajectory","text":"trajectory to be followed by the controller. See Outputs of Planning.","title":"Trajectory"},{"location":"design/autoware-interfaces/components/control/#steering-status","text":"Current steering of the ego vehicle. Published by the Vehicle Interface. Steering message ( github discussion ). builtin_interfaces::msg::Time stamp float32 steering_angle","title":"Steering Status"},{"location":"design/autoware-interfaces/components/control/#actuation-status","text":"Actuation status of the ego vehicle for acceleration, steering, and brake. TODO This represents the reported physical efforts exerted by the vehicle actuators. Published by the Vehicle Interface. ActuationStatus ( github discussion ). builtin_interfaces::msg::Time stamp float32 acceleration float32 steering","title":"Actuation Status"},{"location":"design/autoware-interfaces/components/control/#output","text":"","title":"Output"},{"location":"design/autoware-interfaces/components/control/#vehicle-control-command","text":"A motion signal to drive the vehicle, achieved by the low-level controller in the vehicle layer. Used by the Vehicle Interface. [autoware_auto_control_msgs/AckermannControlCommand]( https://gitlab.com/autowarefoundation/autoware.auto/autoware_auto_msgs/-/blob/master/autoware_auto_control_msgs/msg/AckermannControlCommand.idl builtin_interfaces::msg::Time stamp autoware_auto_control_msgs/AckermannLateralCommand lateral builtin_interfaces::msg::Time stamp float steering_tire_angle float steering_tire_rotation_rate autoware_auto_control_msgs/LongitudinalCommand longitudinal builtin_interfaces::msg::Time stamp builtin_interfaces::msg::Duration duration builtin_interfaces::msg::Duration time_step float[] speeds float[] accelerations float[] jerks","title":"Vehicle Control Command"},{"location":"design/autoware-interfaces/components/planning/","text":"Planning # Inputs # 3D Object Predictions # set of perceived objects around ego that need to be avoided when planning a trajectory. Published by the Perception module. autoware_auto_perception_msgs/msg/PredictedObjects std_msgs/Header header sequence< autoware_auto_perception_msgs::msg::PredictedObject > objects unique_identifier_msgs::msg::UUID uuid float existence_probability sequence< autoware_auto_perception_msgs::msg::ObjectClassification > classification uint8 classification float probability autoware_auto_perception_msgs::msg::PredictedObjectKinematics kinematics geometry_msgs::msg::PoseWithCovariance initial_pose geometry_msgs::msg::TwistWithCovariance geometry_msgs::msg::AccelWithCovariance initial_acceleration sequence< autoware_auto_perception_msgs::msg::PredictedPath , 10> predicted_paths sequence< geometry_msgs::msg::Pose , 100> path builtin_interfaces::msg::Duration time_step float confidence sequence< autoware_auto_perception_msgs::msg::Shape , 5> shape geometry_msgs::msg::Polygon polygon float height Traffic Light Response # Service response with traffic light information. The message definition is under discussion. TrafficLightResponse uint64 traffic_light_id uint8 traffic_light_state With the traffic_light_state being one of the following GREEN = 1 GREEN_BLINKING = 2 YELLOW = 3 YELLOW_BLINKING = 4 RED = 5 RED_BLINKING = 6 OFF = 7 UNKNOWN = 8 Vehicle kinematic state # current position and orientation of ego. Published by the Localization module. VehicleKinematicState nav_msgs/Odometry std_msgs/Header header string child_frame_id geometry_msgs/PoseWithCovariance pose geometry_msgs/TwistWithCovariance twist Lanelet2 Map # map of the environment where the planning takes place. Published by the Map Server. autoware_auto_mapping_msgs/msg/HADMapBin std_msgs::msg::Header header uint8 map_format string format_version string map_version sequence < uint8 > data Goal Pose # target pose of ego. Published by the User Interface. geometry_msgs/PoseStamped Engagement Response # TBD. The message definition is under discussion. Error status # a status corresponding to the current state of Autoware. Used by the Vehicle Interface to switch between different modes in case of emergency. Published by the Diagnostic Manager. autoware_auto_system_msgs/msg/EmergencyState builtin_interfaces::msg::Time stamp uint8 state With the state being one of the following: NORMAL = 1 OVERRIDE_REQUESTING = 2 MRM_OPERATING = 3 MRM_SUCCEEDED = 4 MRM_FAILED = 5 [TODO] original design for these messages: diagnostic manager also publishes an overriding emergency control command ( Add the monitoring system related messages - Autoware.Auto ). Possible new design: gate of the vehicle interface switches to the emergency control command (generated by another controller) when receiving an OVERRIDE_REQUESTING message. The message definition is under discussion. Outputs # Traffic Light Query # service request for the state of a specific traffic light. Sent to the Perception module. uint64 traffic_light_id The message definition is under discussion. Trajectory # A sequence of space and velocity points to be followed by the controller. autoware_auto_planning_msgs/Trajectory std_msgs/Header header sequence< autoware_auto_planning_msgs::msg::TrajectoryPoint , 100> points builtin_interfaces::msg::Duration time_from_start geometry_msgs::msg::Pose pose float longitudinal_velocity_mps float lateral_velocity_mps float acceleration_mps2 float heading_rate_rps float front_wheel_angle_rad float rear_wheel_angle_rad Vehicle Signal Commands # Commands for various elements of the vehicle unrelated to motion. Sent to the Vehicle Interface. (For the definition, see autoware_auto_vehicle_msgs .) HandBrake Command Hazard Lights Command Headlights Command Horn Command Stationary Locking Command Turn Indicator Command Wipers Command Missions Status # TBD. The message definition is under discussion. Engagement Request # TBD, The message definition is under discussion.","title":"Planning"},{"location":"design/autoware-interfaces/components/planning/#planning","text":"","title":"Planning"},{"location":"design/autoware-interfaces/components/planning/#inputs","text":"","title":"Inputs"},{"location":"design/autoware-interfaces/components/planning/#3d-object-predictions","text":"set of perceived objects around ego that need to be avoided when planning a trajectory. Published by the Perception module. autoware_auto_perception_msgs/msg/PredictedObjects std_msgs/Header header sequence< autoware_auto_perception_msgs::msg::PredictedObject > objects unique_identifier_msgs::msg::UUID uuid float existence_probability sequence< autoware_auto_perception_msgs::msg::ObjectClassification > classification uint8 classification float probability autoware_auto_perception_msgs::msg::PredictedObjectKinematics kinematics geometry_msgs::msg::PoseWithCovariance initial_pose geometry_msgs::msg::TwistWithCovariance geometry_msgs::msg::AccelWithCovariance initial_acceleration sequence< autoware_auto_perception_msgs::msg::PredictedPath , 10> predicted_paths sequence< geometry_msgs::msg::Pose , 100> path builtin_interfaces::msg::Duration time_step float confidence sequence< autoware_auto_perception_msgs::msg::Shape , 5> shape geometry_msgs::msg::Polygon polygon float height","title":"3D Object Predictions"},{"location":"design/autoware-interfaces/components/planning/#traffic-light-response","text":"Service response with traffic light information. The message definition is under discussion. TrafficLightResponse uint64 traffic_light_id uint8 traffic_light_state With the traffic_light_state being one of the following GREEN = 1 GREEN_BLINKING = 2 YELLOW = 3 YELLOW_BLINKING = 4 RED = 5 RED_BLINKING = 6 OFF = 7 UNKNOWN = 8","title":"Traffic Light Response"},{"location":"design/autoware-interfaces/components/planning/#vehicle-kinematic-state","text":"current position and orientation of ego. Published by the Localization module. VehicleKinematicState nav_msgs/Odometry std_msgs/Header header string child_frame_id geometry_msgs/PoseWithCovariance pose geometry_msgs/TwistWithCovariance twist","title":"Vehicle kinematic state"},{"location":"design/autoware-interfaces/components/planning/#lanelet2-map","text":"map of the environment where the planning takes place. Published by the Map Server. autoware_auto_mapping_msgs/msg/HADMapBin std_msgs::msg::Header header uint8 map_format string format_version string map_version sequence < uint8 > data","title":"Lanelet2 Map"},{"location":"design/autoware-interfaces/components/planning/#goal-pose","text":"target pose of ego. Published by the User Interface. geometry_msgs/PoseStamped","title":"Goal Pose"},{"location":"design/autoware-interfaces/components/planning/#engagement-response","text":"TBD. The message definition is under discussion.","title":"Engagement Response"},{"location":"design/autoware-interfaces/components/planning/#error-status","text":"a status corresponding to the current state of Autoware. Used by the Vehicle Interface to switch between different modes in case of emergency. Published by the Diagnostic Manager. autoware_auto_system_msgs/msg/EmergencyState builtin_interfaces::msg::Time stamp uint8 state With the state being one of the following: NORMAL = 1 OVERRIDE_REQUESTING = 2 MRM_OPERATING = 3 MRM_SUCCEEDED = 4 MRM_FAILED = 5 [TODO] original design for these messages: diagnostic manager also publishes an overriding emergency control command ( Add the monitoring system related messages - Autoware.Auto ). Possible new design: gate of the vehicle interface switches to the emergency control command (generated by another controller) when receiving an OVERRIDE_REQUESTING message. The message definition is under discussion.","title":"Error status"},{"location":"design/autoware-interfaces/components/planning/#outputs","text":"","title":"Outputs"},{"location":"design/autoware-interfaces/components/planning/#traffic-light-query","text":"service request for the state of a specific traffic light. Sent to the Perception module. uint64 traffic_light_id The message definition is under discussion.","title":"Traffic Light Query"},{"location":"design/autoware-interfaces/components/planning/#trajectory","text":"A sequence of space and velocity points to be followed by the controller. autoware_auto_planning_msgs/Trajectory std_msgs/Header header sequence< autoware_auto_planning_msgs::msg::TrajectoryPoint , 100> points builtin_interfaces::msg::Duration time_from_start geometry_msgs::msg::Pose pose float longitudinal_velocity_mps float lateral_velocity_mps float acceleration_mps2 float heading_rate_rps float front_wheel_angle_rad float rear_wheel_angle_rad","title":"Trajectory"},{"location":"design/autoware-interfaces/components/planning/#vehicle-signal-commands","text":"Commands for various elements of the vehicle unrelated to motion. Sent to the Vehicle Interface. (For the definition, see autoware_auto_vehicle_msgs .) HandBrake Command Hazard Lights Command Headlights Command Horn Command Stationary Locking Command Turn Indicator Command Wipers Command","title":"Vehicle Signal Commands"},{"location":"design/autoware-interfaces/components/planning/#missions-status","text":"TBD. The message definition is under discussion.","title":"Missions Status"},{"location":"design/autoware-interfaces/components/planning/#engagement-request","text":"TBD, The message definition is under discussion.","title":"Engagement Request"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/","text":"Vehicle dimensions # Vehicle axes and base_link # The base_link frame is used very frequently throughout the Autoware stack, and is a projection of the rear-axle center onto the ground surface. Localization module outputs the map to base_link transformation. Planning module plans the poses for where the base_link frame should be in the future. Control module tries to fit base_link to incoming poses. Vehicle dimensions # wheelbase # The distance between front and rear axles. track_width # The distance between left and right wheels. Overhangs # Overhangs are part of the minimum safety box calculation. When measuring overhangs, side mirrors, protruding sensors and wheels should be taken into consideration. left_overhang # The distance between the axis centers of the left wheels and the left-most point of the vehicle. right_overhang # The distance between the axis centers of the right wheels and the right-most point of the vehicle. front_overhang # The distance between the front axle and the foremost point of the vehicle. rear_overhang # The distance between the rear axle and the rear-most point of the vehicle. vehicle_length # Total length of the vehicle. Calculated by front_overhang + wheelbase + rear_overhang vehicle_width # Total width of the vehicle. Calculated by left_overhang + track_width + right_overhang Wheel parameters # wheel_width # The lateral width of a wheel tire, primarily used for dead reckoning. wheel_radius # The radius of the wheel, primarily used for dead reckoning. polygon_footprint # The polygon defines the minimum collision area for the vehicle. The points should be ordered clockwise, with the origin on the base_link . Wheel orientations # If the vehicle is going forward, a positive wheel angle will result in the vehicle turning left. Autoware assumes the rear wheels don't turn on z axis. Notice # The vehicle used in the illustrations was created by xvlblo22 and is from https://www.turbosquid.com/3d-models/modular-sedan-3d-model-1590886 .","title":"Vehicle dimensions"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/#vehicle-dimensions","text":"","title":"Vehicle dimensions"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/#vehicle-axes-and-base_link","text":"The base_link frame is used very frequently throughout the Autoware stack, and is a projection of the rear-axle center onto the ground surface. Localization module outputs the map to base_link transformation. Planning module plans the poses for where the base_link frame should be in the future. Control module tries to fit base_link to incoming poses.","title":"Vehicle axes and base_link"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/#vehicle-dimensions_1","text":"","title":"Vehicle dimensions"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/#wheelbase","text":"The distance between front and rear axles.","title":"wheelbase"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/#track_width","text":"The distance between left and right wheels.","title":"track_width"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/#overhangs","text":"Overhangs are part of the minimum safety box calculation. When measuring overhangs, side mirrors, protruding sensors and wheels should be taken into consideration.","title":"Overhangs"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/#vehicle_length","text":"Total length of the vehicle. Calculated by front_overhang + wheelbase + rear_overhang","title":"vehicle_length"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/#vehicle_width","text":"Total width of the vehicle. Calculated by left_overhang + track_width + right_overhang","title":"vehicle_width"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/#wheel-parameters","text":"","title":"Wheel parameters"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/#polygon_footprint","text":"The polygon defines the minimum collision area for the vehicle. The points should be ordered clockwise, with the origin on the base_link .","title":"polygon_footprint"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/#wheel-orientations","text":"If the vehicle is going forward, a positive wheel angle will result in the vehicle turning left. Autoware assumes the rear wheels don't turn on z axis.","title":"Wheel orientations"},{"location":"design/autoware-interfaces/components/vehicle-dimensions/#notice","text":"The vehicle used in the illustrations was created by xvlblo22 and is from https://www.turbosquid.com/3d-models/modular-sedan-3d-model-1590886 .","title":"Notice"},{"location":"design/autoware-interfaces/components/vehicle-interface/","text":"Vehicle Interface # The Vehicle Interface receives the Vehicle Signal Commands and Vehicle Control Commands and publishes the vehicle status. It also communicates with vehicle by the vehicle-specific protocol. The Gate switches multiple Vehicle Control Commands . These signals include autonomous diving command, joystick, remote control, and emergency operation, etc. The Adapter converts generalized control command (target steering, steering rate, velocity, acceleration, jerk) into vehicle-specific control values (steering-torque, wheel-torque, voltage, pressure, accel pedal position, etc). Inputs # Error status # (See Inputs of Planning.) Vehicle Control Command # (See Output of Control.) Vehicle Signals Commands # Commands for various elements of the vehicle unrelated to motion. Published by the Planning module. Outputs # Vehicle Signal Reports # Reports for various elements of the vehicle unrelated to motion. Published by the Vehicle Interface. Vehicle Odometry # Odometry of the vehicle. Used by the Localization module to update the pose of the vehicle in the map. geometry_msgs/TwistWithCovarianceStamped odometry Steering Status # Steering of the ego vehicle. Published by the Vehicle Interface. Steering message ( github discussion ). builtin_interfaces::msg::Time stamp float32 steering_angle Actuation Status # Actuation status of the ego vehicle for acceleration, steering, and brake. This represents the reported physical efforts exerted by the vehicle actuators. Published by the Vehicle Interface. ActuationStatus ( github discussion ). builtin_interfaces::msg::Time stamp float32 acceleration float32 steering float32 brake The message definition is under discussion. Actuation Command # Actuation command sent to the ego vehicle. This represents the requested physical efforts to be exerted by the vehicle actuators. Published by the Vehicle Interface as generated by the adapter. ActuationCommand ( github discussion .) builtin_interfaces::msg::Time stamp float32 acceleration float32 steering float32 brake The message definition is under discussion. Vehicle Communication # Vehicle specific messages protocol like CAN (Controller Area Network).","title":"Vehicle Interface"},{"location":"design/autoware-interfaces/components/vehicle-interface/#vehicle-interface","text":"The Vehicle Interface receives the Vehicle Signal Commands and Vehicle Control Commands and publishes the vehicle status. It also communicates with vehicle by the vehicle-specific protocol. The Gate switches multiple Vehicle Control Commands . These signals include autonomous diving command, joystick, remote control, and emergency operation, etc. The Adapter converts generalized control command (target steering, steering rate, velocity, acceleration, jerk) into vehicle-specific control values (steering-torque, wheel-torque, voltage, pressure, accel pedal position, etc).","title":"Vehicle Interface"},{"location":"design/autoware-interfaces/components/vehicle-interface/#inputs","text":"","title":"Inputs"},{"location":"design/autoware-interfaces/components/vehicle-interface/#error-status","text":"(See Inputs of Planning.)","title":"Error status"},{"location":"design/autoware-interfaces/components/vehicle-interface/#vehicle-control-command","text":"(See Output of Control.)","title":"Vehicle Control Command"},{"location":"design/autoware-interfaces/components/vehicle-interface/#vehicle-signals-commands","text":"Commands for various elements of the vehicle unrelated to motion. Published by the Planning module.","title":"Vehicle Signals Commands"},{"location":"design/autoware-interfaces/components/vehicle-interface/#outputs","text":"","title":"Outputs"},{"location":"design/autoware-interfaces/components/vehicle-interface/#vehicle-signal-reports","text":"Reports for various elements of the vehicle unrelated to motion. Published by the Vehicle Interface.","title":"Vehicle Signal Reports"},{"location":"design/autoware-interfaces/components/vehicle-interface/#vehicle-odometry","text":"Odometry of the vehicle. Used by the Localization module to update the pose of the vehicle in the map. geometry_msgs/TwistWithCovarianceStamped odometry","title":"Vehicle Odometry"},{"location":"design/autoware-interfaces/components/vehicle-interface/#steering-status","text":"Steering of the ego vehicle. Published by the Vehicle Interface. Steering message ( github discussion ). builtin_interfaces::msg::Time stamp float32 steering_angle","title":"Steering Status"},{"location":"design/autoware-interfaces/components/vehicle-interface/#actuation-status","text":"Actuation status of the ego vehicle for acceleration, steering, and brake. This represents the reported physical efforts exerted by the vehicle actuators. Published by the Vehicle Interface. ActuationStatus ( github discussion ). builtin_interfaces::msg::Time stamp float32 acceleration float32 steering float32 brake The message definition is under discussion.","title":"Actuation Status"},{"location":"design/autoware-interfaces/components/vehicle-interface/#actuation-command","text":"Actuation command sent to the ego vehicle. This represents the requested physical efforts to be exerted by the vehicle actuators. Published by the Vehicle Interface as generated by the adapter. ActuationCommand ( github discussion .) builtin_interfaces::msg::Time stamp float32 acceleration float32 steering float32 brake The message definition is under discussion.","title":"Actuation Command"},{"location":"design/autoware-interfaces/components/vehicle-interface/#vehicle-communication","text":"Vehicle specific messages protocol like CAN (Controller Area Network).","title":"Vehicle Communication"},{"location":"design/configuration-management/","text":"Configuration management # Warning Under Construction","title":"Configuration management"},{"location":"design/configuration-management/#configuration-management","text":"Warning Under Construction","title":"Configuration management"},{"location":"design/configuration-management/development-process/","text":"Development process # Warning Under Construction","title":"Development process"},{"location":"design/configuration-management/development-process/#development-process","text":"Warning Under Construction","title":"Development process"},{"location":"design/configuration-management/release-process/","text":"Release process # Warning Under Construction","title":"Release process"},{"location":"design/configuration-management/release-process/#release-process","text":"Warning Under Construction","title":"Release process"},{"location":"design/configuration-management/repository-structure/","text":"Repository structure # Warning Under Construction","title":"Repository structure"},{"location":"design/configuration-management/repository-structure/#repository-structure","text":"Warning Under Construction","title":"Repository structure"},{"location":"how-to-guides/","text":"How-to guides # Advanced usage of colcon Creating maps for Autoware Determining component dependencies Integrating Autoware with your vehicle Integrating Autoware with a differential drive vehicle Running Autoware without CUDA Calibrating your sensors TODO: Write the following contents. Create an Autoware package Add a custom ROS message Debug Autoware etc.","title":"How-to guides"},{"location":"how-to-guides/#how-to-guides","text":"Advanced usage of colcon Creating maps for Autoware Determining component dependencies Integrating Autoware with your vehicle Integrating Autoware with a differential drive vehicle Running Autoware without CUDA Calibrating your sensors TODO: Write the following contents. Create an Autoware package Add a custom ROS message Debug Autoware etc.","title":"How-to guides"},{"location":"how-to-guides/advanced-usage-of-colcon/","text":"Advanced usage of colcon # This page shows some advanced and useful usage of colcon . If you need more detailed information, refer to the colcon documentation . Common mistakes # Do not run from other than the workspace root # It is important that you always run colcon build from the workspace root because colcon builds only under the current directory. If you have mistakenly built in a wrong directory, run rm -rf build/ install/ log/ to clean the generated files. Do not unnecessarily overlay workspaces # colcon overlays workspaces if you have sourced the setup.bash of other workspaces before building a workspace. You should take care of this especially when you have multiple workspaces. Run echo $COLCON_PREFIX_PATH to check whether workspaces are overlaid. If you find some workspaces are unnecessarily overlaid, remove all built files, restart the terminal to clean environment variables, and re-build the workspace. For more details about workspace overlaying , refer to the ROS 2 documentation . Cleaning up the build artifacts # colcon sometimes causes errors of because of the old cache. To remove the cache and rebuild the workspace, run the following command: rm -rf build/ install/ In case you know what packages to remove: rm -rf { build,install } / { package_a,package_b } Selecting packages to build # To just build specified packages: colcon build --packages-select <package_name1> <package_name2> ... To build specified packages and their dependencies recursively: colcon build --packages-up-to <package_name1> <package_name2> ... You can also use these options for colcon test . Changing the optimization level # Set DCMAKE_BUILD_TYPE to change the optimization level. Warning If you specify DCMAKE_BUILD_TYPE=Debug or no DCMAKE_BUILD_TYPE is given for building the entire Autoware, it may be too slow to use. colcon build --cmake-args -DCMAKE_BUILD_TYPE = Debug colcon build --cmake-args -DCMAKE_BUILD_TYPE = RelWithDebInfo colcon build --cmake-args -DCMAKE_BUILD_TYPE = Release Changing the default configuration of colcon # Create $COLCON_HOME/defaults.yaml to change the default configuration. mkdir -p ~/.colcon cat << EOS > ~/.colcon/defaults.yaml { \"build\" : { \"symlink-install\" : true } } For more details, see here . Generating compile_commands.json # compile_commands.json is used by IDEs/tools to analyze the build dependencies and symbol relationships. You can generate it with the flag DCMAKE_EXPORT_COMPILE_COMMANDS=1 : colcon build --cmake-args -DCMAKE_EXPORT_COMPILE_COMMANDS = 1 Seeing compiler commands # To see the compiler and linker invocations for a package, use VERBOSE=1 and --event-handlers console_cohesion+ : VERBOSE = 1 colcon build --packages-up-to <package_name> --event-handlers console_cohesion+ For other options, see here . Using Ccache # Ccache can speed up recompilation. It is recommended to use it to save your time unless you have a specific reason not to do so. Install Ccache : sudo apt update && sudo apt install ccache Write the following in your .bashrc : export CC = \"/usr/lib/ccache/gcc\" export CXX = \"/usr/lib/ccache/g++\"","title":"Advanced usage of colcon"},{"location":"how-to-guides/advanced-usage-of-colcon/#advanced-usage-of-colcon","text":"This page shows some advanced and useful usage of colcon . If you need more detailed information, refer to the colcon documentation .","title":"Advanced usage of colcon"},{"location":"how-to-guides/advanced-usage-of-colcon/#common-mistakes","text":"","title":"Common mistakes"},{"location":"how-to-guides/advanced-usage-of-colcon/#do-not-run-from-other-than-the-workspace-root","text":"It is important that you always run colcon build from the workspace root because colcon builds only under the current directory. If you have mistakenly built in a wrong directory, run rm -rf build/ install/ log/ to clean the generated files.","title":"Do not run from other than the workspace root"},{"location":"how-to-guides/advanced-usage-of-colcon/#do-not-unnecessarily-overlay-workspaces","text":"colcon overlays workspaces if you have sourced the setup.bash of other workspaces before building a workspace. You should take care of this especially when you have multiple workspaces. Run echo $COLCON_PREFIX_PATH to check whether workspaces are overlaid. If you find some workspaces are unnecessarily overlaid, remove all built files, restart the terminal to clean environment variables, and re-build the workspace. For more details about workspace overlaying , refer to the ROS 2 documentation .","title":"Do not unnecessarily overlay workspaces"},{"location":"how-to-guides/advanced-usage-of-colcon/#cleaning-up-the-build-artifacts","text":"colcon sometimes causes errors of because of the old cache. To remove the cache and rebuild the workspace, run the following command: rm -rf build/ install/ In case you know what packages to remove: rm -rf { build,install } / { package_a,package_b }","title":"Cleaning up the build artifacts"},{"location":"how-to-guides/advanced-usage-of-colcon/#selecting-packages-to-build","text":"To just build specified packages: colcon build --packages-select <package_name1> <package_name2> ... To build specified packages and their dependencies recursively: colcon build --packages-up-to <package_name1> <package_name2> ... You can also use these options for colcon test .","title":"Selecting packages to build"},{"location":"how-to-guides/advanced-usage-of-colcon/#changing-the-optimization-level","text":"Set DCMAKE_BUILD_TYPE to change the optimization level. Warning If you specify DCMAKE_BUILD_TYPE=Debug or no DCMAKE_BUILD_TYPE is given for building the entire Autoware, it may be too slow to use. colcon build --cmake-args -DCMAKE_BUILD_TYPE = Debug colcon build --cmake-args -DCMAKE_BUILD_TYPE = RelWithDebInfo colcon build --cmake-args -DCMAKE_BUILD_TYPE = Release","title":"Changing the optimization level"},{"location":"how-to-guides/advanced-usage-of-colcon/#changing-the-default-configuration-of-colcon","text":"Create $COLCON_HOME/defaults.yaml to change the default configuration. mkdir -p ~/.colcon cat << EOS > ~/.colcon/defaults.yaml { \"build\" : { \"symlink-install\" : true } } For more details, see here .","title":"Changing the default configuration of colcon"},{"location":"how-to-guides/advanced-usage-of-colcon/#generating-compile_commandsjson","text":"compile_commands.json is used by IDEs/tools to analyze the build dependencies and symbol relationships. You can generate it with the flag DCMAKE_EXPORT_COMPILE_COMMANDS=1 : colcon build --cmake-args -DCMAKE_EXPORT_COMPILE_COMMANDS = 1","title":"Generating compile_commands.json"},{"location":"how-to-guides/advanced-usage-of-colcon/#seeing-compiler-commands","text":"To see the compiler and linker invocations for a package, use VERBOSE=1 and --event-handlers console_cohesion+ : VERBOSE = 1 colcon build --packages-up-to <package_name> --event-handlers console_cohesion+ For other options, see here .","title":"Seeing compiler commands"},{"location":"how-to-guides/advanced-usage-of-colcon/#using-ccache","text":"Ccache can speed up recompilation. It is recommended to use it to save your time unless you have a specific reason not to do so. Install Ccache : sudo apt update && sudo apt install ccache Write the following in your .bashrc : export CC = \"/usr/lib/ccache/gcc\" export CXX = \"/usr/lib/ccache/g++\"","title":"Using Ccache"},{"location":"how-to-guides/calibrating-your-sensors/","text":"Calibrating your sensors # Overview # Autoware expects to have multiple sensors attached to the vehicle as input to perception, localization, and planning stack. These sensors must be calibrated correctly and their positions must be defined using either urdf files (as in sample_sensor_kit ) or as tf launch files. Camera calibration # Intrinsic Calibration # Navigation2 provides a good tutorial for camera internal calibration . AutoCore provides a light-weight tool . Lidar-lidar calibration # Lidar-Lidar Calibration tool from Autocore # LL-Calib on Github , provided by AutoCore , is a lightweight toolkit for online/offline 3D LiDAR to LiDAR calibration. It's based on local mapping and \"GICP\" method to derive the relation between main and sub lidar. Information on how to use the tool, troubleshooting tips and example rosbags can be found at the above link. Lidar-camera calibration # TBD Lidar- IMU calibration # Developed by APRIL Lab at Zhejiang University in China, the LI-Calib calibration tool is a toolkit for calibrating the 6DoF rigid transformation and the time offset between a 3D LiDAR and an IMU , based on continuous-time batch optimization. IMU -based cost and LiDAR point-to-surfel (surfel = surface element) distance are minimized jointly, which renders the calibration problem well-constrained in general scenarios. AutoCore has forked the original LI-Calib tool and overwritten the Lidar input for more general usage. Information on how to use the tool, troubleshooting tips and example rosbags can be found at the LI-Calib fork on Github .","title":"Calibrating your sensors"},{"location":"how-to-guides/calibrating-your-sensors/#calibrating-your-sensors","text":"","title":"Calibrating your sensors"},{"location":"how-to-guides/calibrating-your-sensors/#overview","text":"Autoware expects to have multiple sensors attached to the vehicle as input to perception, localization, and planning stack. These sensors must be calibrated correctly and their positions must be defined using either urdf files (as in sample_sensor_kit ) or as tf launch files.","title":"Overview"},{"location":"how-to-guides/calibrating-your-sensors/#camera-calibration","text":"","title":"Camera calibration"},{"location":"how-to-guides/calibrating-your-sensors/#intrinsic-calibration","text":"Navigation2 provides a good tutorial for camera internal calibration . AutoCore provides a light-weight tool .","title":"Intrinsic Calibration"},{"location":"how-to-guides/calibrating-your-sensors/#lidar-lidar-calibration","text":"","title":"Lidar-lidar calibration"},{"location":"how-to-guides/calibrating-your-sensors/#lidar-lidar-calibration-tool-from-autocore","text":"LL-Calib on Github , provided by AutoCore , is a lightweight toolkit for online/offline 3D LiDAR to LiDAR calibration. It's based on local mapping and \"GICP\" method to derive the relation between main and sub lidar. Information on how to use the tool, troubleshooting tips and example rosbags can be found at the above link.","title":"Lidar-Lidar Calibration tool from Autocore"},{"location":"how-to-guides/calibrating-your-sensors/#lidar-camera-calibration","text":"TBD","title":"Lidar-camera calibration"},{"location":"how-to-guides/calibrating-your-sensors/#lidar-imu-calibration","text":"Developed by APRIL Lab at Zhejiang University in China, the LI-Calib calibration tool is a toolkit for calibrating the 6DoF rigid transformation and the time offset between a 3D LiDAR and an IMU , based on continuous-time batch optimization. IMU -based cost and LiDAR point-to-surfel (surfel = surface element) distance are minimized jointly, which renders the calibration problem well-constrained in general scenarios. AutoCore has forked the original LI-Calib tool and overwritten the Lidar input for more general usage. Information on how to use the tool, troubleshooting tips and example rosbags can be found at the LI-Calib fork on Github .","title":"Lidar-IMU calibration"},{"location":"how-to-guides/creating-maps-for-autoware/","text":"Creating maps for Autoware # Autoware relies on high-definition point cloud maps and vector maps of the driving environment to perform various tasks such as localization, route planning, traffic light detection, and predicting the trajectories of pedestrians and other vehicles. The specifications for point cloud and vector maps required by Autoware are given below, along with examples of both open-source and proprietary software that you can use to create them. Point cloud maps # A 3D point cloud map is primarily used for LiDAR-based localization in Autoware. In order to determine the current position and orientation of the vehicle, a live scan captured from one or more LiDAR units is matched against a pre-generated 3D point cloud map. Therefore, an accurate point cloud map is crucial for good localization results. Point cloud map specifications # It must cover the entire operational area of the vehicle and should include an additional buffer zone of at least 200 m in all directions. It must be saved using the PCD (Point Cloud Data) file format , but can be a single PCD file or divided into multiple PCD files. Each point in the map must contain X, Y, and Z coordinates. An intensity or RGB value for each point may be optionally included. Its file size must be smaller than 1 GB, as per the current ROS message size limit . Its resolution should be at least 0.2 m to yield reliable localization results. It can be in either local or global coordinates, but must be in global coordinates (georeferenced) to use GNSS data for localization. Note Three global coordinate systems are supported by Autoware, including Military Grid Reference System (MGRS) , Universal Transverse Mercator (UTM) , and Japan Rectangular Coordinate System . However, MGRS is a preferred coordinate system for georeferenced maps. In a map with MGRS coordinate system, the X and Y coordinates of each point represent the point's location within the 100,000-meter square, while the Z coordinate represents the point's elevation. Creating a point cloud map # Traditionally, a Mobile Mapping System ( MMS ) is used in order to create highly accurate large-scale point cloud maps. However, since a MMS requires high-end sensors for precise positioning, its operational cost can be very expensive and may not be suitable for a relatively small driving environment. Alternatively, a Simultaneous Localization And Mapping ( SLAM ) algorithm can be used to create a point cloud map from recorded LiDAR scans. Commonly used open-source SLAM implementations are lidarslam-ros2 (LiDAR, IMU *) and LIO-SAM (LiDAR, IMU , GNSS ). The required sensor data for each algorithm is specified in the parentheses, where an asterisk (*) indicates that such sensor data is optional. For supported LiDAR models, please check the Github repository of each algorithm. While these ROS 2-based SLAM implementations can be easily installed and used directly on the same machine that runs Autoware, it is important to note that they may not be as well-tested or as mature as ROS 1-based alternatives. The notable open-source SLAM implementations that are based on ROS 1 include hdl-graph-slam (LiDAR, IMU *, GNSS *), LeGO-LOAM (LiDAR, IMU *), LeGO-LOAM-BOR (LiDAR), and LIO-SAM (LiDAR, IMU , GNSS ). Most of these algorithms already have a built-in loop-closure and pose graph optimization. However, if the built-in, automatic loop-closure fails or does not work correctly, you can use Interactive SLAM to adjust and optimize a pose graph manually. Since Autoware is based on ROS 2, it could be problematic if you want to install ROS 1-based SLAM implementations on the same machine. To avoid this problem, you can use Docker or simply install them on a different machine. Another problem is the ROSBAG version; these SLAM implementations require ROSBAG 1 instead of ROSBAG 2 used by Autoware. For the ROSBAG version problem, you may use this stand-alone converter to convert a ROSBAG 2 file to a ROSBAG 1 file and vice versa. If you prefer proprietary software that is easy to use, you can try a fully automatic mapping tool from MAP IV, Inc. , MapIV Engine . They currently provide a trial license for Autoware users free of charge. Vector maps # A vector map contains highly accurate information about a road network, lane geometry, and traffic lights. It is required for route planning, traffic light detection, and predicting the trajectories of other vehicles and pedestrians. Vector map specifications # It must cover the entire operational area of the vehicle and should include an additional buffer zone of at least 200 m in all directions. It must be in Lanelet2 format, with additional modifications required by Autoware . It must contain the shape and position information of lanes, traffic lights, stop lines, crosswalks, parking spaces, and parking lots. Each lanelet in the map must contain information regarding its right of way, speed limit, traffic direction, associated traffic lights, stop lines, and traffic signs. Except at the beginning or end of a road, each lanelet in the map must be correctly connected to its predecessor, successors, left neighbor, and right neighbor. Creating a vector map # The easiest way to create an Autoware-compatible vector map is to use Vector Map Builder , a free web-based tool provided by TIER IV, Inc. . Vector Map Builder allows you to create lanes and add additional regulatory elements such as stop signs or traffic lights using a point cloud map as a reference. For open-source software options, MapToolbox is a plugin for Unity specifically designed to create Lanelet2 maps for Autoware. Although JOSM is another open-source tool that can be used to create Lanelet2 maps, be aware that a number of modifications must be done manually to make the map compatible with Autoware. This process can be tedious and time-consuming, so the use of JOSM is not recommended. Autoware-compatible map providers # If it is not possible to create HD maps yourself, you can use a mapping service from the following Autoware-compatible map providers instead: MAP IV, Inc. AISAN TECHNOLOGY CO., LTD. TomTom The table below shows each company's mapping technology and the types of HD maps they support. Company Mapping technology Available maps MAP IV, Inc. SLAM Point cloud and vector maps AISAN TECHNOLOGY CO., LTD. MMS Point cloud and vector maps TomTom MMS Vector map* Note Maps provided by TomTom use their proprietary AutoStream format, not Lanelet2. The open-source AutoStreamForAutoware tool can be used to convert an AutoStream map to a Lanelet2 map. However, the converter is still in its early stages and has some known limitations .","title":"Creating maps for Autoware"},{"location":"how-to-guides/creating-maps-for-autoware/#creating-maps-for-autoware","text":"Autoware relies on high-definition point cloud maps and vector maps of the driving environment to perform various tasks such as localization, route planning, traffic light detection, and predicting the trajectories of pedestrians and other vehicles. The specifications for point cloud and vector maps required by Autoware are given below, along with examples of both open-source and proprietary software that you can use to create them.","title":"Creating maps for Autoware"},{"location":"how-to-guides/creating-maps-for-autoware/#point-cloud-maps","text":"A 3D point cloud map is primarily used for LiDAR-based localization in Autoware. In order to determine the current position and orientation of the vehicle, a live scan captured from one or more LiDAR units is matched against a pre-generated 3D point cloud map. Therefore, an accurate point cloud map is crucial for good localization results.","title":"Point cloud maps"},{"location":"how-to-guides/creating-maps-for-autoware/#point-cloud-map-specifications","text":"It must cover the entire operational area of the vehicle and should include an additional buffer zone of at least 200 m in all directions. It must be saved using the PCD (Point Cloud Data) file format , but can be a single PCD file or divided into multiple PCD files. Each point in the map must contain X, Y, and Z coordinates. An intensity or RGB value for each point may be optionally included. Its file size must be smaller than 1 GB, as per the current ROS message size limit . Its resolution should be at least 0.2 m to yield reliable localization results. It can be in either local or global coordinates, but must be in global coordinates (georeferenced) to use GNSS data for localization. Note Three global coordinate systems are supported by Autoware, including Military Grid Reference System (MGRS) , Universal Transverse Mercator (UTM) , and Japan Rectangular Coordinate System . However, MGRS is a preferred coordinate system for georeferenced maps. In a map with MGRS coordinate system, the X and Y coordinates of each point represent the point's location within the 100,000-meter square, while the Z coordinate represents the point's elevation.","title":"Point cloud map specifications"},{"location":"how-to-guides/creating-maps-for-autoware/#creating-a-point-cloud-map","text":"Traditionally, a Mobile Mapping System ( MMS ) is used in order to create highly accurate large-scale point cloud maps. However, since a MMS requires high-end sensors for precise positioning, its operational cost can be very expensive and may not be suitable for a relatively small driving environment. Alternatively, a Simultaneous Localization And Mapping ( SLAM ) algorithm can be used to create a point cloud map from recorded LiDAR scans. Commonly used open-source SLAM implementations are lidarslam-ros2 (LiDAR, IMU *) and LIO-SAM (LiDAR, IMU , GNSS ). The required sensor data for each algorithm is specified in the parentheses, where an asterisk (*) indicates that such sensor data is optional. For supported LiDAR models, please check the Github repository of each algorithm. While these ROS 2-based SLAM implementations can be easily installed and used directly on the same machine that runs Autoware, it is important to note that they may not be as well-tested or as mature as ROS 1-based alternatives. The notable open-source SLAM implementations that are based on ROS 1 include hdl-graph-slam (LiDAR, IMU *, GNSS *), LeGO-LOAM (LiDAR, IMU *), LeGO-LOAM-BOR (LiDAR), and LIO-SAM (LiDAR, IMU , GNSS ). Most of these algorithms already have a built-in loop-closure and pose graph optimization. However, if the built-in, automatic loop-closure fails or does not work correctly, you can use Interactive SLAM to adjust and optimize a pose graph manually. Since Autoware is based on ROS 2, it could be problematic if you want to install ROS 1-based SLAM implementations on the same machine. To avoid this problem, you can use Docker or simply install them on a different machine. Another problem is the ROSBAG version; these SLAM implementations require ROSBAG 1 instead of ROSBAG 2 used by Autoware. For the ROSBAG version problem, you may use this stand-alone converter to convert a ROSBAG 2 file to a ROSBAG 1 file and vice versa. If you prefer proprietary software that is easy to use, you can try a fully automatic mapping tool from MAP IV, Inc. , MapIV Engine . They currently provide a trial license for Autoware users free of charge.","title":"Creating a point cloud map"},{"location":"how-to-guides/creating-maps-for-autoware/#vector-maps","text":"A vector map contains highly accurate information about a road network, lane geometry, and traffic lights. It is required for route planning, traffic light detection, and predicting the trajectories of other vehicles and pedestrians.","title":"Vector maps"},{"location":"how-to-guides/creating-maps-for-autoware/#vector-map-specifications","text":"It must cover the entire operational area of the vehicle and should include an additional buffer zone of at least 200 m in all directions. It must be in Lanelet2 format, with additional modifications required by Autoware . It must contain the shape and position information of lanes, traffic lights, stop lines, crosswalks, parking spaces, and parking lots. Each lanelet in the map must contain information regarding its right of way, speed limit, traffic direction, associated traffic lights, stop lines, and traffic signs. Except at the beginning or end of a road, each lanelet in the map must be correctly connected to its predecessor, successors, left neighbor, and right neighbor.","title":"Vector map specifications"},{"location":"how-to-guides/creating-maps-for-autoware/#creating-a-vector-map","text":"The easiest way to create an Autoware-compatible vector map is to use Vector Map Builder , a free web-based tool provided by TIER IV, Inc. . Vector Map Builder allows you to create lanes and add additional regulatory elements such as stop signs or traffic lights using a point cloud map as a reference. For open-source software options, MapToolbox is a plugin for Unity specifically designed to create Lanelet2 maps for Autoware. Although JOSM is another open-source tool that can be used to create Lanelet2 maps, be aware that a number of modifications must be done manually to make the map compatible with Autoware. This process can be tedious and time-consuming, so the use of JOSM is not recommended.","title":"Creating a vector map"},{"location":"how-to-guides/creating-maps-for-autoware/#autoware-compatible-map-providers","text":"If it is not possible to create HD maps yourself, you can use a mapping service from the following Autoware-compatible map providers instead: MAP IV, Inc. AISAN TECHNOLOGY CO., LTD. TomTom The table below shows each company's mapping technology and the types of HD maps they support. Company Mapping technology Available maps MAP IV, Inc. SLAM Point cloud and vector maps AISAN TECHNOLOGY CO., LTD. MMS Point cloud and vector maps TomTom MMS Vector map* Note Maps provided by TomTom use their proprietary AutoStream format, not Lanelet2. The open-source AutoStreamForAutoware tool can be used to convert an AutoStream map to a Lanelet2 map. However, the converter is still in its early stages and has some known limitations .","title":"Autoware-compatible map providers"},{"location":"how-to-guides/determining-component-dependencies/","text":"Determining component dependencies # For any developers who wish to try and deploy Autoware as a microservices architecture, it is necessary to understand the software dependencies, communication, and implemented features of each ROS package/node. As an example, the commands necessary to determine the dependencies for the Perception component are shown below. Perception component dependencies # To generate a graph of package dependencies, use the following colcon command: colcon graph --dot --packages-up-to tier4_perception_launch | dot -Tpng -o graph.png To generate a list of dependencies, use: colcon list --packages-up-to tier4_perception_launch --names-only colcon list output autoware_auto_geometry_msgs autoware_auto_mapping_msgs autoware_auto_perception_msgs autoware_auto_planning_msgs autoware_auto_vehicle_msgs autoware_cmake autoware_lint_common autoware_point_types compare_map_segmentation detected_object_feature_remover detected_object_validation detection_by_tracker euclidean_cluster grid_map_cmake_helpers grid_map_core grid_map_cv grid_map_msgs grid_map_pcl grid_map_ros ground_segmentation image_projection_based_fusion image_transport_decompressor interpolation kalman_filter lanelet2_extension lidar_apollo_instance_segmentation map_based_prediction multi_object_tracker mussp object_merger object_range_splitter occupancy_grid_map_outlier_filter pointcloud_preprocessor pointcloud_to_laserscan shape_estimation tensorrt_yolo tier4_autoware_utils tier4_debug_msgs tier4_pcl_extensions tier4_perception_launch tier4_perception_msgs traffic_light_classifier traffic_light_map_based_detector traffic_light_ssd_fine_detector traffic_light_visualization vehicle_info_util Tip To output a list of modules with their respective paths, run the command above without the --names-only parameter. To see which ROS topics are being subscribed and published to, use rqt_graph as follows: ros2 launch tier4_perception_launch perception.launch.xml mode: = lidar ros2 run rqt_graph rqt_graph","title":"Determining component dependencies"},{"location":"how-to-guides/determining-component-dependencies/#determining-component-dependencies","text":"For any developers who wish to try and deploy Autoware as a microservices architecture, it is necessary to understand the software dependencies, communication, and implemented features of each ROS package/node. As an example, the commands necessary to determine the dependencies for the Perception component are shown below.","title":"Determining component dependencies"},{"location":"how-to-guides/determining-component-dependencies/#perception-component-dependencies","text":"To generate a graph of package dependencies, use the following colcon command: colcon graph --dot --packages-up-to tier4_perception_launch | dot -Tpng -o graph.png To generate a list of dependencies, use: colcon list --packages-up-to tier4_perception_launch --names-only colcon list output autoware_auto_geometry_msgs autoware_auto_mapping_msgs autoware_auto_perception_msgs autoware_auto_planning_msgs autoware_auto_vehicle_msgs autoware_cmake autoware_lint_common autoware_point_types compare_map_segmentation detected_object_feature_remover detected_object_validation detection_by_tracker euclidean_cluster grid_map_cmake_helpers grid_map_core grid_map_cv grid_map_msgs grid_map_pcl grid_map_ros ground_segmentation image_projection_based_fusion image_transport_decompressor interpolation kalman_filter lanelet2_extension lidar_apollo_instance_segmentation map_based_prediction multi_object_tracker mussp object_merger object_range_splitter occupancy_grid_map_outlier_filter pointcloud_preprocessor pointcloud_to_laserscan shape_estimation tensorrt_yolo tier4_autoware_utils tier4_debug_msgs tier4_pcl_extensions tier4_perception_launch tier4_perception_msgs traffic_light_classifier traffic_light_map_based_detector traffic_light_ssd_fine_detector traffic_light_visualization vehicle_info_util Tip To output a list of modules with their respective paths, run the command above without the --names-only parameter. To see which ROS topics are being subscribed and published to, use rqt_graph as follows: ros2 launch tier4_perception_launch perception.launch.xml mode: = lidar ros2 run rqt_graph rqt_graph","title":"Perception component dependencies"},{"location":"how-to-guides/integrating-autoware-with-a-diff-drive-vehicle/","text":"Integrating Autoware with a differential drive vehicle # 1. Introduction # Currently, Autoware assumes that vehicles use an Ackermann kinematic model with Ackermann steering. Thus, Autoware adopts the Ackermann command format for the Control module's output (see the AckermannDrive ROS message definition for an overview of Ackermann commands, and the AckermannControlCommands struct used in Autoware for more details). However, it is possible to integrate Autoware with a vehicle that follows a differential drive kinematic model, as commonly used by small mobile robots. 2. Procedure # One simple way of using Autoware with a differential drive vehicle is to create a vehicle_interface package that translates Ackermann commands to differential drive commands. Here are two points that you need to consider: Create vehicle_interface package for differential drive vehicle Set an appropriate wheel_base 2.1 Create a vehicle_interface package for differential drive vehicle # An Ackermann command in Autoware consists of two main control inputs: steering angle ( \\omega \\omega ) velocity ( v v ) Conversely, a typical differential drive command consists of the following inputs: left wheel velocity ( v_l v_l ) right wheel velocity ( v_r v_r ) So, one way in which an Ackermann command can be converted to a differential drive command is by using the following equations: v_l = v - \\frac{l\\omega}{2}, v_r = v + \\frac{l\\omega}{2} v_l = v - \\frac{l\\omega}{2}, v_r = v + \\frac{l\\omega}{2} where l l denotes wheel tread. For information about other factors that need to be considered when creating a vehicle_interface package, refer to the vehicle_interface component page . 2.2 Set an appropriate wheel_base # A differential drive robot does not necessarily have front and rear wheels, which means that the wheelbase (the horizontal distance between the axles of the front and rear wheels) cannot be defined. However, Autoware expects wheel_base to be set in vehicle_info.param.yaml with some value. Thus, you need to set a pseudo value for wheel_base . The appropriate pseudo value for wheel_base depends on the size of your vehicle. Setting it to be the same value as wheel_tread is one possible choice. Warning If the wheel_base value is set too small then the vehicle may behave unexpectedly. For example, the vehicle may drive beyond the bounds of a calculated path. Conversely, if wheel_base is set too large, the vehicle's range of motion will be restricted. The reason being that Autoware's Planning module will calculate an overly conservative trajectory based on the assumed vehicle length. 3. Known issues # Motion model incompatibility # Since Autoware assumes that vehicles use a steering system, it is not possible to take advantage of the flexibility of a differential drive system's motion model. For example, when planning a parking maneuver with the freespace_planner module, Autoware may drive the differential drive vehicle forward and backward, even if the vehicle can be parked with a simpler trajectory that uses pure rotational movement.","title":"Integrating Autoware with a differential drive vehicle"},{"location":"how-to-guides/integrating-autoware-with-a-diff-drive-vehicle/#integrating-autoware-with-a-differential-drive-vehicle","text":"","title":"Integrating Autoware with a differential drive vehicle"},{"location":"how-to-guides/integrating-autoware-with-a-diff-drive-vehicle/#1-introduction","text":"Currently, Autoware assumes that vehicles use an Ackermann kinematic model with Ackermann steering. Thus, Autoware adopts the Ackermann command format for the Control module's output (see the AckermannDrive ROS message definition for an overview of Ackermann commands, and the AckermannControlCommands struct used in Autoware for more details). However, it is possible to integrate Autoware with a vehicle that follows a differential drive kinematic model, as commonly used by small mobile robots.","title":"1. Introduction"},{"location":"how-to-guides/integrating-autoware-with-a-diff-drive-vehicle/#2-procedure","text":"One simple way of using Autoware with a differential drive vehicle is to create a vehicle_interface package that translates Ackermann commands to differential drive commands. Here are two points that you need to consider: Create vehicle_interface package for differential drive vehicle Set an appropriate wheel_base","title":"2. Procedure"},{"location":"how-to-guides/integrating-autoware-with-a-diff-drive-vehicle/#21-create-a-vehicle_interface-package-for-differential-drive-vehicle","text":"An Ackermann command in Autoware consists of two main control inputs: steering angle ( \\omega \\omega ) velocity ( v v ) Conversely, a typical differential drive command consists of the following inputs: left wheel velocity ( v_l v_l ) right wheel velocity ( v_r v_r ) So, one way in which an Ackermann command can be converted to a differential drive command is by using the following equations: v_l = v - \\frac{l\\omega}{2}, v_r = v + \\frac{l\\omega}{2} v_l = v - \\frac{l\\omega}{2}, v_r = v + \\frac{l\\omega}{2} where l l denotes wheel tread. For information about other factors that need to be considered when creating a vehicle_interface package, refer to the vehicle_interface component page .","title":"2.1 Create a vehicle_interface package for differential drive vehicle"},{"location":"how-to-guides/integrating-autoware-with-a-diff-drive-vehicle/#22-set-an-appropriate-wheel_base","text":"A differential drive robot does not necessarily have front and rear wheels, which means that the wheelbase (the horizontal distance between the axles of the front and rear wheels) cannot be defined. However, Autoware expects wheel_base to be set in vehicle_info.param.yaml with some value. Thus, you need to set a pseudo value for wheel_base . The appropriate pseudo value for wheel_base depends on the size of your vehicle. Setting it to be the same value as wheel_tread is one possible choice. Warning If the wheel_base value is set too small then the vehicle may behave unexpectedly. For example, the vehicle may drive beyond the bounds of a calculated path. Conversely, if wheel_base is set too large, the vehicle's range of motion will be restricted. The reason being that Autoware's Planning module will calculate an overly conservative trajectory based on the assumed vehicle length.","title":"2.2 Set an appropriate wheel_base"},{"location":"how-to-guides/integrating-autoware-with-a-diff-drive-vehicle/#3-known-issues","text":"","title":"3. Known issues"},{"location":"how-to-guides/integrating-autoware-with-a-diff-drive-vehicle/#motion-model-incompatibility","text":"Since Autoware assumes that vehicles use a steering system, it is not possible to take advantage of the flexibility of a differential drive system's motion model. For example, when planning a parking maneuver with the freespace_planner module, Autoware may drive the differential drive vehicle forward and backward, even if the vehicle can be parked with a simpler trajectory that uses pure rotational movement.","title":"Motion model incompatibility"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/","text":"Integrating Autoware with your vehicle # 1. Prepare your real vehicle hardware # Prerequisites for the vehicle: An onboard computer that satisfies the Autoware installation prerequisites The following devices attached Drive-by-wire interface LiDAR Optional: Inertial measurement unit Optional: Camera Optional: GNSS 2. Create maps # You need both a pointcloud map and a vector map in order to use Autoware. Create a pointcloud map # Use third-party tools such as a LiDAR-based SLAM (Simultaneous Localization And Mapping) package to create a pointcloud map in the .pcd format. Some examples are: HDL LIO-SAM LiDAR- SLAM ( ROS 2) Create vector map # Use third-party tools such as TIER IV's Vector Map Builder to create a Lanelet2 format .osm file. 3. Create your Autoware meta-repository # Create your Autoware meta-repository. One easy way is to fork autowarefoundation/autoware and clone it. For how to fork a repository, refer to GitHub Docs . git clone https://github.com/YOUR_NAME/autoware.git If you set up multiple types of vehicles, adding a suffix like \"autoware.vehicle_A\" or \"autoware.vehicle_B\" is recommended. 4. Create the description packages of your vehicle # Next, you need to create description packages that define the vehicle and sensor configuration of your vehicle. Create the following two packages: YOUR_VEHICLE_launch (see here for example) YOUR_SENSOR_KIT_launch (see here for example) Once created, you need to update the autoware.repos file of your cloned Autoware repository to refer to these two description packages. - # sensor_kit - sensor_kit/sample_sensor_kit_launch: - type: git - url: https://github.com/autowarefoundation/sample_sensor_kit_launch.git - version: main - # vehicle - vehicle/sample_vehicle_launch: - type: git - url: https://github.com/autowarefoundation/sample_vehicle_launch.git - version: main + # sensor_kit + sensor_kit/YOUR_SENSOR_KIT_launch: + type: git + url: https://github.com/YOUR_NAME/YOUR_SENSOR_KIT_launch.git + version: main + # vehicle + vehicle/YOUR_VEHICLE_launch: + type: git + url: https://github.com/YOUR_NAME/YOUR_VEHICLE_launch.git + version: main Adapt YOUR_VEHICLE_launch for autoware launching system # At YOUR_VEHICLE_description # Define URDF and parameters in the vehicle description package (refer to the sample vehicle description package for an example). At YOUR_VEHICLE_launch # Create a launch file (refer to the sample vehicle launch package for example). If you have multiple vehicles with the same hardware setup, you can specify vehicle_id to distinguish them. Adapt YOUR_SENSOR_KIT_description for autoware launching system # At YOUR_SENSOR_KIT_description # Define URDF and extrinsic parameters for all the sensors here (refer to the sample sensor kit description package for example). Note that you need to calibrate extrinsic parameters for all the sensors beforehand. At YOUR_SENSOR_KIT_launch # Create launch/sensing.launch.xml that launches the interfaces of all the sensors on the vehicle. (refer to the sample sensor kit launch package for example). Note At this point, you are now able to run Autoware's Planning Simulator to do a basic test of your vehicle and sensing packages. To do so, you need to build and install Autoware using your cloned repository. Follow the steps for either Docker or source installation (starting from the dependency installation step) and then run the following command: ros2 launch autoware_launch planning_simulator.launch.xml vehicle_model: = YOUR_VEHICLE sensor_kit: = YOUR_SENSOR_KIT map_path: = /PATH/TO/YOUR/MAP 5. Create a vehicle_interface package # You need to create an interface package for your vehicle. The package is expected to provide the following two functions. Receive command messages from vehicle_cmd_gate and drive the vehicle accordingly Send vehicle status information to Autoware You can find detailed information about the requirements of the vehicle_interface package in the Vehicle Interface design documentation . You can also refer to TIER IV's pacmod_interface repository as an example of a vehicle interface package. 6. Launch Autoware # This section briefly explains how to run your vehicle with Autoware. Install Autoware # Follow the installation steps of Autoware . Launch Autoware # Launch Autoware with the following command: ros2 launch autoware_launch autoware.launch.xml vehicle_model: = YOUR_VEHICLE sensor_kit: = YOUR_SENSOR_KIT map_path: = /PATH/TO/YOUR/MAP Set initial pose # If GNSS is available, Autoware automatically initializes the vehicle's pose. If not, you need to set the initial pose using the RViz GUI. Click the 2D Pose estimate button in the toolbar, or hit the P key In the 3D View pane, click and hold the left mouse button, and then drag to set the direction for the initial pose. Set goal pose # Set a goal pose for the ego vehicle. Click the 2D Nav Goal button in the toolbar, or hit the G key In the 3D View pane, click and hold the left mouse button, and then drag to set the direction for the goal pose. If successful, you will see the calculated planning path on RViz. Engage # In your terminal, execute the following command. source ~/autoware.YOURS/install/setup.bash ros2 topic pub /autoware.YOURS/engage autoware_auto_vehicle_msgs/msg/Engage \"engage: true\" -1 You can also engage via RViz with \"AutowareStatePanel\". The panel can be found in Panels > Add New Panel > tier4_state_rviz_plugin > AutowareStatePanel . Now the vehicle should drive along the calculated path! 7. Tune parameters for your vehicle & environment # You may need to tune your parameters depending on the domain in which you will operate your vehicle. If you have any issues or questions, feel free to create an Autoware Foundation GitHub Discussion in the Q&A category!","title":"Integrating Autoware with your vehicle"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#integrating-autoware-with-your-vehicle","text":"","title":"Integrating Autoware with your vehicle"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#1-prepare-your-real-vehicle-hardware","text":"Prerequisites for the vehicle: An onboard computer that satisfies the Autoware installation prerequisites The following devices attached Drive-by-wire interface LiDAR Optional: Inertial measurement unit Optional: Camera Optional: GNSS","title":"1. Prepare your real vehicle hardware"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#2-create-maps","text":"You need both a pointcloud map and a vector map in order to use Autoware.","title":"2. Create maps"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#create-a-pointcloud-map","text":"Use third-party tools such as a LiDAR-based SLAM (Simultaneous Localization And Mapping) package to create a pointcloud map in the .pcd format. Some examples are: HDL LIO-SAM LiDAR- SLAM ( ROS 2)","title":"Create a pointcloud map"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#create-vector-map","text":"Use third-party tools such as TIER IV's Vector Map Builder to create a Lanelet2 format .osm file.","title":"Create vector map"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#3-create-your-autoware-meta-repository","text":"Create your Autoware meta-repository. One easy way is to fork autowarefoundation/autoware and clone it. For how to fork a repository, refer to GitHub Docs . git clone https://github.com/YOUR_NAME/autoware.git If you set up multiple types of vehicles, adding a suffix like \"autoware.vehicle_A\" or \"autoware.vehicle_B\" is recommended.","title":"3. Create your Autoware meta-repository"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#4-create-the-description-packages-of-your-vehicle","text":"Next, you need to create description packages that define the vehicle and sensor configuration of your vehicle. Create the following two packages: YOUR_VEHICLE_launch (see here for example) YOUR_SENSOR_KIT_launch (see here for example) Once created, you need to update the autoware.repos file of your cloned Autoware repository to refer to these two description packages. - # sensor_kit - sensor_kit/sample_sensor_kit_launch: - type: git - url: https://github.com/autowarefoundation/sample_sensor_kit_launch.git - version: main - # vehicle - vehicle/sample_vehicle_launch: - type: git - url: https://github.com/autowarefoundation/sample_vehicle_launch.git - version: main + # sensor_kit + sensor_kit/YOUR_SENSOR_KIT_launch: + type: git + url: https://github.com/YOUR_NAME/YOUR_SENSOR_KIT_launch.git + version: main + # vehicle + vehicle/YOUR_VEHICLE_launch: + type: git + url: https://github.com/YOUR_NAME/YOUR_VEHICLE_launch.git + version: main","title":"4. Create the description packages of your vehicle"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#adapt-your_vehicle_launch-for-autoware-launching-system","text":"","title":"Adapt YOUR_VEHICLE_launch for autoware launching system"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#adapt-your_sensor_kit_description-for-autoware-launching-system","text":"","title":"Adapt YOUR_SENSOR_KIT_description for autoware launching system"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#5-create-a-vehicle_interface-package","text":"You need to create an interface package for your vehicle. The package is expected to provide the following two functions. Receive command messages from vehicle_cmd_gate and drive the vehicle accordingly Send vehicle status information to Autoware You can find detailed information about the requirements of the vehicle_interface package in the Vehicle Interface design documentation . You can also refer to TIER IV's pacmod_interface repository as an example of a vehicle interface package.","title":"5. Create a vehicle_interface package"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#6-launch-autoware","text":"This section briefly explains how to run your vehicle with Autoware.","title":"6. Launch Autoware"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#install-autoware","text":"Follow the installation steps of Autoware .","title":"Install Autoware"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#launch-autoware","text":"Launch Autoware with the following command: ros2 launch autoware_launch autoware.launch.xml vehicle_model: = YOUR_VEHICLE sensor_kit: = YOUR_SENSOR_KIT map_path: = /PATH/TO/YOUR/MAP","title":"Launch Autoware"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#set-initial-pose","text":"If GNSS is available, Autoware automatically initializes the vehicle's pose. If not, you need to set the initial pose using the RViz GUI. Click the 2D Pose estimate button in the toolbar, or hit the P key In the 3D View pane, click and hold the left mouse button, and then drag to set the direction for the initial pose.","title":"Set initial pose"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#set-goal-pose","text":"Set a goal pose for the ego vehicle. Click the 2D Nav Goal button in the toolbar, or hit the G key In the 3D View pane, click and hold the left mouse button, and then drag to set the direction for the goal pose. If successful, you will see the calculated planning path on RViz.","title":"Set goal pose"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#engage","text":"In your terminal, execute the following command. source ~/autoware.YOURS/install/setup.bash ros2 topic pub /autoware.YOURS/engage autoware_auto_vehicle_msgs/msg/Engage \"engage: true\" -1 You can also engage via RViz with \"AutowareStatePanel\". The panel can be found in Panels > Add New Panel > tier4_state_rviz_plugin > AutowareStatePanel . Now the vehicle should drive along the calculated path!","title":"Engage"},{"location":"how-to-guides/integrating-autoware-with-your-vehicle/#7-tune-parameters-for-your-vehicle-environment","text":"You may need to tune your parameters depending on the domain in which you will operate your vehicle. If you have any issues or questions, feel free to create an Autoware Foundation GitHub Discussion in the Q&A category!","title":"7. Tune parameters for your vehicle &amp; environment"},{"location":"how-to-guides/running-autoware-without-cuda/","text":"Running Autoware without CUDA # Although CUDA installation is recommended to achieve better performance for object detection and traffic light recognition in Autoware Universe, it is possible to run these algorithms without CUDA. The following subsections briefly explain how to run each algorithm in such an environment. Running 2D/3D object detection without CUDA # Autoware Universe's object detection can be run using one of five possible configurations: lidar_centerpoint lidar_apollo_instance_segmentation lidar-apollo + tensorrt_yolo lidar-centerpoint + tensorrt_yolo euclidean_cluster Of these five configurations, only the last one ( euclidean_cluster ) can be run without CUDA. For more details, refer to the euclidean_cluster module's README file . Running traffic light detection without CUDA # For traffic light recognition (both detection and classification), there are two modules that require CUDA: traffic_light_ssd_fine_detector traffic_light_classifier To run traffic light detection without CUDA, set enable_fine_detection to false in the traffic light launch file . Doing so disables the traffic_light_ssd_fine_detector such that traffic light detection is handled by the map_based_traffic_light_detector module instead. To run traffic light classification without CUDA, set use_gpu to false in the traffic light classifier launch file . Doing so will force the traffic_light_classifier to use a different classification algorithm that does not require CUDA or a GPU .","title":"Running Autoware without CUDA"},{"location":"how-to-guides/running-autoware-without-cuda/#running-autoware-without-cuda","text":"Although CUDA installation is recommended to achieve better performance for object detection and traffic light recognition in Autoware Universe, it is possible to run these algorithms without CUDA. The following subsections briefly explain how to run each algorithm in such an environment.","title":"Running Autoware without CUDA"},{"location":"how-to-guides/running-autoware-without-cuda/#running-2d3d-object-detection-without-cuda","text":"Autoware Universe's object detection can be run using one of five possible configurations: lidar_centerpoint lidar_apollo_instance_segmentation lidar-apollo + tensorrt_yolo lidar-centerpoint + tensorrt_yolo euclidean_cluster Of these five configurations, only the last one ( euclidean_cluster ) can be run without CUDA. For more details, refer to the euclidean_cluster module's README file .","title":"Running 2D/3D object detection without CUDA"},{"location":"how-to-guides/running-autoware-without-cuda/#running-traffic-light-detection-without-cuda","text":"For traffic light recognition (both detection and classification), there are two modules that require CUDA: traffic_light_ssd_fine_detector traffic_light_classifier To run traffic light detection without CUDA, set enable_fine_detection to false in the traffic light launch file . Doing so disables the traffic_light_ssd_fine_detector such that traffic light detection is handled by the map_based_traffic_light_detector module instead. To run traffic light classification without CUDA, set use_gpu to false in the traffic light classifier launch file . Doing so will force the traffic_light_classifier to use a different classification algorithm that does not require CUDA or a GPU .","title":"Running traffic light detection without CUDA"},{"location":"installation/","text":"Installation # Target platforms # Autoware targets the platforms listed below. It may change in future versions of Autoware. The Autoware Foundation provides no support on other platforms than those listed below. Architecture # amd64 arm64 Minimum hardware requirements # Info Autoware is scalable and can be customized to work with distributed or less powerful hardware. The minimum hardware requirements given below are just a general recommendation. However, performance will be improved with more cores, RAM and a higher-spec graphics card or GPU core. CPU with 8 cores 16GB RAM [Optional] NVIDIA GPU (4GB RAM) Although GPU is not required to run basic functionality, it is mandatory to enable the following neural network related functions: LiDAR based object detection Camera based object detection Traffic light detection and classification For details of how to enable object detection and traffic light detection/classification without a GPU , refer to the Running Autoware without CUDA . Installing Autoware # There are two ways to set up Autoware. Choose one according to your preference. If any issues occur during installation, refer to the Support page . 1. Docker installation # Docker can ensure that all developers in a project have a common, consistent development environment. It is recommended for beginners, casual users, people who are unfamiliar with Ubuntu. For more information, refer to the Docker installation guide . 2. Source installation # Source installation is for the cases where more granular control of the installation environment is needed. It is recommended for experienced users or people who want to customize their environment. Note that some problems may occur depending on your local environment. For more information, refer to the source installation guide . Installing related tools # Some other tools are required depending on the evaluation you want to do. For example, to run an end-to-end simulation you need to install an appropriate simulator. For more information, see here . Additional settings for developers # There are also tools and settings for developers, such as Shells or IDEs. For more information, see here .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#target-platforms","text":"Autoware targets the platforms listed below. It may change in future versions of Autoware. The Autoware Foundation provides no support on other platforms than those listed below.","title":"Target platforms"},{"location":"installation/#architecture","text":"amd64 arm64","title":"Architecture"},{"location":"installation/#minimum-hardware-requirements","text":"Info Autoware is scalable and can be customized to work with distributed or less powerful hardware. The minimum hardware requirements given below are just a general recommendation. However, performance will be improved with more cores, RAM and a higher-spec graphics card or GPU core. CPU with 8 cores 16GB RAM [Optional] NVIDIA GPU (4GB RAM) Although GPU is not required to run basic functionality, it is mandatory to enable the following neural network related functions: LiDAR based object detection Camera based object detection Traffic light detection and classification For details of how to enable object detection and traffic light detection/classification without a GPU , refer to the Running Autoware without CUDA .","title":"Minimum hardware requirements"},{"location":"installation/#installing-autoware","text":"There are two ways to set up Autoware. Choose one according to your preference. If any issues occur during installation, refer to the Support page .","title":"Installing Autoware"},{"location":"installation/#1-docker-installation","text":"Docker can ensure that all developers in a project have a common, consistent development environment. It is recommended for beginners, casual users, people who are unfamiliar with Ubuntu. For more information, refer to the Docker installation guide .","title":"1. Docker installation"},{"location":"installation/#2-source-installation","text":"Source installation is for the cases where more granular control of the installation environment is needed. It is recommended for experienced users or people who want to customize their environment. Note that some problems may occur depending on your local environment. For more information, refer to the source installation guide .","title":"2. Source installation"},{"location":"installation/#installing-related-tools","text":"Some other tools are required depending on the evaluation you want to do. For example, to run an end-to-end simulation you need to install an appropriate simulator. For more information, see here .","title":"Installing related tools"},{"location":"installation/#additional-settings-for-developers","text":"There are also tools and settings for developers, such as Shells or IDEs. For more information, see here .","title":"Additional settings for developers"},{"location":"installation/additional-settings-for-developers/","text":"Additional settings for developers # ROS 2 settings # Colorizing logger output # By default, ROS 2 logger doesn't colorize the output. To colorize it, write the following in your .bashrc : export RCUTILS_COLORIZED_OUTPUT = 1 Customizing the format of logger output # By default, ROS 2 logger doesn't output detailed information such as file name, function name, or line number. To customize it, write the following in your .bashrc : export RCUTILS_CONSOLE_OUTPUT_FORMAT = \"[{severity} {time}] [{name}]: {message} ({function_name}() at {file_name}:{line_number})\" For more options, see here . Enabling localhost-only communication # By default, ROS 2 communicates using multi-cast, which may unnecessarily increase the network traffic. To avoid it, write the following in your .bashrc : export ROS_LOCALHOST_ONLY = 1 Setting up ROS_DOMAIN_ID # ROS 2 uses ROS_DOMAIN_ID to create groups and communicate between machines in the groups. Since all ROS 2 nodes use domain ID 0 by default, it may cause unintended interference. To avoid it, set a different domain ID for each group in your .bashrc : # Replace X with the Domain ID you want to use # Domain ID should be a number in range [0, 101] (inclusive) export ROS_DOMAIN_ID = X For more information, see here .","title":"Additional settings for developers"},{"location":"installation/additional-settings-for-developers/#additional-settings-for-developers","text":"","title":"Additional settings for developers"},{"location":"installation/additional-settings-for-developers/#ros-2-settings","text":"","title":"ROS 2 settings"},{"location":"installation/additional-settings-for-developers/#colorizing-logger-output","text":"By default, ROS 2 logger doesn't colorize the output. To colorize it, write the following in your .bashrc : export RCUTILS_COLORIZED_OUTPUT = 1","title":"Colorizing logger output"},{"location":"installation/additional-settings-for-developers/#customizing-the-format-of-logger-output","text":"By default, ROS 2 logger doesn't output detailed information such as file name, function name, or line number. To customize it, write the following in your .bashrc : export RCUTILS_CONSOLE_OUTPUT_FORMAT = \"[{severity} {time}] [{name}]: {message} ({function_name}() at {file_name}:{line_number})\" For more options, see here .","title":"Customizing the format of logger output"},{"location":"installation/additional-settings-for-developers/#enabling-localhost-only-communication","text":"By default, ROS 2 communicates using multi-cast, which may unnecessarily increase the network traffic. To avoid it, write the following in your .bashrc : export ROS_LOCALHOST_ONLY = 1","title":"Enabling localhost-only communication"},{"location":"installation/additional-settings-for-developers/#setting-up-ros_domain_id","text":"ROS 2 uses ROS_DOMAIN_ID to create groups and communicate between machines in the groups. Since all ROS 2 nodes use domain ID 0 by default, it may cause unintended interference. To avoid it, set a different domain ID for each group in your .bashrc : # Replace X with the Domain ID you want to use # Domain ID should be a number in range [0, 101] (inclusive) export ROS_DOMAIN_ID = X For more information, see here .","title":"Setting up ROS_DOMAIN_ID"},{"location":"installation/autoware/docker-installation/","text":"Docker installation # Info Since this page explains Docker-specific information, it is recommended to see Source installation as well if you need detailed information. Prerequisites # Git For NVIDIA Jetson devices, install JetPack >= 5.0 How to set up a development environment # Clone autowarefoundation/autoware and move to the directory. git clone https://github.com/autowarefoundation/autoware.git cd autoware If you want to use ROS 2 Humble, use the humble branch. git clone https://github.com/autowarefoundation/autoware.git -b humble cd autoware You can install the dependencies either manually or using the provided Ansible script. Installing dependencies manually # Install Docker Engine Install NVIDIA Container Toolkit Install rocker Installing dependencies using Ansible # Be very careful with this method. Make sure you read and confirmed all the steps in the Ansible configuration before using it. If you've manually installed the dependencies, you can skip this section. ./setup-dev-env.sh docker You might need to log out and log back to make the current user able to use docker. How to set up a workspace # Warning Before proceeding, confirm and agree with the NVIDIA Deep Learning Container license . By pulling and using the Autoware Universe images, you accept the terms and conditions of the license. Create the autoware_map directory for map data later. mkdir ~/autoware_map Launch a Docker container. For amd64 architecture computers with NVIDIA GPU : rocker --nvidia --x11 --user --volume $HOME /autoware --volume $HOME /autoware_map -- ghcr.io/autowarefoundation/autoware-universe:latest-cuda If you want to use ROS 2 Humble: rocker --nvidia --x11 --user --volume $HOME /autoware --volume $HOME /autoware_map -- ghcr.io/autowarefoundation/autoware-universe:humble-latest-cuda If you want to run container without using NVIDIA GPU , or for arm64 architecture computers: rocker -e LIBGL_ALWAYS_SOFTWARE = 1 --x11 --user --volume $HOME /autoware --volume $HOME /autoware_map -- ghcr.io/autowarefoundation/autoware-universe:latest-cuda For detailed reason could be found here For more advanced usage, see here . After that, move to the workspace in the container: cd autoware Create the src directory and clone repositories into it. mkdir src vcs import src < autoware.repos Update dependent ROS packages. The dependency of Autoware may change after the Docker image was created. In that case, you need to run the following commands to update the dependency. sudo apt update rosdep update rosdep install --from-paths . --ignore-src --rosdistro $ROS_DISTRO Build the workspace. colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release How to update a workspace # Update the Docker image. docker pull ghcr.io/autowarefoundation/autoware-universe:latest-cuda Launch a Docker container. For amd64 architecture computers: rocker --nvidia --x11 --user --volume $HOME /autoware -- ghcr.io/autowarefoundation/autoware-universe:latest-cuda If you want to run container without using NVIDIA GPU , or for arm64 architecture computers: rocker -e LIBGL_ALWAYS_SOFTWARE = 1 --x11 --user --volume $HOME /autoware -- ghcr.io/autowarefoundation/autoware-universe:latest-cuda Update the .repos file. cd autoware git pull Update the repositories. vcs import src < autoware.repos vcs pull src Build the workspace. colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release Troubleshooting # Here are solutions for a few specific errors: cuda error: forward compatibility was attempted on non supported hw # When starting Docker with GPU support enabled for NVIDIA graphics, you may sometimes receive the following error: docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused \"process_linux.go:449: container init caused \\\"process_linux.go:432: running prestart hook 0 caused \\\\\\\"error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: initialization error: cuda error: forward compatibility was attempted on non supported hw\\\\\\\\n\\\\\\\"\\\"\" : unknown. ERROR: Command return non-zero exit code ( see above ) : 125 This usually indicates that a new NVIDIA graphics driver has been installed (usually via apt ) but the system has not yet been restarted. A similar message may appear if the graphics driver is not available, for example because of resuming after suspend. To fix this, restart your system after installing the new NVIDIA driver. Docker with NVIDIA gpu fails to start Autoware on arm64 devices # When starting Docker with GPU support enabled for NVIDIA graphics on arm64 devices, e.g. NVIDIA jetson AGX xavier, you may receive the following error: nvidia@xavier:~$ rocker --nvidia --x11 --user --volume $HOME /autoware -- ghcr.io/autowarefoundation/autoware-universe:galactic-latest-cuda-arm64 ... Collecting staticx == 0 .12.3 Downloading https://files.pythonhosted.org/packages/92/ff/d9960ea1f9db48d6044a24ee0f3d78d07bcaddf96eb0c0e8806f941fb7d3/staticx-0.12.3.tar.gz ( 68kB ) Complete output from command python setup.py egg_info: Traceback ( most recent call last ) : File \"\" , line 1 , in File \"/tmp/pip-install-m_nm8mya/staticx/setup.py\" , line 4 , in from wheel.bdist_wheel import bdist_wheel ModuleNotFoundError: No module named 'wheel' Command \"python setup.py egg_info\" failed with error code 1 in /tmp/pip-install-m_nm8mya/staticx/ ... This error exists in current version of rocker tool, which relates to the os_detection function of rocker. To fix this error, temporary modification of rocker source code is required, which is not recommended. At current stage, it is recommended to run docker without NVIDIA gpu enabled for arm64 devices: rocker -e LIBGL_ALWAYS_SOFTWARE = 1 --x11 --user --volume $HOME /autoware -- ghcr.io/autowarefoundation/autoware-universe:latest-cuda This tutorial will be updated after official fix from rocker. Tips # Non-native arm64 System # This section describes a process to run arm64 systems on amd64 systems using qemu-user-static . Initially, your system is usually incompatible with arm64 systems. To check that: $ docker run --rm -t arm64v8/ubuntu uname -m WARNING: The requested image's platform (linux/arm64/v8) does not match the detected host platform (linux/amd64) and no specific platform was requested standard_init_linux.go:228: exec user process caused: exec format error Installing qemu-user-static enables us to run arm64 images on amd64 systems. $ sudo apt-get install qemu-user-static $ docker run --rm --privileged multiarch/qemu-user-static --reset -p yes $ docker run --rm -t arm64v8/ubuntu uname -m WARNING: The requested image's platform (linux/arm64/v8) does not match the detected host platform (linux/amd64) and no specific platform was requested aarch64 To run Autoware's Docker images of arm64 architecture, add the suffix -arm64 . $ docker run --rm -it ghcr.io/autowarefoundation/autoware-universe:galactic-latest-cuda-arm64 WARNING: The requested image's platform (linux/arm64) does not match the detected host platform (linux/amd64) and no specific platform was requested root@5b71391ad50f:/autoware#","title":"Docker installation"},{"location":"installation/autoware/docker-installation/#docker-installation","text":"Info Since this page explains Docker-specific information, it is recommended to see Source installation as well if you need detailed information.","title":"Docker installation"},{"location":"installation/autoware/docker-installation/#prerequisites","text":"Git For NVIDIA Jetson devices, install JetPack >= 5.0","title":"Prerequisites"},{"location":"installation/autoware/docker-installation/#how-to-set-up-a-development-environment","text":"Clone autowarefoundation/autoware and move to the directory. git clone https://github.com/autowarefoundation/autoware.git cd autoware If you want to use ROS 2 Humble, use the humble branch. git clone https://github.com/autowarefoundation/autoware.git -b humble cd autoware You can install the dependencies either manually or using the provided Ansible script.","title":"How to set up a development environment"},{"location":"installation/autoware/docker-installation/#installing-dependencies-manually","text":"Install Docker Engine Install NVIDIA Container Toolkit Install rocker","title":"Installing dependencies manually"},{"location":"installation/autoware/docker-installation/#installing-dependencies-using-ansible","text":"Be very careful with this method. Make sure you read and confirmed all the steps in the Ansible configuration before using it. If you've manually installed the dependencies, you can skip this section. ./setup-dev-env.sh docker You might need to log out and log back to make the current user able to use docker.","title":"Installing dependencies using Ansible"},{"location":"installation/autoware/docker-installation/#how-to-set-up-a-workspace","text":"Warning Before proceeding, confirm and agree with the NVIDIA Deep Learning Container license . By pulling and using the Autoware Universe images, you accept the terms and conditions of the license. Create the autoware_map directory for map data later. mkdir ~/autoware_map Launch a Docker container. For amd64 architecture computers with NVIDIA GPU : rocker --nvidia --x11 --user --volume $HOME /autoware --volume $HOME /autoware_map -- ghcr.io/autowarefoundation/autoware-universe:latest-cuda If you want to use ROS 2 Humble: rocker --nvidia --x11 --user --volume $HOME /autoware --volume $HOME /autoware_map -- ghcr.io/autowarefoundation/autoware-universe:humble-latest-cuda If you want to run container without using NVIDIA GPU , or for arm64 architecture computers: rocker -e LIBGL_ALWAYS_SOFTWARE = 1 --x11 --user --volume $HOME /autoware --volume $HOME /autoware_map -- ghcr.io/autowarefoundation/autoware-universe:latest-cuda For detailed reason could be found here For more advanced usage, see here . After that, move to the workspace in the container: cd autoware Create the src directory and clone repositories into it. mkdir src vcs import src < autoware.repos Update dependent ROS packages. The dependency of Autoware may change after the Docker image was created. In that case, you need to run the following commands to update the dependency. sudo apt update rosdep update rosdep install --from-paths . --ignore-src --rosdistro $ROS_DISTRO Build the workspace. colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release","title":"How to set up a workspace"},{"location":"installation/autoware/docker-installation/#how-to-update-a-workspace","text":"Update the Docker image. docker pull ghcr.io/autowarefoundation/autoware-universe:latest-cuda Launch a Docker container. For amd64 architecture computers: rocker --nvidia --x11 --user --volume $HOME /autoware -- ghcr.io/autowarefoundation/autoware-universe:latest-cuda If you want to run container without using NVIDIA GPU , or for arm64 architecture computers: rocker -e LIBGL_ALWAYS_SOFTWARE = 1 --x11 --user --volume $HOME /autoware -- ghcr.io/autowarefoundation/autoware-universe:latest-cuda Update the .repos file. cd autoware git pull Update the repositories. vcs import src < autoware.repos vcs pull src Build the workspace. colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release","title":"How to update a workspace"},{"location":"installation/autoware/docker-installation/#troubleshooting","text":"Here are solutions for a few specific errors:","title":"Troubleshooting"},{"location":"installation/autoware/docker-installation/#cuda-error-forward-compatibility-was-attempted-on-non-supported-hw","text":"When starting Docker with GPU support enabled for NVIDIA graphics, you may sometimes receive the following error: docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused \"process_linux.go:449: container init caused \\\"process_linux.go:432: running prestart hook 0 caused \\\\\\\"error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: initialization error: cuda error: forward compatibility was attempted on non supported hw\\\\\\\\n\\\\\\\"\\\"\" : unknown. ERROR: Command return non-zero exit code ( see above ) : 125 This usually indicates that a new NVIDIA graphics driver has been installed (usually via apt ) but the system has not yet been restarted. A similar message may appear if the graphics driver is not available, for example because of resuming after suspend. To fix this, restart your system after installing the new NVIDIA driver.","title":"cuda error: forward compatibility was attempted on non supported hw"},{"location":"installation/autoware/docker-installation/#docker-with-nvidia-gpu-fails-to-start-autoware-on-arm64-devices","text":"When starting Docker with GPU support enabled for NVIDIA graphics on arm64 devices, e.g. NVIDIA jetson AGX xavier, you may receive the following error: nvidia@xavier:~$ rocker --nvidia --x11 --user --volume $HOME /autoware -- ghcr.io/autowarefoundation/autoware-universe:galactic-latest-cuda-arm64 ... Collecting staticx == 0 .12.3 Downloading https://files.pythonhosted.org/packages/92/ff/d9960ea1f9db48d6044a24ee0f3d78d07bcaddf96eb0c0e8806f941fb7d3/staticx-0.12.3.tar.gz ( 68kB ) Complete output from command python setup.py egg_info: Traceback ( most recent call last ) : File \"\" , line 1 , in File \"/tmp/pip-install-m_nm8mya/staticx/setup.py\" , line 4 , in from wheel.bdist_wheel import bdist_wheel ModuleNotFoundError: No module named 'wheel' Command \"python setup.py egg_info\" failed with error code 1 in /tmp/pip-install-m_nm8mya/staticx/ ... This error exists in current version of rocker tool, which relates to the os_detection function of rocker. To fix this error, temporary modification of rocker source code is required, which is not recommended. At current stage, it is recommended to run docker without NVIDIA gpu enabled for arm64 devices: rocker -e LIBGL_ALWAYS_SOFTWARE = 1 --x11 --user --volume $HOME /autoware -- ghcr.io/autowarefoundation/autoware-universe:latest-cuda This tutorial will be updated after official fix from rocker.","title":"Docker with NVIDIA gpu fails to start Autoware on arm64 devices"},{"location":"installation/autoware/docker-installation/#tips","text":"","title":"Tips"},{"location":"installation/autoware/docker-installation/#non-native-arm64-system","text":"This section describes a process to run arm64 systems on amd64 systems using qemu-user-static . Initially, your system is usually incompatible with arm64 systems. To check that: $ docker run --rm -t arm64v8/ubuntu uname -m WARNING: The requested image's platform (linux/arm64/v8) does not match the detected host platform (linux/amd64) and no specific platform was requested standard_init_linux.go:228: exec user process caused: exec format error Installing qemu-user-static enables us to run arm64 images on amd64 systems. $ sudo apt-get install qemu-user-static $ docker run --rm --privileged multiarch/qemu-user-static --reset -p yes $ docker run --rm -t arm64v8/ubuntu uname -m WARNING: The requested image's platform (linux/arm64/v8) does not match the detected host platform (linux/amd64) and no specific platform was requested aarch64 To run Autoware's Docker images of arm64 architecture, add the suffix -arm64 . $ docker run --rm -it ghcr.io/autowarefoundation/autoware-universe:galactic-latest-cuda-arm64 WARNING: The requested image's platform (linux/arm64) does not match the detected host platform (linux/amd64) and no specific platform was requested root@5b71391ad50f:/autoware#","title":"Non-native arm64 System"},{"location":"installation/autoware/source-installation/","text":"Source installation # Prerequisites # OS Ubuntu 20.04 Ubuntu 22.04 ROS ROS 2 Galactic ROS 2 Humble For ROS 2 system dependencies, refer to REP-2000 . Git Registering SSH keys to GitHub is preferable. sudo apt-get -y update sudo apt-get -y install git How to set up a development environment # Clone autowarefoundation/autoware and move to the directory. git clone https://github.com/autowarefoundation/autoware.git cd autoware If you want to use ROS 2 Humble, use the humble branch. git clone https://github.com/autowarefoundation/autoware.git -b humble cd autoware You can install the dependencies either manually or using the provided Ansible script. Note: Before installing NVIDIA libraries, confirm and agree with the licenses. CUDA cuDNN TensorRT Installing dependencies manually # Install ROS 2 Install ROS 2 Dev Tools Install the RMW Implementation Install pacmod Install Autoware Core dependencies Install Autoware Universe dependencies Install pre-commit dependencies Install Nvidia CUDA Install Nvidia cuDNN and TensorRT Installing dependencies using Ansible # Be very careful with this method. Make sure you read and confirmed all the steps in the Ansible configuration before using it. If you've manually installed the dependencies, you can skip this section. ./setup-dev-env.sh How to set up a workspace # Create the src directory and clone repositories into it. Autoware uses vcstool to construct workspaces. cd autoware mkdir src vcs import src < autoware.repos Install dependent ROS packages. Autoware requires some ROS 2 packages in addition to the core components. The tool rosdep allows an automatic search and installation of such dependencies. You might need to run rosdep update before rosdep install . source /opt/ros/galactic/setup.bash rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO Build the workspace. Autoware uses colcon to build workspaces. For more advanced options, refer to the documentation . colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release How to update a workspace # Update the .repos file. cd autoware git pull Update the repositories. vcs import src < autoware.repos vcs pull src For Git users: vcs import is similar to git checkout . Note that it doesn't pull from the remote. vcs pull is similar to git pull . Note that it doesn't switch branches. For more information, refer to the official documentation . Install dependent ROS packages. source /opt/ros/galactic/setup.bash rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO Build the workspace. colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release","title":"Source installation"},{"location":"installation/autoware/source-installation/#source-installation","text":"","title":"Source installation"},{"location":"installation/autoware/source-installation/#prerequisites","text":"OS Ubuntu 20.04 Ubuntu 22.04 ROS ROS 2 Galactic ROS 2 Humble For ROS 2 system dependencies, refer to REP-2000 . Git Registering SSH keys to GitHub is preferable. sudo apt-get -y update sudo apt-get -y install git","title":"Prerequisites"},{"location":"installation/autoware/source-installation/#how-to-set-up-a-development-environment","text":"Clone autowarefoundation/autoware and move to the directory. git clone https://github.com/autowarefoundation/autoware.git cd autoware If you want to use ROS 2 Humble, use the humble branch. git clone https://github.com/autowarefoundation/autoware.git -b humble cd autoware You can install the dependencies either manually or using the provided Ansible script. Note: Before installing NVIDIA libraries, confirm and agree with the licenses. CUDA cuDNN TensorRT","title":"How to set up a development environment"},{"location":"installation/autoware/source-installation/#installing-dependencies-manually","text":"Install ROS 2 Install ROS 2 Dev Tools Install the RMW Implementation Install pacmod Install Autoware Core dependencies Install Autoware Universe dependencies Install pre-commit dependencies Install Nvidia CUDA Install Nvidia cuDNN and TensorRT","title":"Installing dependencies manually"},{"location":"installation/autoware/source-installation/#installing-dependencies-using-ansible","text":"Be very careful with this method. Make sure you read and confirmed all the steps in the Ansible configuration before using it. If you've manually installed the dependencies, you can skip this section. ./setup-dev-env.sh","title":"Installing dependencies using Ansible"},{"location":"installation/autoware/source-installation/#how-to-set-up-a-workspace","text":"Create the src directory and clone repositories into it. Autoware uses vcstool to construct workspaces. cd autoware mkdir src vcs import src < autoware.repos Install dependent ROS packages. Autoware requires some ROS 2 packages in addition to the core components. The tool rosdep allows an automatic search and installation of such dependencies. You might need to run rosdep update before rosdep install . source /opt/ros/galactic/setup.bash rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO Build the workspace. Autoware uses colcon to build workspaces. For more advanced options, refer to the documentation . colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release","title":"How to set up a workspace"},{"location":"installation/autoware/source-installation/#how-to-update-a-workspace","text":"Update the .repos file. cd autoware git pull Update the repositories. vcs import src < autoware.repos vcs pull src For Git users: vcs import is similar to git checkout . Note that it doesn't pull from the remote. vcs pull is similar to git pull . Note that it doesn't switch branches. For more information, refer to the official documentation . Install dependent ROS packages. source /opt/ros/galactic/setup.bash rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO Build the workspace. colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release","title":"How to update a workspace"},{"location":"installation/related-tools/","text":"Installation of related tools # Warning Under Construction","title":"Installation of related tools"},{"location":"installation/related-tools/#installation-of-related-tools","text":"Warning Under Construction","title":"Installation of related tools"},{"location":"support/","text":"Support # This page explains several support resources. Support guidelines pages explain the support mechanisms and guidelines. Troubleshooting pages explain solutions for common issues. Docs guide pages explain related documentation sites.","title":"Support"},{"location":"support/#support","text":"This page explains several support resources. Support guidelines pages explain the support mechanisms and guidelines. Troubleshooting pages explain solutions for common issues. Docs guide pages explain related documentation sites.","title":"Support"},{"location":"support/docs-guide/","text":"Docs guide # This page explains several documentation sites that are useful for Autoware and ROS development. The Autoware Foundation is the official site of the Autoware Foundation. You can learn about the Autoware community here. Autoware Documentation (this site) is the central documentation site for Autoware maintained by the Autoware community. General software-related information of Autoware is aggregated here. Autoware Universe Documentation has READMEs and design documents of software components. ROS Docs Guide explains the ROS 1 and ROS 2 documentation infrastructure.","title":"Docs guide"},{"location":"support/docs-guide/#docs-guide","text":"This page explains several documentation sites that are useful for Autoware and ROS development. The Autoware Foundation is the official site of the Autoware Foundation. You can learn about the Autoware community here. Autoware Documentation (this site) is the central documentation site for Autoware maintained by the Autoware community. General software-related information of Autoware is aggregated here. Autoware Universe Documentation has READMEs and design documents of software components. ROS Docs Guide explains the ROS 1 and ROS 2 documentation infrastructure.","title":"Docs guide"},{"location":"support/support-guidelines/","text":"Support guidelines # This page explains the support mechanisms we provide. Warning Before asking for help, search and read this documentation site carefully. Also, follow the discussion guidelines for discussions. Choose appropriate resources depending on what kind of help you need and read the detailed description in the sections below. Documentation sites Various information GitHub Discussions Questions Unconfirmed bugs Feature requests Design discussions GitHub Issues Confirmed bugs Discord Instant messaging between contributors ROS Discourse General topics that should be widely announced Documentation sites # Docs guide shows the list of useful documentation sites. Visit them and see if there is any information related to your problem. Note that the documentation sites aren't always up-to-date and perfect. If you find out that some information is wrong, unclear, or missing in Autoware docs, feel free to submit a pull request following the contribution guidelines . Warning Since this documentation site is still under construction, there are some empty pages. GitHub Discussions # If you encounter a problem with Autoware, check existing issues and questions and search for similar issues first. Issues Note that Autoware has multiple repositories listed in autoware.repos . It is recommended to search across the repositories. Questions If no answer was found, create a new question thread here . If your question is not answered within a week, then @mention the maintainers to remind them. Also, there are other discussion types such as feature requests or design discussions . Feel free to open or join such discussions. If you don't know how to create a discussion, refer to GitHub Docs . GitHub Issues # If you have a problem and you have confirmed it is a bug, find the appropriate repository and create a new issue there. If you can't determine the appropriate repository, ask the maintainers for help by creating a new discussion in the Q&A category . Warning Do not create issues for questions or unconfirmed bugs. If such issues are created, maintainers will transfer them to GitHub Discussions. If you want to fix the bug by yourself, discuss the approach with maintainers and submit a pull request. Discord # Autoware has a Discord server for casual communication between contributors. The Autoware Discord server is a good place for the following activities: Introduce yourself to the community. Chat with contributors. Take a quick straw poll. Note that it is not the right place to get help for your issues. ROS Discourse # If you want to widely discuss a topic with the general Autoware and ROS community or ask a question not related to Autoware's bugs, post to the Autoware category on ROS Discourse . Warning Do not post questions about bugs to ROS Discourse!","title":"Support guidelines"},{"location":"support/support-guidelines/#support-guidelines","text":"This page explains the support mechanisms we provide. Warning Before asking for help, search and read this documentation site carefully. Also, follow the discussion guidelines for discussions. Choose appropriate resources depending on what kind of help you need and read the detailed description in the sections below. Documentation sites Various information GitHub Discussions Questions Unconfirmed bugs Feature requests Design discussions GitHub Issues Confirmed bugs Discord Instant messaging between contributors ROS Discourse General topics that should be widely announced","title":"Support guidelines"},{"location":"support/support-guidelines/#documentation-sites","text":"Docs guide shows the list of useful documentation sites. Visit them and see if there is any information related to your problem. Note that the documentation sites aren't always up-to-date and perfect. If you find out that some information is wrong, unclear, or missing in Autoware docs, feel free to submit a pull request following the contribution guidelines . Warning Since this documentation site is still under construction, there are some empty pages.","title":"Documentation sites"},{"location":"support/support-guidelines/#github-discussions","text":"If you encounter a problem with Autoware, check existing issues and questions and search for similar issues first. Issues Note that Autoware has multiple repositories listed in autoware.repos . It is recommended to search across the repositories. Questions If no answer was found, create a new question thread here . If your question is not answered within a week, then @mention the maintainers to remind them. Also, there are other discussion types such as feature requests or design discussions . Feel free to open or join such discussions. If you don't know how to create a discussion, refer to GitHub Docs .","title":"GitHub Discussions"},{"location":"support/support-guidelines/#github-issues","text":"If you have a problem and you have confirmed it is a bug, find the appropriate repository and create a new issue there. If you can't determine the appropriate repository, ask the maintainers for help by creating a new discussion in the Q&A category . Warning Do not create issues for questions or unconfirmed bugs. If such issues are created, maintainers will transfer them to GitHub Discussions. If you want to fix the bug by yourself, discuss the approach with maintainers and submit a pull request.","title":"GitHub Issues"},{"location":"support/support-guidelines/#discord","text":"Autoware has a Discord server for casual communication between contributors. The Autoware Discord server is a good place for the following activities: Introduce yourself to the community. Chat with contributors. Take a quick straw poll. Note that it is not the right place to get help for your issues.","title":"Discord"},{"location":"support/support-guidelines/#ros-discourse","text":"If you want to widely discuss a topic with the general Autoware and ROS community or ask a question not related to Autoware's bugs, post to the Autoware category on ROS Discourse . Warning Do not post questions about bugs to ROS Discourse!","title":"ROS Discourse"},{"location":"support/troubleshooting/","text":"Troubleshooting # Setup issues # CUDA-related errors # When installing CUDA, errors may occur because of version conflicts. To resolve these types of errors, try one of the following methods: Unhold all CUDA-related libraries and rerun the setup script. sudo apt-mark unhold \\ \"cuda*\" \\ \"libcudnn*\" \\ \"libnvinfer*\" \\ \"libnvonnxparsers*\" \\ \"libnvparsers*\" \\ \"tensorrt*\" \\ \"nvidia*\" ./setup-dev-env.sh Uninstall all CUDA-related libraries and rerun the setup script. sudo apt purge \\ \"cuda*\" \\ \"libcudnn*\" \\ \"libnvinfer*\" \\ \"libnvonnxparsers*\" \\ \"libnvparsers*\" \\ \"tensorrt*\" \\ \"nvidia*\" sudo apt autoremove ./setup-dev-env.sh Warning Note that this may break your system and run carefully. Run the setup script without installing CUDA-related libraries. ./setup-dev-env.sh --no-nvidia Warning Note that some components in Autoware Universe require CUDA, and only the CUDA version in the env file is supported at this time. Autoware may work with other CUDA versions, but those versions are not supported and functionality is not guaranteed. Build issues # Insufficient memory # Building Autoware requires a lot of memory, and your machine can freeze or crash if memory runs out during a build. To avoid this problem, 16-32GB of swap should be configured. # Optional: Check the current swapfile free -h # Remove the current swapfile sudo swapoff /swapfile sudo rm /swapfile # Create a new swapfile sudo fallocate -l 32G /swapfile sudo chmod 600 /swapfile sudo mkswap /swapfile sudo swapon /swapfile # Optional: Check if the change is reflected free -h For more detailed configuration steps, along with an explanation of swap, refer to Digital Ocean's \"How To Add Swap Space on Ubuntu 20.04\" tutorial Errors when using the latest version of Autoware # If you are working with the latest version of Autoware, issues can occur due to out-of-date software or old build files. To resolve these types of problems, first try cleaning your build artifacts and rebuilding: rm -rf build/ install/ log/ colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release If the error is not resolved, remove src/ and update your workspace according to installation type ( Docker / source ). Warning Before removing src/ , confirm that there are no modifications in your local environment that you want to keep! If errors still persist after trying the steps above, delete the entire workspace, clone the repository once again and restart the installation process. rm -rf autoware/ git clone https://github.com/autowarefoundation/autoware.git Errors when using a fixed version of Autoware # In principle, errors should not occur when using a fixed version. That said, possible causes include: ROS 2 has been updated with breaking changes. For confirmation, check the Packaging and Release Management tag on ROS Discourse. Your local environment is broken. Confirm your .bashrc file, environment variables, and library versions. In addition to the causes listed above, there are two common misunderstandings around the use of fixed versions. You used a fixed version for autowarefoundation/autoware only. All of the repository versions in the .repos file must be specified in order to use a completely fixed version. You didn't update the workspace after changing the branch of autowarefoundation/autoware . Changing the branch of autowarefoundation/autoware does not affect the files under src/ . You have to run the vcs import command to update them. Docker/rocker issues # If any errors occur when running Autoware with Docker or rocker, first confirm that your Docker installation is working correctly by running the following commands: docker run --rm -it hello-world docker run --rm -it ubuntu:latest Next, confirm that you are able to access the base Autoware image that is stored on the GitHub Packages website docker run --rm -it ghcr.io/autowarefoundation/autoware-universe:latest Runtime issues # Map does not display when running the Planning Simulator # When running the Planning Simulator, the most common reason for the map not being displayed in RViz is because the map path has not been specified correctly in the launch command . You can confirm if this is the case by searching for Could not find lanelet map under {path-to-map-dir}/lanelet2_map.osm errors in the log. Another possible reason is that map loading is taking a long time due to poor DDS performance. To address this issue, first enable localhost-only communication to reduce network traffic, and then tune DDS settings if the problem continues to occur. Enable localhost-only communication Tune DDS settings Add the following lines to /etc/sysctl.conf net.ipv4.ipfrag_time = 3 // generic DDS setting net.ipv4.ipfrag_high_thresh = 134217728 // generic DDS setting net.core.rmem_max = 2147483647 // only add if CycloneDDS is configured net.core.rmem_default = 8388608 // only add if CycloneDDS is confgured Note DDS configuration can be determined by running the following command. echo $RMW_IMPLEMENTATION // if Cyclone DDS is configured, this command will return \"rmw_cyclonedds_cpp\" Multicast is disabled # If you get the error message selected interface \"{your-interface-name}\" is not multicast-capable: disabling multicast , run the following command to allow multicast. sudo ip link set multicast on { your-interface-name }","title":"Troubleshooting"},{"location":"support/troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"support/troubleshooting/#setup-issues","text":"","title":"Setup issues"},{"location":"support/troubleshooting/#cuda-related-errors","text":"When installing CUDA, errors may occur because of version conflicts. To resolve these types of errors, try one of the following methods: Unhold all CUDA-related libraries and rerun the setup script. sudo apt-mark unhold \\ \"cuda*\" \\ \"libcudnn*\" \\ \"libnvinfer*\" \\ \"libnvonnxparsers*\" \\ \"libnvparsers*\" \\ \"tensorrt*\" \\ \"nvidia*\" ./setup-dev-env.sh Uninstall all CUDA-related libraries and rerun the setup script. sudo apt purge \\ \"cuda*\" \\ \"libcudnn*\" \\ \"libnvinfer*\" \\ \"libnvonnxparsers*\" \\ \"libnvparsers*\" \\ \"tensorrt*\" \\ \"nvidia*\" sudo apt autoremove ./setup-dev-env.sh Warning Note that this may break your system and run carefully. Run the setup script without installing CUDA-related libraries. ./setup-dev-env.sh --no-nvidia Warning Note that some components in Autoware Universe require CUDA, and only the CUDA version in the env file is supported at this time. Autoware may work with other CUDA versions, but those versions are not supported and functionality is not guaranteed.","title":"CUDA-related errors"},{"location":"support/troubleshooting/#build-issues","text":"","title":"Build issues"},{"location":"support/troubleshooting/#insufficient-memory","text":"Building Autoware requires a lot of memory, and your machine can freeze or crash if memory runs out during a build. To avoid this problem, 16-32GB of swap should be configured. # Optional: Check the current swapfile free -h # Remove the current swapfile sudo swapoff /swapfile sudo rm /swapfile # Create a new swapfile sudo fallocate -l 32G /swapfile sudo chmod 600 /swapfile sudo mkswap /swapfile sudo swapon /swapfile # Optional: Check if the change is reflected free -h For more detailed configuration steps, along with an explanation of swap, refer to Digital Ocean's \"How To Add Swap Space on Ubuntu 20.04\" tutorial","title":"Insufficient memory"},{"location":"support/troubleshooting/#errors-when-using-the-latest-version-of-autoware","text":"If you are working with the latest version of Autoware, issues can occur due to out-of-date software or old build files. To resolve these types of problems, first try cleaning your build artifacts and rebuilding: rm -rf build/ install/ log/ colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release If the error is not resolved, remove src/ and update your workspace according to installation type ( Docker / source ). Warning Before removing src/ , confirm that there are no modifications in your local environment that you want to keep! If errors still persist after trying the steps above, delete the entire workspace, clone the repository once again and restart the installation process. rm -rf autoware/ git clone https://github.com/autowarefoundation/autoware.git","title":"Errors when using the latest version of Autoware"},{"location":"support/troubleshooting/#errors-when-using-a-fixed-version-of-autoware","text":"In principle, errors should not occur when using a fixed version. That said, possible causes include: ROS 2 has been updated with breaking changes. For confirmation, check the Packaging and Release Management tag on ROS Discourse. Your local environment is broken. Confirm your .bashrc file, environment variables, and library versions. In addition to the causes listed above, there are two common misunderstandings around the use of fixed versions. You used a fixed version for autowarefoundation/autoware only. All of the repository versions in the .repos file must be specified in order to use a completely fixed version. You didn't update the workspace after changing the branch of autowarefoundation/autoware . Changing the branch of autowarefoundation/autoware does not affect the files under src/ . You have to run the vcs import command to update them.","title":"Errors when using a fixed version of Autoware"},{"location":"support/troubleshooting/#dockerrocker-issues","text":"If any errors occur when running Autoware with Docker or rocker, first confirm that your Docker installation is working correctly by running the following commands: docker run --rm -it hello-world docker run --rm -it ubuntu:latest Next, confirm that you are able to access the base Autoware image that is stored on the GitHub Packages website docker run --rm -it ghcr.io/autowarefoundation/autoware-universe:latest","title":"Docker/rocker issues"},{"location":"support/troubleshooting/#runtime-issues","text":"","title":"Runtime issues"},{"location":"support/troubleshooting/#map-does-not-display-when-running-the-planning-simulator","text":"When running the Planning Simulator, the most common reason for the map not being displayed in RViz is because the map path has not been specified correctly in the launch command . You can confirm if this is the case by searching for Could not find lanelet map under {path-to-map-dir}/lanelet2_map.osm errors in the log. Another possible reason is that map loading is taking a long time due to poor DDS performance. To address this issue, first enable localhost-only communication to reduce network traffic, and then tune DDS settings if the problem continues to occur. Enable localhost-only communication Tune DDS settings Add the following lines to /etc/sysctl.conf net.ipv4.ipfrag_time = 3 // generic DDS setting net.ipv4.ipfrag_high_thresh = 134217728 // generic DDS setting net.core.rmem_max = 2147483647 // only add if CycloneDDS is configured net.core.rmem_default = 8388608 // only add if CycloneDDS is confgured Note DDS configuration can be determined by running the following command. echo $RMW_IMPLEMENTATION // if Cyclone DDS is configured, this command will return \"rmw_cyclonedds_cpp\"","title":"Map does not display when running the Planning Simulator"},{"location":"support/troubleshooting/#multicast-is-disabled","text":"If you get the error message selected interface \"{your-interface-name}\" is not multicast-capable: disabling multicast , run the following command to allow multicast. sudo ip link set multicast on { your-interface-name }","title":"Multicast is disabled"},{"location":"tutorials/","text":"Simulation tutorials # Simulations provide a way of verifying Autoware's functionality before field testing with an actual vehicle. There are three main types of simulation that can be run ad hoc or via a scenario runner. Simulation methods # Ad hoc simulation # Ad hoc simulation is a flexible method for running basic simulations on your local machine, and is the recommended method for anyone new to Autoware. Scenario simulation # Scenario simulation uses a scenario runner to run more complex simulations based on predefined scenarios. It is often run automatically for continuous integration purposes, but can also be run on a local machine. Simulation types # Planning simulation # Planning simulation uses simple dummy data to test the Planning and Control components - specifically path generation, path following and obstacle avoidance. It verifies that a vehicle can reach a goal destination while avoiding pedestrians and surrounding cars, and is another method for verifying the validity of Lanelet2 maps. It also allows for testing of traffic light handling. How does planning simulation work? # Generate a path to the goal destination Control the car along the generated path Detect and avoid any humans or other vehicles on the way to the goal destination Rosbag replay simulation # Rosbag replay simulation uses prerecorded rosbag data to test the following aspects of the Localization and Perception components: Localization: Estimation of the vehicle's location on the map by matching sensor and vehicle feedback data to the map. Perception: Using sensor data to detect, track and predict dynamic objects such as surrounding cars, pedestrians, and other objects By repeatedly playing back the data, this simulation type can also be used for endurance testing. Digital twin simulation # Digital twin simulation is a simulation type that is able to produce realistic data and simulate almost the entire system. It is also commonly referred to as end-to-end simulation.","title":"Simulation tutorials"},{"location":"tutorials/#simulation-tutorials","text":"Simulations provide a way of verifying Autoware's functionality before field testing with an actual vehicle. There are three main types of simulation that can be run ad hoc or via a scenario runner.","title":"Simulation tutorials"},{"location":"tutorials/#simulation-methods","text":"","title":"Simulation methods"},{"location":"tutorials/#ad-hoc-simulation","text":"Ad hoc simulation is a flexible method for running basic simulations on your local machine, and is the recommended method for anyone new to Autoware.","title":"Ad hoc simulation"},{"location":"tutorials/#scenario-simulation","text":"Scenario simulation uses a scenario runner to run more complex simulations based on predefined scenarios. It is often run automatically for continuous integration purposes, but can also be run on a local machine.","title":"Scenario simulation"},{"location":"tutorials/#simulation-types","text":"","title":"Simulation types"},{"location":"tutorials/#planning-simulation","text":"Planning simulation uses simple dummy data to test the Planning and Control components - specifically path generation, path following and obstacle avoidance. It verifies that a vehicle can reach a goal destination while avoiding pedestrians and surrounding cars, and is another method for verifying the validity of Lanelet2 maps. It also allows for testing of traffic light handling.","title":"Planning simulation"},{"location":"tutorials/#rosbag-replay-simulation","text":"Rosbag replay simulation uses prerecorded rosbag data to test the following aspects of the Localization and Perception components: Localization: Estimation of the vehicle's location on the map by matching sensor and vehicle feedback data to the map. Perception: Using sensor data to detect, track and predict dynamic objects such as surrounding cars, pedestrians, and other objects By repeatedly playing back the data, this simulation type can also be used for endurance testing.","title":"Rosbag replay simulation"},{"location":"tutorials/#digital-twin-simulation","text":"Digital twin simulation is a simulation type that is able to produce realistic data and simulate almost the entire system. It is also commonly referred to as end-to-end simulation.","title":"Digital twin simulation"},{"location":"tutorials/ad-hoc-simulation/","text":"Ad hoc simulation # Warning Under Construction","title":"Ad hoc simulation"},{"location":"tutorials/ad-hoc-simulation/#ad-hoc-simulation","text":"Warning Under Construction","title":"Ad hoc simulation"},{"location":"tutorials/ad-hoc-simulation/planning-simulation/","text":"Planning simulation # Preparation # Download and unpack a sample map. You can also download the map manually. gdown -O ~/autoware_map/ 'https://docs.google.com/uc?export=download&id=1499_nsbUbIeturZaDj7jhUownh5fvXHd' unzip -d ~/autoware_map ~/autoware_map/sample-map-planning.zip Note Sample map: Copyright 2020 TIER IV, Inc. Basic simulations # Lane driving scenario # 1. Launch Autoware # source ~/autoware/install/setup.bash ros2 launch autoware_launch planning_simulator.launch.xml map_path: = $HOME /autoware_map/sample-map-planning vehicle_model: = sample_vehicle sensor_model: = sample_sensor_kit Warning Note that you cannot use ~ instead of $HOME here. If ~ is used, the map will fail to load. 2. Add Autoware State Panel # This panel is useful when running planning simulations. To add the panel, click Panels -> Add new panel , select AutowareStatePanel , and then click OK . 3. Set an initial pose for the ego vehicle # a) Click the 2D Pose estimate button in the toolbar, or hit the P key. b) In the 3D View pane, click and hold the left-mouse button, and then drag to set the direction for the initial pose. An image representing the vehicle should now be displayed. Warning Remember to set the initial pose of the car in the same direction as the lane. To confirm the direction of the lane, check the arrowheads displayed on the map. 4. Set a goal pose for the ego vehicle # a) Click the 2D Goal Pose button in the toolbar, or hit the G key. b) In the 3D View pane, click and hold the left-mouse button, and then drag to set the direction for the goal pose. If done correctly, you will see a planned path from initial pose to goal pose. 5. Engage the ego vehicle # Now you can start the ego vehicle driving by clicking the Engage button in AutowareStatePanel . Alteratively, you can manually engage the vehicle by running the following command: source ~/autoware/install/setup.bash ros2 topic pub /autoware/engage autoware_auto_vehicle_msgs/msg/Engage \"engage: true\" -1 Parking scenario # Set an initial pose and a goal pose, and engage the ego vehicle. When the vehicle approaches the goal, it will switch from lane driving mode to parking mode. After that, the vehicle will reverse into the destination parking spot. Advanced Simulations # Placing dummy objects # Click the 2D Dummy Car or 2D Dummy Pedestrian button in the toolbar. Set the pose of the dummy object by clicking and dragging on the map. Set the velocity of the object in Tool Properties -> 2D Dummy Car/Pedestrian panel. Note Changes to the velocity parameter will only affect objects placed after the parameter is changed. 4. Delete any dummy objects placed in the view by clicking the Delete All Objects button in the toolbar. Traffic light recognition simulation # By default, traffic lights on the map are all treated as if they are set to green. As a result, when a path is created that passed through an intersection with a traffic light, the ego vehicle will drive through the intersection without stopping. The following steps explain how to set and reset traffic lights in order to test how the Planning component will respond. Set traffic light # Go to Panels -> Add new panel , select TrafficLightPublishPanel , and then press OK . In TrafficLightPublishPanel , set the ID and color of the traffic light. Click the SET button. Finally, click the PUBLISH button to send the traffic light status to the simulator. Any planned path that goes past the selected traffic light will then change accordingly. By default, Rviz should display the ID of each traffic light on the map. You can have a closer look at the IDs by zooming in the region or by changing the View type. In case the IDs are not displayed, try the following troubleshooting steps: a) In the Displays panel, find the traffic_light_id topic by toggling the triangle icons next to Map > Lanelet2VectorMap > Namespaces . b) Check the traffic_light_id checkbox. c) Reload the topic by clicking the Map checkbox twice. Update/Reset traffic light # You can update the color of the traffic light by selecting the next color (in the image it is GREEN ) and clicking SET button. In the image the traffic light in front of the ego vehicle changed from RED to GREEN and the vehicle restarted. To remove a traffic light from TrafficLightPublishPanel , click the RESET button.","title":"Planning simulation"},{"location":"tutorials/ad-hoc-simulation/planning-simulation/#planning-simulation","text":"","title":"Planning simulation"},{"location":"tutorials/ad-hoc-simulation/planning-simulation/#preparation","text":"Download and unpack a sample map. You can also download the map manually. gdown -O ~/autoware_map/ 'https://docs.google.com/uc?export=download&id=1499_nsbUbIeturZaDj7jhUownh5fvXHd' unzip -d ~/autoware_map ~/autoware_map/sample-map-planning.zip Note Sample map: Copyright 2020 TIER IV, Inc.","title":"Preparation"},{"location":"tutorials/ad-hoc-simulation/planning-simulation/#basic-simulations","text":"","title":"Basic simulations"},{"location":"tutorials/ad-hoc-simulation/planning-simulation/#lane-driving-scenario","text":"","title":"Lane driving scenario"},{"location":"tutorials/ad-hoc-simulation/planning-simulation/#parking-scenario","text":"Set an initial pose and a goal pose, and engage the ego vehicle. When the vehicle approaches the goal, it will switch from lane driving mode to parking mode. After that, the vehicle will reverse into the destination parking spot.","title":"Parking scenario"},{"location":"tutorials/ad-hoc-simulation/planning-simulation/#advanced-simulations","text":"","title":"Advanced Simulations"},{"location":"tutorials/ad-hoc-simulation/planning-simulation/#placing-dummy-objects","text":"Click the 2D Dummy Car or 2D Dummy Pedestrian button in the toolbar. Set the pose of the dummy object by clicking and dragging on the map. Set the velocity of the object in Tool Properties -> 2D Dummy Car/Pedestrian panel. Note Changes to the velocity parameter will only affect objects placed after the parameter is changed. 4. Delete any dummy objects placed in the view by clicking the Delete All Objects button in the toolbar.","title":"Placing dummy objects"},{"location":"tutorials/ad-hoc-simulation/planning-simulation/#traffic-light-recognition-simulation","text":"By default, traffic lights on the map are all treated as if they are set to green. As a result, when a path is created that passed through an intersection with a traffic light, the ego vehicle will drive through the intersection without stopping. The following steps explain how to set and reset traffic lights in order to test how the Planning component will respond.","title":"Traffic light recognition simulation"},{"location":"tutorials/ad-hoc-simulation/rosbag-replay-simulation/","text":"Rosbag replay simulation # Steps # Download and unpack a sample map. You can also download the map manually. gdown -O ~/autoware_map/ 'https://docs.google.com/uc?export=download&id=1A-8BvYRX3DhSzkAnOcGWFw5T30xTlwZI' unzip -d ~/autoware_map/ ~/autoware_map/sample-map-rosbag.zip Download the sample rosbag files. You can also download the rosbag files manually. gdown -O ~/autoware_map/ 'https://docs.google.com/uc?export=download&id=1VnwJx9tI3kI_cTLzP61ktuAJ1ChgygpG' unzip -d ~/autoware_map/ ~/autoware_map/sample-rosbag.zip Note # Sample map and rosbag: Copyright 2020 TIER IV, Inc. Due to privacy concerns, the rosbag does not contain image data, which will cause: Traffic light recognition functionality cannot be tested with this sample rosbag. Object detection accuracy is decreased. How to run a rosbag replay simulation # Launch Autoware. source ~/autoware/install/setup.bash ros2 launch autoware_launch logging_simulator.launch.xml map_path: = $HOME /autoware_map/sample-map-rosbag vehicle_model: = sample_vehicle sensor_model: = sample_sensor_kit Note that you cannot use ~ instead of $HOME here. Play the sample rosbag file. source ~/autoware/install/setup.bash ros2 bag play ~/autoware_map/sample-rosbag/sample.db3 -r 0 .2 -s sqlite3 To focus the view on the ego vehicle, change the Target Frame in the RViz Views panel from viewer to base_link . To switch the view to Third Person Follower etc, change the Type in the RViz Views panel.","title":"Rosbag replay simulation"},{"location":"tutorials/ad-hoc-simulation/rosbag-replay-simulation/#rosbag-replay-simulation","text":"","title":"Rosbag replay simulation"},{"location":"tutorials/ad-hoc-simulation/rosbag-replay-simulation/#steps","text":"Download and unpack a sample map. You can also download the map manually. gdown -O ~/autoware_map/ 'https://docs.google.com/uc?export=download&id=1A-8BvYRX3DhSzkAnOcGWFw5T30xTlwZI' unzip -d ~/autoware_map/ ~/autoware_map/sample-map-rosbag.zip Download the sample rosbag files. You can also download the rosbag files manually. gdown -O ~/autoware_map/ 'https://docs.google.com/uc?export=download&id=1VnwJx9tI3kI_cTLzP61ktuAJ1ChgygpG' unzip -d ~/autoware_map/ ~/autoware_map/sample-rosbag.zip","title":"Steps"},{"location":"tutorials/ad-hoc-simulation/rosbag-replay-simulation/#note","text":"Sample map and rosbag: Copyright 2020 TIER IV, Inc. Due to privacy concerns, the rosbag does not contain image data, which will cause: Traffic light recognition functionality cannot be tested with this sample rosbag. Object detection accuracy is decreased.","title":"Note"},{"location":"tutorials/ad-hoc-simulation/rosbag-replay-simulation/#how-to-run-a-rosbag-replay-simulation","text":"Launch Autoware. source ~/autoware/install/setup.bash ros2 launch autoware_launch logging_simulator.launch.xml map_path: = $HOME /autoware_map/sample-map-rosbag vehicle_model: = sample_vehicle sensor_model: = sample_sensor_kit Note that you cannot use ~ instead of $HOME here. Play the sample rosbag file. source ~/autoware/install/setup.bash ros2 bag play ~/autoware_map/sample-rosbag/sample.db3 -r 0 .2 -s sqlite3 To focus the view on the ego vehicle, change the Target Frame in the RViz Views panel from viewer to base_link . To switch the view to Third Person Follower etc, change the Type in the RViz Views panel.","title":"How to run a rosbag replay simulation"},{"location":"tutorials/ad-hoc-simulation/digital-twin-simulation/awsim-tutorial/","text":"AWSIM simulator # AWSIM is a simulator for Autoware development and testing. To get started, please follow the official instruction provided by TIER IV.","title":"AWSIM simulator"},{"location":"tutorials/ad-hoc-simulation/digital-twin-simulation/awsim-tutorial/#awsim-simulator","text":"AWSIM is a simulator for Autoware development and testing. To get started, please follow the official instruction provided by TIER IV.","title":"AWSIM simulator"},{"location":"tutorials/scenario-simulation/rosbag-replay-simulation/","text":"Rosbag replay simulation # Warning Under Construction","title":"Rosbag replay simulation"},{"location":"tutorials/scenario-simulation/rosbag-replay-simulation/#rosbag-replay-simulation","text":"Warning Under Construction","title":"Rosbag replay simulation"},{"location":"tutorials/scenario-simulation/planning-simulation/installation/","text":"Installation # This document contains step-by-step instruction on how to build AWF Autoware Core/Universe with scenario_simulator_v2 . Prerequisites # Autoware has been built and installed How to build # Navigate to the Autoware workspace: cd autoware Import Simulator dependencies: vcs import src < simulator.repos Install dependent ROS packages: source /opt/ros/galactic/setup.bash rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO Build the workspace: colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release","title":"Installation"},{"location":"tutorials/scenario-simulation/planning-simulation/installation/#installation","text":"This document contains step-by-step instruction on how to build AWF Autoware Core/Universe with scenario_simulator_v2 .","title":"Installation"},{"location":"tutorials/scenario-simulation/planning-simulation/installation/#prerequisites","text":"Autoware has been built and installed","title":"Prerequisites"},{"location":"tutorials/scenario-simulation/planning-simulation/installation/#how-to-build","text":"Navigate to the Autoware workspace: cd autoware Import Simulator dependencies: vcs import src < simulator.repos Install dependent ROS packages: source /opt/ros/galactic/setup.bash rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO Build the workspace: colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release","title":"How to build"},{"location":"tutorials/scenario-simulation/planning-simulation/random-test-simulation/","text":"Random test simulation # Note Running the Scenario Simulator requires some additional steps on top of building and installing Autoware, so make sure that Scenario Simulator installation has been completed first before proceeding. Running steps # Move to the workspace directory where Autoware and the Scenario Simulator have been built. Source the workspace setup script: source install/setup.bash Run the simulation: ros2 launch random_test_runner random_test.launch.py \\ architecture_type: = awf/universe \\ sensor_model: = sample_sensor_kit \\ vehicle_model: = sample_vehicle For more information about supported parameters, refer to the random_test_runner documentation .","title":"Random test simulation"},{"location":"tutorials/scenario-simulation/planning-simulation/random-test-simulation/#random-test-simulation","text":"Note Running the Scenario Simulator requires some additional steps on top of building and installing Autoware, so make sure that Scenario Simulator installation has been completed first before proceeding.","title":"Random test simulation"},{"location":"tutorials/scenario-simulation/planning-simulation/random-test-simulation/#running-steps","text":"Move to the workspace directory where Autoware and the Scenario Simulator have been built. Source the workspace setup script: source install/setup.bash Run the simulation: ros2 launch random_test_runner random_test.launch.py \\ architecture_type: = awf/universe \\ sensor_model: = sample_sensor_kit \\ vehicle_model: = sample_vehicle For more information about supported parameters, refer to the random_test_runner documentation .","title":"Running steps"},{"location":"tutorials/scenario-simulation/planning-simulation/scenario-test-simulation/","text":"Scenario test simulation # Note Running the Scenario Simulator requires some additional steps on top of building and installing Autoware, so make sure that Scenario Simulator installation has been completed first before proceeding. Running steps # Move to the workspace directory where Autoware and the Scenario Simulator have been built. Source the workspace setup script: source install/setup.bash Run the simulation: ros2 launch scenario_test_runner scenario_test_runner.launch.py \\ architecture_type: = awf/universe \\ record: = false \\ scenario: = '$(find-pkg-share scenario_test_runner)/scenario/sample.yaml' \\ sensor_model: = sample_sensor_kit \\ vehicle_model: = sample_vehicle","title":"Scenario test simulation"},{"location":"tutorials/scenario-simulation/planning-simulation/scenario-test-simulation/#scenario-test-simulation","text":"Note Running the Scenario Simulator requires some additional steps on top of building and installing Autoware, so make sure that Scenario Simulator installation has been completed first before proceeding.","title":"Scenario test simulation"},{"location":"tutorials/scenario-simulation/planning-simulation/scenario-test-simulation/#running-steps","text":"Move to the workspace directory where Autoware and the Scenario Simulator have been built. Source the workspace setup script: source install/setup.bash Run the simulation: ros2 launch scenario_test_runner scenario_test_runner.launch.py \\ architecture_type: = awf/universe \\ record: = false \\ scenario: = '$(find-pkg-share scenario_test_runner)/scenario/sample.yaml' \\ sensor_model: = sample_sensor_kit \\ vehicle_model: = sample_vehicle","title":"Running steps"}]}